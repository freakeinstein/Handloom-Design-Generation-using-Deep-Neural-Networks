{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'horse2zebra'\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 32\n",
    "        self.df = 64\n",
    "\n",
    "        # Loss weights\n",
    "        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n",
    "        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminators\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "\n",
    "        # Input images from both domains\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        # Translate images back to original domain\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # Identity mapping of images\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generators\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[img_A, img_B],\n",
    "                              outputs=[ valid_A, valid_B,\n",
    "                                        reconstr_A, reconstr_B,\n",
    "                                        img_A_id, img_B_id ])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                            loss_weights=[  1, 1,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id ],\n",
    "                            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            d = InstanceNormalization()(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = InstanceNormalization()(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d4, d3, self.gf*4)\n",
    "        u2 = deconv2d(u1, d2, self.gf*2)\n",
    "        u3 = deconv2d(u2, d1, self.gf)\n",
    "\n",
    "        u4 = UpSampling2D(size=2)(u3)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if normalization:\n",
    "                d = InstanceNormalization()(d)\n",
    "            return d\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        d1 = d_layer(img, self.df, normalization=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # Total disciminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "\n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                        [valid, valid,\n",
    "                                                        imgs_A, imgs_B,\n",
    "                                                        imgs_A, imgs_B])\n",
    "                    \n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
    "                                                                        % ( epoch, epochs,\n",
    "                                                                            batch_i, self.data_loader.n_batches,\n",
    "                                                                            d_loss[0], 100*d_loss[1],\n",
    "                                                                            g_loss[0],\n",
    "                                                                            np.mean(g_loss[1:3]),\n",
    "                                                                            np.mean(g_loss[3:5]),\n",
    "                                                                            np.mean(g_loss[5:6]),\n",
    "                                                                            elapsed_time))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)\n",
    "            \n",
    "            self.combined.save('cyclegan_models/v1_horse2zebra/epoch_' + str(epoch) + '_model.h5')\n",
    "                \n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
    "        r, c = 2, 3\n",
    "\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
    "\n",
    "        # Demo (for GIF)\n",
    "        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
    "        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
    "\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        fake_A = self.g_BA.predict(imgs_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amrit/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/amrit/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/amrit/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/266] [D loss: 28.902859, acc:  10%] [G loss: 54.874325, adv: 19.892166, recon: 0.667843, id: 1.059934] time: 0:00:54.126151 \n",
      "[Epoch 0/200] [Batch 1/266] [D loss: 9.926638, acc:  15%] [G loss: 68.096985, adv: 26.460175, recon: 0.670909, id: 0.911474] time: 0:00:55.201686 \n",
      "[Epoch 0/200] [Batch 2/266] [D loss: 11.332312, acc:  11%] [G loss: 41.906540, adv: 13.890949, recon: 0.627404, id: 0.833495] time: 0:00:55.842391 \n",
      "[Epoch 0/200] [Batch 3/266] [D loss: 6.562084, acc:  18%] [G loss: 19.063219, adv: 2.634443, recon: 0.605820, id: 0.857869] time: 0:00:56.430360 \n",
      "[Epoch 0/200] [Batch 4/266] [D loss: 3.504441, acc:  19%] [G loss: 14.399940, adv: 1.114183, recon: 0.511620, id: 1.046693] time: 0:00:57.052834 \n",
      "[Epoch 0/200] [Batch 5/266] [D loss: 1.221640, acc:  36%] [G loss: 13.581953, adv: 0.924550, recon: 0.495146, id: 0.952461] time: 0:00:57.724454 \n",
      "[Epoch 0/200] [Batch 6/266] [D loss: 0.483917, acc:  52%] [G loss: 13.349558, adv: 0.963545, recon: 0.476792, id: 0.982808] time: 0:00:58.373495 \n",
      "[Epoch 0/200] [Batch 7/266] [D loss: 0.893719, acc:  56%] [G loss: 13.306479, adv: 0.940938, recon: 0.473062, id: 1.026679] time: 0:00:58.954031 \n",
      "[Epoch 0/200] [Batch 8/266] [D loss: 0.565883, acc:  47%] [G loss: 12.865119, adv: 0.890542, recon: 0.464503, id: 0.996694] time: 0:00:59.574522 \n",
      "[Epoch 0/200] [Batch 9/266] [D loss: 0.264762, acc:  68%] [G loss: 11.921980, adv: 0.937036, recon: 0.416715, id: 0.887440] time: 0:01:00.201876 \n",
      "[Epoch 0/200] [Batch 10/266] [D loss: 0.397841, acc:  60%] [G loss: 12.719721, adv: 1.006566, recon: 0.446144, id: 0.925293] time: 0:01:00.874376 \n",
      "[Epoch 0/200] [Batch 11/266] [D loss: 0.311192, acc:  56%] [G loss: 12.021702, adv: 1.069061, recon: 0.400852, id: 0.977267] time: 0:01:01.457785 \n",
      "[Epoch 0/200] [Batch 12/266] [D loss: 0.304314, acc:  60%] [G loss: 12.389679, adv: 0.913251, recon: 0.440804, id: 0.949298] time: 0:01:02.064580 \n",
      "[Epoch 0/200] [Batch 13/266] [D loss: 0.357121, acc:  52%] [G loss: 11.470716, adv: 1.012938, recon: 0.386091, id: 0.920587] time: 0:01:02.683526 \n",
      "[Epoch 0/200] [Batch 14/266] [D loss: 0.360412, acc:  52%] [G loss: 12.322948, adv: 1.046370, recon: 0.421974, id: 0.969117] time: 0:01:03.292213 \n",
      "[Epoch 0/200] [Batch 15/266] [D loss: 0.425324, acc:  43%] [G loss: 11.572686, adv: 1.317641, recon: 0.363547, id: 0.935928] time: 0:01:03.865832 \n",
      "[Epoch 0/200] [Batch 16/266] [D loss: 0.392123, acc:  57%] [G loss: 12.306089, adv: 0.846296, recon: 0.446668, id: 0.927020] time: 0:01:04.398290 \n",
      "[Epoch 0/200] [Batch 17/266] [D loss: 0.291042, acc:  60%] [G loss: 11.501513, adv: 0.797265, recon: 0.416154, id: 0.811877] time: 0:01:04.988391 \n",
      "[Epoch 0/200] [Batch 18/266] [D loss: 0.751644, acc:  28%] [G loss: 12.060527, adv: 1.487400, recon: 0.369365, id: 0.995219] time: 0:01:05.585253 \n",
      "[Epoch 0/200] [Batch 19/266] [D loss: 0.667668, acc:  40%] [G loss: 12.096072, adv: 1.101996, recon: 0.410911, id: 0.955496] time: 0:01:06.121692 \n",
      "[Epoch 0/200] [Batch 20/266] [D loss: 0.677328, acc:  50%] [G loss: 12.550505, adv: 1.034973, recon: 0.447066, id: 0.780188] time: 0:01:06.687670 \n",
      "[Epoch 0/200] [Batch 21/266] [D loss: 0.311466, acc:  58%] [G loss: 11.647253, adv: 1.128417, recon: 0.390174, id: 0.828595] time: 0:01:07.233067 \n",
      "[Epoch 0/200] [Batch 22/266] [D loss: 0.385573, acc:  53%] [G loss: 11.843999, adv: 0.910083, recon: 0.418936, id: 0.902213] time: 0:01:07.802322 \n",
      "[Epoch 0/200] [Batch 23/266] [D loss: 0.486840, acc:  60%] [G loss: 12.877939, adv: 1.336642, recon: 0.424591, id: 0.916923] time: 0:01:08.346028 \n",
      "[Epoch 0/200] [Batch 24/266] [D loss: 0.497140, acc:  45%] [G loss: 12.522930, adv: 1.301930, recon: 0.420647, id: 0.814341] time: 0:01:08.938021 \n",
      "[Epoch 0/200] [Batch 25/266] [D loss: 0.357104, acc:  55%] [G loss: 12.760502, adv: 0.953310, recon: 0.449105, id: 0.951670] time: 0:01:09.554017 \n",
      "[Epoch 0/200] [Batch 26/266] [D loss: 0.617864, acc:  39%] [G loss: 12.638457, adv: 1.423070, recon: 0.410012, id: 0.823666] time: 0:01:10.131997 \n",
      "[Epoch 0/200] [Batch 27/266] [D loss: 0.343284, acc:  63%] [G loss: 10.611647, adv: 0.784913, recon: 0.367683, id: 0.824390] time: 0:01:10.642785 \n",
      "[Epoch 0/200] [Batch 28/266] [D loss: 0.528262, acc:  34%] [G loss: 11.840891, adv: 1.295976, recon: 0.383773, id: 0.881036] time: 0:01:11.226846 \n",
      "[Epoch 0/200] [Batch 29/266] [D loss: 0.897915, acc:  23%] [G loss: 11.339428, adv: 0.943525, recon: 0.391209, id: 0.896948] time: 0:01:11.841075 \n",
      "[Epoch 0/200] [Batch 30/266] [D loss: 0.464888, acc:  49%] [G loss: 11.543781, adv: 1.030723, recon: 0.403371, id: 0.698843] time: 0:01:12.554641 \n",
      "[Epoch 0/200] [Batch 31/266] [D loss: 0.518214, acc:  36%] [G loss: 10.976434, adv: 0.853805, recon: 0.379704, id: 0.892623] time: 0:01:13.179637 \n",
      "[Epoch 0/200] [Batch 32/266] [D loss: 0.661627, acc:  30%] [G loss: 10.503861, adv: 0.875562, recon: 0.360149, id: 0.744547] time: 0:01:13.749209 \n",
      "[Epoch 0/200] [Batch 33/266] [D loss: 0.625581, acc:  28%] [G loss: 10.806093, adv: 0.971510, recon: 0.366455, id: 0.810768] time: 0:01:14.300599 \n",
      "[Epoch 0/200] [Batch 34/266] [D loss: 0.411171, acc:  44%] [G loss: 12.794288, adv: 1.128505, recon: 0.440866, id: 1.002245] time: 0:01:14.841052 \n",
      "[Epoch 0/200] [Batch 35/266] [D loss: 0.597381, acc:  34%] [G loss: 10.701920, adv: 0.539547, recon: 0.398898, id: 0.804849] time: 0:01:15.425712 \n",
      "[Epoch 0/200] [Batch 36/266] [D loss: 0.184428, acc:  76%] [G loss: 10.346786, adv: 1.082030, recon: 0.301564, id: 1.233779] time: 0:01:15.989542 \n",
      "[Epoch 0/200] [Batch 37/266] [D loss: 0.868774, acc:  22%] [G loss: 12.464971, adv: 1.443056, recon: 0.407056, id: 0.795098] time: 0:01:16.597835 \n",
      "[Epoch 0/200] [Batch 38/266] [D loss: 0.659200, acc:  39%] [G loss: 11.891153, adv: 1.379822, recon: 0.375838, id: 0.928932] time: 0:01:17.169852 \n",
      "[Epoch 0/200] [Batch 39/266] [D loss: 0.654127, acc:  41%] [G loss: 11.456581, adv: 1.340225, recon: 0.355799, id: 1.024160] time: 0:01:17.711026 \n",
      "[Epoch 0/200] [Batch 40/266] [D loss: 0.530396, acc:  44%] [G loss: 10.017764, adv: 0.640417, recon: 0.354066, id: 0.931619] time: 0:01:18.325573 \n",
      "[Epoch 0/200] [Batch 41/266] [D loss: 0.500450, acc:  38%] [G loss: 10.459305, adv: 0.509756, recon: 0.382311, id: 0.793636] time: 0:01:18.897351 \n",
      "[Epoch 0/200] [Batch 42/266] [D loss: 0.454159, acc:  31%] [G loss: 10.030242, adv: 0.522580, recon: 0.360147, id: 0.865114] time: 0:01:19.446428 \n",
      "[Epoch 0/200] [Batch 43/266] [D loss: 0.380122, acc:  53%] [G loss: 9.594432, adv: 0.704002, recon: 0.329188, id: 0.712022] time: 0:01:20.020017 \n",
      "[Epoch 0/200] [Batch 44/266] [D loss: 0.492133, acc:  38%] [G loss: 9.430622, adv: 0.770424, recon: 0.319364, id: 0.824199] time: 0:01:20.633193 \n",
      "[Epoch 0/200] [Batch 45/266] [D loss: 0.381429, acc:  39%] [G loss: 9.753208, adv: 0.984468, recon: 0.319976, id: 0.747162] time: 0:01:21.288061 \n",
      "[Epoch 0/200] [Batch 46/266] [D loss: 0.476549, acc:  45%] [G loss: 9.719235, adv: 0.934310, recon: 0.313293, id: 0.768439] time: 0:01:21.877233 \n",
      "[Epoch 0/200] [Batch 47/266] [D loss: 0.498435, acc:  37%] [G loss: 8.700199, adv: 0.496753, recon: 0.296968, id: 0.874291] time: 0:01:22.441052 \n",
      "[Epoch 0/200] [Batch 48/266] [D loss: 0.367714, acc:  52%] [G loss: 9.463257, adv: 0.825887, recon: 0.298562, id: 1.019741] time: 0:01:22.971636 \n",
      "[Epoch 0/200] [Batch 49/266] [D loss: 0.346409, acc:  50%] [G loss: 9.598211, adv: 0.909917, recon: 0.296365, id: 0.958163] time: 0:01:23.524299 \n",
      "[Epoch 0/200] [Batch 50/266] [D loss: 0.337784, acc:  58%] [G loss: 9.107096, adv: 0.751577, recon: 0.286990, id: 1.034272] time: 0:01:24.232623 \n",
      "[Epoch 0/200] [Batch 51/266] [D loss: 0.324446, acc:  52%] [G loss: 9.305405, adv: 0.650827, recon: 0.304952, id: 1.067376] time: 0:01:24.889420 \n",
      "[Epoch 0/200] [Batch 52/266] [D loss: 0.560346, acc:  28%] [G loss: 10.167116, adv: 0.762434, recon: 0.348837, id: 0.798649] time: 0:01:25.554501 \n",
      "[Epoch 0/200] [Batch 53/266] [D loss: 0.396738, acc:  56%] [G loss: 10.077228, adv: 1.165736, recon: 0.303112, id: 0.872028] time: 0:01:26.182622 \n",
      "[Epoch 0/200] [Batch 54/266] [D loss: 0.433736, acc:  57%] [G loss: 8.541098, adv: 0.637214, recon: 0.287080, id: 0.752269] time: 0:01:26.811936 \n",
      "[Epoch 0/200] [Batch 55/266] [D loss: 0.316991, acc:  47%] [G loss: 9.146937, adv: 0.706235, recon: 0.306322, id: 0.958084] time: 0:01:27.388906 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 56/266] [D loss: 0.519890, acc:  24%] [G loss: 8.090616, adv: 0.570924, recon: 0.252512, id: 1.062010] time: 0:01:27.908569 \n",
      "[Epoch 0/200] [Batch 57/266] [D loss: 0.411220, acc:  42%] [G loss: 9.605376, adv: 0.895550, recon: 0.304995, id: 0.987738] time: 0:01:28.493266 \n",
      "[Epoch 0/200] [Batch 58/266] [D loss: 0.397164, acc:  55%] [G loss: 9.717443, adv: 0.611568, recon: 0.333658, id: 0.879348] time: 0:01:29.028926 \n",
      "[Epoch 0/200] [Batch 59/266] [D loss: 0.513797, acc:  27%] [G loss: 8.612302, adv: 0.579173, recon: 0.289718, id: 0.770504] time: 0:01:29.683829 \n",
      "[Epoch 0/200] [Batch 60/266] [D loss: 0.555678, acc:  37%] [G loss: 8.305759, adv: 1.254650, recon: 0.203373, id: 0.830766] time: 0:01:30.199675 \n",
      "[Epoch 0/200] [Batch 61/266] [D loss: 0.643188, acc:  50%] [G loss: 8.028234, adv: 0.627510, recon: 0.262854, id: 0.710464] time: 0:01:30.759984 \n",
      "[Epoch 0/200] [Batch 62/266] [D loss: 0.616676, acc:  29%] [G loss: 8.396306, adv: 0.540702, recon: 0.291598, id: 0.616187] time: 0:01:31.383237 \n",
      "[Epoch 0/200] [Batch 63/266] [D loss: 0.384581, acc:  43%] [G loss: 8.762657, adv: 0.761576, recon: 0.288533, id: 0.780993] time: 0:01:32.008485 \n",
      "[Epoch 0/200] [Batch 64/266] [D loss: 0.538721, acc:  29%] [G loss: 9.037264, adv: 0.668028, recon: 0.308873, id: 0.705848] time: 0:01:32.608123 \n",
      "[Epoch 0/200] [Batch 65/266] [D loss: 0.415034, acc:  41%] [G loss: 10.013114, adv: 0.711606, recon: 0.350349, id: 0.810722] time: 0:01:33.169145 \n",
      "[Epoch 0/200] [Batch 66/266] [D loss: 0.397003, acc:  42%] [G loss: 8.251099, adv: 0.539036, recon: 0.281340, id: 0.815864] time: 0:01:33.755653 \n",
      "[Epoch 0/200] [Batch 67/266] [D loss: 0.369219, acc:  37%] [G loss: 8.523693, adv: 0.531991, recon: 0.295512, id: 0.886394] time: 0:01:34.363721 \n",
      "[Epoch 0/200] [Batch 68/266] [D loss: 0.419026, acc:  42%] [G loss: 7.652728, adv: 0.562964, recon: 0.245216, id: 0.854658] time: 0:01:34.973307 \n",
      "[Epoch 0/200] [Batch 69/266] [D loss: 0.447298, acc:  34%] [G loss: 7.776186, adv: 0.599061, recon: 0.237808, id: 1.040437] time: 0:01:35.515739 \n",
      "[Epoch 0/200] [Batch 70/266] [D loss: 0.425628, acc:  32%] [G loss: 9.071095, adv: 0.740007, recon: 0.301213, id: 0.881683] time: 0:01:36.107207 \n",
      "[Epoch 0/200] [Batch 71/266] [D loss: 0.425728, acc:  33%] [G loss: 8.297291, adv: 0.633808, recon: 0.277561, id: 0.803534] time: 0:01:36.684669 \n",
      "[Epoch 0/200] [Batch 72/266] [D loss: 0.401728, acc:  38%] [G loss: 8.804634, adv: 0.718431, recon: 0.300739, id: 0.741996] time: 0:01:37.355519 \n",
      "[Epoch 0/200] [Batch 73/266] [D loss: 0.521639, acc:  27%] [G loss: 8.659552, adv: 0.638936, recon: 0.293885, id: 0.710694] time: 0:01:37.994942 \n",
      "[Epoch 0/200] [Batch 74/266] [D loss: 0.459585, acc:  41%] [G loss: 7.428584, adv: 0.760605, recon: 0.215912, id: 0.907674] time: 0:01:38.585184 \n",
      "[Epoch 0/200] [Batch 75/266] [D loss: 0.638765, acc:  17%] [G loss: 8.520794, adv: 0.578835, recon: 0.298580, id: 0.670816] time: 0:01:39.133863 \n",
      "[Epoch 0/200] [Batch 76/266] [D loss: 0.357499, acc:  52%] [G loss: 7.957265, adv: 0.747599, recon: 0.248725, id: 0.749634] time: 0:01:39.704497 \n",
      "[Epoch 0/200] [Batch 77/266] [D loss: 0.450473, acc:  33%] [G loss: 8.027088, adv: 0.645493, recon: 0.252176, id: 0.879985] time: 0:01:40.296303 \n",
      "[Epoch 0/200] [Batch 78/266] [D loss: 0.329979, acc:  47%] [G loss: 7.975924, adv: 0.667479, recon: 0.243176, id: 1.047295] time: 0:01:40.889722 \n",
      "[Epoch 0/200] [Batch 79/266] [D loss: 0.441859, acc:  33%] [G loss: 8.213137, adv: 0.494829, recon: 0.278216, id: 0.839737] time: 0:01:41.614626 \n",
      "[Epoch 0/200] [Batch 80/266] [D loss: 0.285529, acc:  55%] [G loss: 8.251835, adv: 0.601519, recon: 0.277496, id: 0.736566] time: 0:01:42.254774 \n",
      "[Epoch 0/200] [Batch 81/266] [D loss: 0.255155, acc:  59%] [G loss: 7.947506, adv: 0.677069, recon: 0.252398, id: 0.823817] time: 0:01:42.849612 \n",
      "[Epoch 0/200] [Batch 82/266] [D loss: 0.480894, acc:  32%] [G loss: 7.652410, adv: 0.654082, recon: 0.232344, id: 0.829690] time: 0:01:43.411358 \n",
      "[Epoch 0/200] [Batch 83/266] [D loss: 0.328968, acc:  47%] [G loss: 7.978195, adv: 0.673377, recon: 0.250998, id: 0.880877] time: 0:01:44.030365 \n",
      "[Epoch 0/200] [Batch 84/266] [D loss: 0.452475, acc:  41%] [G loss: 8.342713, adv: 0.717182, recon: 0.264284, id: 0.901033] time: 0:01:44.601974 \n",
      "[Epoch 0/200] [Batch 85/266] [D loss: 0.322230, acc:  55%] [G loss: 8.438881, adv: 0.766222, recon: 0.259719, id: 0.861820] time: 0:01:45.138304 \n",
      "[Epoch 0/200] [Batch 86/266] [D loss: 0.506475, acc:  30%] [G loss: 7.252480, adv: 0.511995, recon: 0.243417, id: 0.724198] time: 0:01:45.772117 \n",
      "[Epoch 0/200] [Batch 87/266] [D loss: 0.385825, acc:  36%] [G loss: 8.335886, adv: 0.675840, recon: 0.283437, id: 0.658065] time: 0:01:46.422114 \n",
      "[Epoch 0/200] [Batch 88/266] [D loss: 0.536029, acc:  27%] [G loss: 8.149736, adv: 0.595183, recon: 0.273359, id: 0.732413] time: 0:01:46.957594 \n",
      "[Epoch 0/200] [Batch 89/266] [D loss: 0.364158, acc:  43%] [G loss: 8.526173, adv: 0.615750, recon: 0.285680, id: 0.841460] time: 0:01:47.568044 \n",
      "[Epoch 0/200] [Batch 90/266] [D loss: 0.412543, acc:  34%] [G loss: 8.514858, adv: 0.645640, recon: 0.282824, id: 0.822685] time: 0:01:48.245384 \n",
      "[Epoch 0/200] [Batch 91/266] [D loss: 0.350006, acc:  53%] [G loss: 8.205602, adv: 0.555663, recon: 0.268761, id: 0.869782] time: 0:01:48.824863 \n",
      "[Epoch 0/200] [Batch 92/266] [D loss: 0.425772, acc:  37%] [G loss: 7.184598, adv: 0.502264, recon: 0.228712, id: 0.865207] time: 0:01:49.353791 \n",
      "[Epoch 0/200] [Batch 93/266] [D loss: 0.364849, acc:  39%] [G loss: 7.814904, adv: 0.518458, recon: 0.256673, id: 0.916912] time: 0:01:49.893774 \n",
      "[Epoch 0/200] [Batch 94/266] [D loss: 0.438436, acc:  29%] [G loss: 7.520131, adv: 0.443275, recon: 0.259292, id: 0.671421] time: 0:01:50.490726 \n",
      "[Epoch 0/200] [Batch 95/266] [D loss: 0.257248, acc:  53%] [G loss: 8.291680, adv: 0.678166, recon: 0.263776, id: 0.778134] time: 0:01:51.110847 \n",
      "[Epoch 0/200] [Batch 96/266] [D loss: 0.394610, acc:  34%] [G loss: 7.283786, adv: 0.486232, recon: 0.240507, id: 0.727779] time: 0:01:51.734754 \n",
      "[Epoch 0/200] [Batch 97/266] [D loss: 0.265458, acc:  55%] [G loss: 7.806380, adv: 0.639589, recon: 0.254533, id: 0.600390] time: 0:01:52.378603 \n",
      "[Epoch 0/200] [Batch 98/266] [D loss: 0.292638, acc:  50%] [G loss: 7.133714, adv: 0.553767, recon: 0.223100, id: 0.806353] time: 0:01:52.930778 \n",
      "[Epoch 0/200] [Batch 99/266] [D loss: 0.232708, acc:  65%] [G loss: 7.419192, adv: 0.777193, recon: 0.214952, id: 0.799105] time: 0:01:53.507435 \n",
      "[Epoch 0/200] [Batch 100/266] [D loss: 0.448802, acc:  29%] [G loss: 6.693842, adv: 0.481388, recon: 0.211959, id: 0.824770] time: 0:01:54.129481 \n",
      "[Epoch 0/200] [Batch 101/266] [D loss: 0.410338, acc:  34%] [G loss: 6.822955, adv: 0.463213, recon: 0.210841, id: 0.913317] time: 0:01:54.695092 \n",
      "[Epoch 0/200] [Batch 102/266] [D loss: 0.402789, acc:  40%] [G loss: 7.503800, adv: 0.729488, recon: 0.217304, id: 0.779857] time: 0:01:55.296193 \n",
      "[Epoch 0/200] [Batch 103/266] [D loss: 0.294595, acc:  58%] [G loss: 7.583567, adv: 0.706966, recon: 0.223193, id: 0.877725] time: 0:01:55.859747 \n",
      "[Epoch 0/200] [Batch 104/266] [D loss: 0.439800, acc:  34%] [G loss: 7.634314, adv: 0.709539, recon: 0.234268, id: 0.798955] time: 0:01:56.475808 \n",
      "[Epoch 0/200] [Batch 105/266] [D loss: 0.377838, acc:  35%] [G loss: 7.409169, adv: 0.566512, recon: 0.234871, id: 0.816787] time: 0:01:57.105219 \n",
      "[Epoch 0/200] [Batch 106/266] [D loss: 0.377238, acc:  37%] [G loss: 7.228645, adv: 0.609463, recon: 0.225417, id: 0.801469] time: 0:01:57.762939 \n",
      "[Epoch 0/200] [Batch 107/266] [D loss: 0.443615, acc:  29%] [G loss: 7.023339, adv: 0.463059, recon: 0.225031, id: 0.848596] time: 0:01:58.321204 \n",
      "[Epoch 0/200] [Batch 108/266] [D loss: 0.342245, acc:  34%] [G loss: 6.843486, adv: 0.609954, recon: 0.198723, id: 0.912889] time: 0:01:58.953669 \n",
      "[Epoch 0/200] [Batch 109/266] [D loss: 0.293956, acc:  57%] [G loss: 7.285138, adv: 0.600472, recon: 0.215493, id: 1.016036] time: 0:01:59.548396 \n",
      "[Epoch 0/200] [Batch 110/266] [D loss: 0.499793, acc:  34%] [G loss: 6.844743, adv: 0.480858, recon: 0.215398, id: 0.941320] time: 0:02:00.166853 \n",
      "[Epoch 0/200] [Batch 111/266] [D loss: 0.230974, acc:  63%] [G loss: 8.151939, adv: 0.882820, recon: 0.233072, id: 0.869775] time: 0:02:00.726126 \n",
      "[Epoch 0/200] [Batch 112/266] [D loss: 0.448844, acc:  36%] [G loss: 6.822323, adv: 0.481209, recon: 0.221978, id: 0.808134] time: 0:02:01.331638 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 113/266] [D loss: 0.253790, acc:  65%] [G loss: 8.081391, adv: 0.747204, recon: 0.264461, id: 0.666529] time: 0:02:01.931049 \n",
      "[Epoch 0/200] [Batch 114/266] [D loss: 0.384032, acc:  40%] [G loss: 7.390393, adv: 0.574991, recon: 0.240305, id: 0.665329] time: 0:02:02.600499 \n",
      "[Epoch 0/200] [Batch 115/266] [D loss: 0.327503, acc:  43%] [G loss: 6.675506, adv: 0.507846, recon: 0.197729, id: 0.813417] time: 0:02:03.253977 \n",
      "[Epoch 0/200] [Batch 116/266] [D loss: 0.379796, acc:  43%] [G loss: 7.225586, adv: 0.560857, recon: 0.217600, id: 0.906865] time: 0:02:03.853818 \n",
      "[Epoch 0/200] [Batch 117/266] [D loss: 0.287697, acc:  52%] [G loss: 8.072680, adv: 0.695947, recon: 0.236946, id: 0.896232] time: 0:02:04.408603 \n",
      "[Epoch 0/200] [Batch 118/266] [D loss: 0.361924, acc:  49%] [G loss: 8.200281, adv: 0.668147, recon: 0.275819, id: 0.707033] time: 0:02:04.981412 \n",
      "[Epoch 0/200] [Batch 119/266] [D loss: 0.265554, acc:  63%] [G loss: 7.209681, adv: 0.672283, recon: 0.218735, id: 0.797364] time: 0:02:05.583387 \n",
      "[Epoch 0/200] [Batch 120/266] [D loss: 0.315218, acc:  56%] [G loss: 7.905721, adv: 0.737658, recon: 0.251111, id: 0.671914] time: 0:02:06.147889 \n",
      "[Epoch 0/200] [Batch 121/266] [D loss: 0.283863, acc:  52%] [G loss: 7.827193, adv: 0.823976, recon: 0.226721, id: 0.812990] time: 0:02:06.679746 \n",
      "[Epoch 0/200] [Batch 122/266] [D loss: 0.556188, acc:  32%] [G loss: 7.907355, adv: 0.802237, recon: 0.237161, id: 0.726266] time: 0:02:07.280630 \n",
      "[Epoch 0/200] [Batch 123/266] [D loss: 0.407818, acc:  54%] [G loss: 6.738199, adv: 0.530084, recon: 0.208964, id: 0.644316] time: 0:02:07.883225 \n",
      "[Epoch 0/200] [Batch 124/266] [D loss: 0.255708, acc:  67%] [G loss: 6.744810, adv: 0.688854, recon: 0.198982, id: 0.723097] time: 0:02:08.528487 \n",
      "[Epoch 0/200] [Batch 125/266] [D loss: 0.276305, acc:  58%] [G loss: 6.484827, adv: 0.581635, recon: 0.196641, id: 0.692557] time: 0:02:09.110735 \n",
      "[Epoch 0/200] [Batch 126/266] [D loss: 0.404037, acc:  35%] [G loss: 6.631384, adv: 0.438075, recon: 0.218881, id: 0.724214] time: 0:02:09.706049 \n",
      "[Epoch 0/200] [Batch 127/266] [D loss: 0.425960, acc:  34%] [G loss: 7.733126, adv: 0.481931, recon: 0.249455, id: 0.796207] time: 0:02:10.289945 \n",
      "[Epoch 0/200] [Batch 128/266] [D loss: 0.268170, acc:  52%] [G loss: 7.681585, adv: 0.617399, recon: 0.247511, id: 0.674394] time: 0:02:10.936739 \n",
      "[Epoch 0/200] [Batch 129/266] [D loss: 0.288291, acc:  52%] [G loss: 7.550644, adv: 0.611502, recon: 0.234583, id: 0.798876] time: 0:02:11.494608 \n",
      "[Epoch 0/200] [Batch 130/266] [D loss: 0.469275, acc:  25%] [G loss: 6.608791, adv: 0.389539, recon: 0.215676, id: 0.732476] time: 0:02:12.129316 \n",
      "[Epoch 0/200] [Batch 131/266] [D loss: 0.265317, acc:  56%] [G loss: 7.140079, adv: 0.585341, recon: 0.225680, id: 0.691511] time: 0:02:12.752052 \n",
      "[Epoch 0/200] [Batch 132/266] [D loss: 0.368092, acc:  33%] [G loss: 6.567534, adv: 0.479229, recon: 0.204657, id: 0.823008] time: 0:02:13.338372 \n",
      "[Epoch 0/200] [Batch 133/266] [D loss: 0.365259, acc:  39%] [G loss: 6.773903, adv: 0.606248, recon: 0.203687, id: 0.758270] time: 0:02:13.873814 \n",
      "[Epoch 0/200] [Batch 134/266] [D loss: 0.402316, acc:  37%] [G loss: 6.926238, adv: 0.507518, recon: 0.227347, id: 0.769308] time: 0:02:14.424575 \n",
      "[Epoch 0/200] [Batch 135/266] [D loss: 0.390371, acc:  37%] [G loss: 7.020875, adv: 0.467058, recon: 0.220590, id: 0.872241] time: 0:02:15.127903 \n",
      "[Epoch 0/200] [Batch 136/266] [D loss: 0.277645, acc:  53%] [G loss: 7.316562, adv: 0.670921, recon: 0.219097, id: 0.812120] time: 0:02:15.731341 \n",
      "[Epoch 0/200] [Batch 137/266] [D loss: 0.218315, acc:  67%] [G loss: 6.545346, adv: 0.648560, recon: 0.185815, id: 0.830948] time: 0:02:16.318711 \n",
      "[Epoch 0/200] [Batch 138/266] [D loss: 0.338938, acc:  44%] [G loss: 6.977627, adv: 0.550808, recon: 0.219982, id: 0.776999] time: 0:02:16.933017 \n",
      "[Epoch 0/200] [Batch 139/266] [D loss: 0.314162, acc:  46%] [G loss: 6.542572, adv: 0.632560, recon: 0.192517, id: 0.684632] time: 0:02:17.533009 \n",
      "[Epoch 0/200] [Batch 140/266] [D loss: 0.274069, acc:  55%] [G loss: 6.669417, adv: 0.674002, recon: 0.198804, id: 0.598760] time: 0:02:18.228434 \n",
      "[Epoch 0/200] [Batch 141/266] [D loss: 0.471308, acc:  33%] [G loss: 7.073262, adv: 0.682475, recon: 0.214897, id: 0.715736] time: 0:02:18.853812 \n",
      "[Epoch 0/200] [Batch 142/266] [D loss: 0.507563, acc:  34%] [G loss: 6.737472, adv: 0.542587, recon: 0.210162, id: 0.712317] time: 0:02:19.417956 \n",
      "[Epoch 0/200] [Batch 143/266] [D loss: 0.417679, acc:  40%] [G loss: 6.959581, adv: 0.467202, recon: 0.233390, id: 0.613788] time: 0:02:19.976483 \n",
      "[Epoch 0/200] [Batch 144/266] [D loss: 0.279949, acc:  62%] [G loss: 6.675568, adv: 0.651253, recon: 0.197465, id: 0.646259] time: 0:02:20.546824 \n",
      "[Epoch 0/200] [Batch 145/266] [D loss: 0.437838, acc:  38%] [G loss: 7.334832, adv: 0.654859, recon: 0.220845, id: 0.630881] time: 0:02:21.112642 \n",
      "[Epoch 0/200] [Batch 146/266] [D loss: 0.315793, acc:  53%] [G loss: 8.208505, adv: 0.748125, recon: 0.256484, id: 0.851075] time: 0:02:21.695994 \n",
      "[Epoch 0/200] [Batch 147/266] [D loss: 0.450656, acc:  60%] [G loss: 8.438855, adv: 0.834150, recon: 0.242229, id: 0.944722] time: 0:02:22.240202 \n",
      "[Epoch 0/200] [Batch 148/266] [D loss: 1.462133, acc:  18%] [G loss: 7.608619, adv: 0.988824, recon: 0.197038, id: 0.938778] time: 0:02:22.772178 \n",
      "[Epoch 0/200] [Batch 149/266] [D loss: 0.799450, acc:  32%] [G loss: 7.658442, adv: 1.140082, recon: 0.190864, id: 0.857313] time: 0:02:23.373915 \n",
      "[Epoch 0/200] [Batch 150/266] [D loss: 0.617871, acc:  41%] [G loss: 8.528155, adv: 0.934124, recon: 0.250345, id: 0.903397] time: 0:02:23.934095 \n",
      "[Epoch 0/200] [Batch 151/266] [D loss: 0.541848, acc:  52%] [G loss: 7.801791, adv: 0.634487, recon: 0.250084, id: 0.628379] time: 0:02:24.599591 \n",
      "[Epoch 0/200] [Batch 152/266] [D loss: 0.406107, acc:  42%] [G loss: 7.828507, adv: 0.468021, recon: 0.262360, id: 0.859794] time: 0:02:25.162548 \n",
      "[Epoch 0/200] [Batch 153/266] [D loss: 0.278796, acc:  57%] [G loss: 6.404661, adv: 0.620453, recon: 0.170685, id: 0.829336] time: 0:02:25.750403 \n",
      "[Epoch 0/200] [Batch 154/266] [D loss: 0.380085, acc:  39%] [G loss: 6.448378, adv: 0.493999, recon: 0.199954, id: 0.665293] time: 0:02:26.343128 \n",
      "[Epoch 0/200] [Batch 155/266] [D loss: 0.292233, acc:  55%] [G loss: 7.419080, adv: 0.678047, recon: 0.234227, id: 0.666165] time: 0:02:26.902965 \n",
      "[Epoch 0/200] [Batch 156/266] [D loss: 0.498273, acc:  35%] [G loss: 6.127751, adv: 0.427180, recon: 0.186594, id: 0.713656] time: 0:02:27.470411 \n",
      "[Epoch 0/200] [Batch 157/266] [D loss: 0.322420, acc:  45%] [G loss: 6.928647, adv: 0.546743, recon: 0.224723, id: 0.625455] time: 0:02:28.066963 \n",
      "[Epoch 0/200] [Batch 158/266] [D loss: 0.310783, acc:  51%] [G loss: 5.992635, adv: 0.610206, recon: 0.164643, id: 0.674670] time: 0:02:28.672738 \n",
      "[Epoch 0/200] [Batch 159/266] [D loss: 0.381740, acc:  38%] [G loss: 5.475999, adv: 0.442636, recon: 0.155711, id: 0.673571] time: 0:02:29.207857 \n",
      "[Epoch 0/200] [Batch 160/266] [D loss: 0.340478, acc:  34%] [G loss: 6.440369, adv: 0.477224, recon: 0.199323, id: 0.685122] time: 0:02:29.779815 \n",
      "[Epoch 0/200] [Batch 161/266] [D loss: 0.309864, acc:  51%] [G loss: 7.074802, adv: 0.545478, recon: 0.225489, id: 0.761205] time: 0:02:30.412051 \n",
      "[Epoch 0/200] [Batch 162/266] [D loss: 0.323621, acc:  45%] [G loss: 6.899660, adv: 0.625560, recon: 0.198794, id: 0.893355] time: 0:02:30.983626 \n",
      "[Epoch 0/200] [Batch 163/266] [D loss: 0.471752, acc:  28%] [G loss: 6.853873, adv: 0.556756, recon: 0.209420, id: 0.761034] time: 0:02:31.522840 \n",
      "[Epoch 0/200] [Batch 164/266] [D loss: 0.334733, acc:  45%] [G loss: 6.424857, adv: 0.563766, recon: 0.192136, id: 0.709182] time: 0:02:32.150306 \n",
      "[Epoch 0/200] [Batch 165/266] [D loss: 0.394235, acc:  29%] [G loss: 6.861222, adv: 0.515165, recon: 0.217651, id: 0.760719] time: 0:02:32.713082 \n",
      "[Epoch 0/200] [Batch 166/266] [D loss: 0.398501, acc:  31%] [G loss: 5.928650, adv: 0.450196, recon: 0.180006, id: 0.704302] time: 0:02:33.256858 \n",
      "[Epoch 0/200] [Batch 167/266] [D loss: 0.198209, acc:  67%] [G loss: 6.278375, adv: 0.778025, recon: 0.166463, id: 0.649846] time: 0:02:33.830901 \n",
      "[Epoch 0/200] [Batch 168/266] [D loss: 0.370522, acc:  38%] [G loss: 6.687761, adv: 0.466803, recon: 0.220313, id: 0.694809] time: 0:02:34.350976 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 169/266] [D loss: 0.233580, acc:  59%] [G loss: 6.799505, adv: 0.584661, recon: 0.212660, id: 0.716462] time: 0:02:34.873464 \n",
      "[Epoch 0/200] [Batch 170/266] [D loss: 0.237954, acc:  57%] [G loss: 7.201649, adv: 0.574346, recon: 0.218014, id: 0.928896] time: 0:02:35.505237 \n",
      "[Epoch 0/200] [Batch 171/266] [D loss: 0.391844, acc:  31%] [G loss: 6.772981, adv: 0.456665, recon: 0.208826, id: 0.722113] time: 0:02:36.075531 \n",
      "[Epoch 0/200] [Batch 172/266] [D loss: 0.353324, acc:  43%] [G loss: 6.092183, adv: 0.405900, recon: 0.183796, id: 0.823814] time: 0:02:36.625696 \n",
      "[Epoch 0/200] [Batch 173/266] [D loss: 0.324239, acc:  39%] [G loss: 6.474831, adv: 0.449843, recon: 0.201417, id: 0.778055] time: 0:02:37.201998 \n",
      "[Epoch 0/200] [Batch 174/266] [D loss: 0.343320, acc:  42%] [G loss: 6.773449, adv: 0.531767, recon: 0.215923, id: 0.729445] time: 0:02:37.720279 \n",
      "[Epoch 0/200] [Batch 175/266] [D loss: 0.282432, acc:  49%] [G loss: 6.498951, adv: 0.619570, recon: 0.194820, id: 0.612001] time: 0:02:38.239677 \n",
      "[Epoch 0/200] [Batch 176/266] [D loss: 0.314601, acc:  48%] [G loss: 6.030897, adv: 0.509917, recon: 0.178825, id: 0.708376] time: 0:02:38.828091 \n",
      "[Epoch 0/200] [Batch 177/266] [D loss: 0.291270, acc:  51%] [G loss: 7.723659, adv: 0.690846, recon: 0.242638, id: 0.618713] time: 0:02:39.436277 \n",
      "[Epoch 0/200] [Batch 178/266] [D loss: 0.259458, acc:  63%] [G loss: 6.225682, adv: 0.589415, recon: 0.176381, id: 0.712860] time: 0:02:39.988000 \n",
      "[Epoch 0/200] [Batch 179/266] [D loss: 0.308400, acc:  40%] [G loss: 6.537152, adv: 0.489972, recon: 0.206000, id: 0.798464] time: 0:02:40.609116 \n",
      "[Epoch 0/200] [Batch 180/266] [D loss: 0.339172, acc:  35%] [G loss: 6.447840, adv: 0.539519, recon: 0.196045, id: 0.638782] time: 0:02:41.197216 \n",
      "[Epoch 0/200] [Batch 181/266] [D loss: 0.303483, acc:  45%] [G loss: 6.113893, adv: 0.522687, recon: 0.184252, id: 0.676898] time: 0:02:41.764030 \n",
      "[Epoch 0/200] [Batch 182/266] [D loss: 0.268351, acc:  60%] [G loss: 7.398009, adv: 0.683417, recon: 0.218155, id: 0.790745] time: 0:02:42.293034 \n",
      "[Epoch 0/200] [Batch 183/266] [D loss: 0.371643, acc:  45%] [G loss: 6.514953, adv: 0.500490, recon: 0.195794, id: 0.863899] time: 0:02:42.899706 \n",
      "[Epoch 0/200] [Batch 184/266] [D loss: 0.192873, acc:  72%] [G loss: 7.457319, adv: 0.645313, recon: 0.215704, id: 1.006827] time: 0:02:43.489015 \n",
      "[Epoch 0/200] [Batch 185/266] [D loss: 0.341600, acc:  51%] [G loss: 7.451927, adv: 0.572174, recon: 0.239371, id: 0.697603] time: 0:02:44.066346 \n",
      "[Epoch 0/200] [Batch 186/266] [D loss: 0.340056, acc:  50%] [G loss: 5.921334, adv: 0.491979, recon: 0.158535, id: 0.873250] time: 0:02:44.686363 \n",
      "[Epoch 0/200] [Batch 187/266] [D loss: 0.309789, acc:  52%] [G loss: 6.410769, adv: 0.524805, recon: 0.195820, id: 0.731661] time: 0:02:45.265455 \n",
      "[Epoch 0/200] [Batch 188/266] [D loss: 0.298541, acc:  48%] [G loss: 7.116436, adv: 0.481226, recon: 0.237707, id: 0.678560] time: 0:02:45.794957 \n",
      "[Epoch 0/200] [Batch 189/266] [D loss: 0.370880, acc:  47%] [G loss: 6.888616, adv: 0.882963, recon: 0.188868, id: 0.732171] time: 0:02:46.378628 \n",
      "[Epoch 0/200] [Batch 190/266] [D loss: 0.360838, acc:  41%] [G loss: 6.176026, adv: 0.414678, recon: 0.192684, id: 0.696105] time: 0:02:46.885894 \n",
      "[Epoch 0/200] [Batch 191/266] [D loss: 0.389567, acc:  30%] [G loss: 7.120544, adv: 0.558709, recon: 0.225124, id: 0.689469] time: 0:02:47.506301 \n",
      "[Epoch 0/200] [Batch 192/266] [D loss: 0.300716, acc:  57%] [G loss: 6.297665, adv: 0.533578, recon: 0.192573, id: 0.729630] time: 0:02:48.039035 \n",
      "[Epoch 0/200] [Batch 193/266] [D loss: 0.283169, acc:  58%] [G loss: 6.859122, adv: 0.507586, recon: 0.221708, id: 0.801565] time: 0:02:48.595754 \n",
      "[Epoch 0/200] [Batch 194/266] [D loss: 0.362859, acc:  33%] [G loss: 6.041222, adv: 0.480503, recon: 0.186438, id: 0.806608] time: 0:02:49.181216 \n",
      "[Epoch 0/200] [Batch 195/266] [D loss: 0.331773, acc:  42%] [G loss: 8.064650, adv: 0.655616, recon: 0.258814, id: 0.729777] time: 0:02:49.758775 \n",
      "[Epoch 0/200] [Batch 196/266] [D loss: 0.309849, acc:  58%] [G loss: 7.019635, adv: 0.532442, recon: 0.218660, id: 0.875485] time: 0:02:50.341808 \n",
      "[Epoch 0/200] [Batch 197/266] [D loss: 0.356699, acc:  38%] [G loss: 6.945373, adv: 0.535039, recon: 0.222597, id: 0.665758] time: 0:02:50.930214 \n",
      "[Epoch 0/200] [Batch 198/266] [D loss: 0.317308, acc:  50%] [G loss: 7.028619, adv: 0.486393, recon: 0.221654, id: 0.774190] time: 0:02:51.509448 \n",
      "[Epoch 0/200] [Batch 199/266] [D loss: 0.297876, acc:  42%] [G loss: 6.356738, adv: 0.558132, recon: 0.184455, id: 0.839679] time: 0:02:52.099051 \n",
      "[Epoch 0/200] [Batch 200/266] [D loss: 0.263872, acc:  55%] [G loss: 6.780334, adv: 0.592930, recon: 0.202824, id: 0.720397] time: 0:02:52.693330 \n",
      "[Epoch 0/200] [Batch 201/266] [D loss: 0.335267, acc:  37%] [G loss: 6.181061, adv: 0.484952, recon: 0.198431, id: 0.626719] time: 0:02:53.594659 \n",
      "[Epoch 0/200] [Batch 202/266] [D loss: 0.296901, acc:  46%] [G loss: 5.947834, adv: 0.504444, recon: 0.185770, id: 0.622328] time: 0:02:54.182531 \n",
      "[Epoch 0/200] [Batch 203/266] [D loss: 0.348704, acc:  33%] [G loss: 6.393241, adv: 0.684232, recon: 0.187226, id: 0.600499] time: 0:02:54.698345 \n",
      "[Epoch 0/200] [Batch 204/266] [D loss: 0.349539, acc:  41%] [G loss: 6.004545, adv: 0.524675, recon: 0.181649, id: 0.717733] time: 0:02:55.254620 \n",
      "[Epoch 0/200] [Batch 205/266] [D loss: 0.286216, acc:  51%] [G loss: 6.290004, adv: 0.551530, recon: 0.190174, id: 0.690291] time: 0:02:55.835268 \n",
      "[Epoch 0/200] [Batch 206/266] [D loss: 0.362986, acc:  38%] [G loss: 6.197422, adv: 0.448871, recon: 0.197601, id: 0.669619] time: 0:02:56.427863 \n",
      "[Epoch 0/200] [Batch 207/266] [D loss: 0.363061, acc:  42%] [G loss: 5.439211, adv: 0.477522, recon: 0.159726, id: 0.663698] time: 0:02:57.077543 \n",
      "[Epoch 0/200] [Batch 208/266] [D loss: 0.313894, acc:  45%] [G loss: 5.894097, adv: 0.440756, recon: 0.182944, id: 0.699304] time: 0:02:57.640176 \n",
      "[Epoch 0/200] [Batch 209/266] [D loss: 0.311913, acc:  43%] [G loss: 5.929633, adv: 0.506949, recon: 0.180443, id: 0.631109] time: 0:02:58.228086 \n",
      "[Epoch 0/200] [Batch 210/266] [D loss: 0.265050, acc:  56%] [G loss: 6.593920, adv: 0.532567, recon: 0.197023, id: 0.755872] time: 0:02:58.804786 \n",
      "[Epoch 0/200] [Batch 211/266] [D loss: 0.301634, acc:  47%] [G loss: 6.652384, adv: 0.572954, recon: 0.203322, id: 0.651059] time: 0:02:59.313663 \n",
      "[Epoch 0/200] [Batch 212/266] [D loss: 0.329326, acc:  39%] [G loss: 5.544024, adv: 0.467651, recon: 0.164627, id: 0.619271] time: 0:02:59.912090 \n",
      "[Epoch 0/200] [Batch 213/266] [D loss: 0.319213, acc:  41%] [G loss: 7.058216, adv: 0.469463, recon: 0.230125, id: 0.720510] time: 0:03:00.569216 \n",
      "[Epoch 0/200] [Batch 214/266] [D loss: 0.313259, acc:  43%] [G loss: 5.946285, adv: 0.548120, recon: 0.170211, id: 0.739506] time: 0:03:01.167553 \n",
      "[Epoch 0/200] [Batch 215/266] [D loss: 0.337549, acc:  42%] [G loss: 5.708164, adv: 0.454187, recon: 0.164454, id: 0.769184] time: 0:03:01.770099 \n",
      "[Epoch 0/200] [Batch 216/266] [D loss: 0.296090, acc:  43%] [G loss: 6.313436, adv: 0.499019, recon: 0.186007, id: 0.761043] time: 0:03:02.348539 \n",
      "[Epoch 0/200] [Batch 217/266] [D loss: 0.204811, acc:  69%] [G loss: 6.654517, adv: 0.573375, recon: 0.201158, id: 0.684681] time: 0:03:02.877015 \n",
      "[Epoch 0/200] [Batch 218/266] [D loss: 0.304663, acc:  47%] [G loss: 6.856516, adv: 0.523860, recon: 0.219370, id: 0.644189] time: 0:03:03.449338 \n",
      "[Epoch 0/200] [Batch 219/266] [D loss: 0.223179, acc:  66%] [G loss: 5.771229, adv: 0.561807, recon: 0.164226, id: 0.649880] time: 0:03:04.017717 \n",
      "[Epoch 0/200] [Batch 220/266] [D loss: 0.372884, acc:  31%] [G loss: 6.283764, adv: 0.458675, recon: 0.197509, id: 0.672907] time: 0:03:04.626475 \n",
      "[Epoch 0/200] [Batch 221/266] [D loss: 0.233449, acc:  61%] [G loss: 6.451052, adv: 0.629717, recon: 0.191710, id: 0.693073] time: 0:03:05.212883 \n",
      "[Epoch 0/200] [Batch 222/266] [D loss: 0.354499, acc:  44%] [G loss: 6.340449, adv: 0.518995, recon: 0.193291, id: 0.705979] time: 0:03:05.766507 \n",
      "[Epoch 0/200] [Batch 223/266] [D loss: 0.303261, acc:  49%] [G loss: 6.518789, adv: 0.514340, recon: 0.190745, id: 0.926147] time: 0:03:06.322111 \n",
      "[Epoch 0/200] [Batch 224/266] [D loss: 0.217702, acc:  67%] [G loss: 6.804700, adv: 0.620889, recon: 0.197845, id: 0.758734] time: 0:03:06.974806 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 225/266] [D loss: 0.306989, acc:  56%] [G loss: 6.388684, adv: 0.466463, recon: 0.189470, id: 0.929585] time: 0:03:07.677929 \n",
      "[Epoch 0/200] [Batch 226/266] [D loss: 0.292966, acc:  51%] [G loss: 6.418468, adv: 0.670276, recon: 0.168857, id: 0.814681] time: 0:03:08.223922 \n",
      "[Epoch 0/200] [Batch 227/266] [D loss: 0.284335, acc:  54%] [G loss: 6.389474, adv: 0.538162, recon: 0.193008, id: 0.678753] time: 0:03:08.891239 \n",
      "[Epoch 0/200] [Batch 228/266] [D loss: 0.396095, acc:  37%] [G loss: 7.346576, adv: 0.971955, recon: 0.200828, id: 0.754101] time: 0:03:09.531936 \n",
      "[Epoch 0/200] [Batch 229/266] [D loss: 0.371985, acc:  39%] [G loss: 7.011521, adv: 0.407161, recon: 0.226487, id: 0.895204] time: 0:03:10.155216 \n",
      "[Epoch 0/200] [Batch 230/266] [D loss: 0.224104, acc:  62%] [G loss: 6.946828, adv: 0.609891, recon: 0.208690, id: 0.837061] time: 0:03:10.777204 \n",
      "[Epoch 0/200] [Batch 231/266] [D loss: 0.333096, acc:  52%] [G loss: 7.409560, adv: 0.617581, recon: 0.237218, id: 0.859911] time: 0:03:11.444469 \n",
      "[Epoch 0/200] [Batch 232/266] [D loss: 0.360414, acc:  43%] [G loss: 6.959141, adv: 0.470875, recon: 0.222015, id: 0.852662] time: 0:03:12.030907 \n",
      "[Epoch 0/200] [Batch 233/266] [D loss: 0.347652, acc:  36%] [G loss: 6.991206, adv: 0.531958, recon: 0.228237, id: 0.732540] time: 0:03:12.601815 \n",
      "[Epoch 0/200] [Batch 234/266] [D loss: 0.322035, acc:  48%] [G loss: 6.567736, adv: 0.455261, recon: 0.220387, id: 0.649971] time: 0:03:13.217136 \n",
      "[Epoch 0/200] [Batch 235/266] [D loss: 0.319129, acc:  37%] [G loss: 5.910470, adv: 0.477359, recon: 0.177334, id: 0.719163] time: 0:03:13.797275 \n",
      "[Epoch 0/200] [Batch 236/266] [D loss: 0.249212, acc:  58%] [G loss: 6.756119, adv: 0.555041, recon: 0.212820, id: 0.809047] time: 0:03:14.383639 \n",
      "[Epoch 0/200] [Batch 237/266] [D loss: 0.177774, acc:  74%] [G loss: 7.049515, adv: 0.735210, recon: 0.197720, id: 0.818309] time: 0:03:14.990714 \n",
      "[Epoch 0/200] [Batch 238/266] [D loss: 0.443563, acc:  28%] [G loss: 5.516992, adv: 0.323984, recon: 0.169689, id: 0.728811] time: 0:03:15.560959 \n",
      "[Epoch 0/200] [Batch 239/266] [D loss: 0.159535, acc:  79%] [G loss: 7.262610, adv: 0.876065, recon: 0.193274, id: 0.737994] time: 0:03:16.089762 \n",
      "[Epoch 0/200] [Batch 240/266] [D loss: 0.240113, acc:  74%] [G loss: 7.792833, adv: 0.835208, recon: 0.235705, id: 0.626594] time: 0:03:16.674926 \n",
      "[Epoch 0/200] [Batch 241/266] [D loss: 0.431595, acc:  40%] [G loss: 5.862686, adv: 0.429924, recon: 0.182641, id: 0.614311] time: 0:03:17.244750 \n",
      "[Epoch 0/200] [Batch 242/266] [D loss: 0.247687, acc:  59%] [G loss: 6.479378, adv: 0.526562, recon: 0.198802, id: 0.775295] time: 0:03:17.853015 \n",
      "[Epoch 0/200] [Batch 243/266] [D loss: 0.309424, acc:  40%] [G loss: 5.910479, adv: 0.550552, recon: 0.173866, id: 0.702047] time: 0:03:18.405261 \n",
      "[Epoch 0/200] [Batch 244/266] [D loss: 0.331227, acc:  39%] [G loss: 6.010766, adv: 0.478664, recon: 0.182876, id: 0.731011] time: 0:03:19.041203 \n",
      "[Epoch 0/200] [Batch 245/266] [D loss: 0.294759, acc:  49%] [G loss: 6.189647, adv: 0.496291, recon: 0.189023, id: 0.706413] time: 0:03:19.579244 \n",
      "[Epoch 0/200] [Batch 246/266] [D loss: 0.283585, acc:  51%] [G loss: 5.868150, adv: 0.536849, recon: 0.169622, id: 0.657007] time: 0:03:20.219893 \n",
      "[Epoch 0/200] [Batch 247/266] [D loss: 0.295604, acc:  52%] [G loss: 6.398617, adv: 0.677166, recon: 0.175742, id: 0.782070] time: 0:03:20.795710 \n",
      "[Epoch 0/200] [Batch 248/266] [D loss: 0.388513, acc:  45%] [G loss: 5.990489, adv: 0.472062, recon: 0.178185, id: 0.700887] time: 0:03:21.380859 \n",
      "[Epoch 0/200] [Batch 249/266] [D loss: 0.281765, acc:  56%] [G loss: 6.219114, adv: 0.589451, recon: 0.180414, id: 0.828124] time: 0:03:21.958649 \n",
      "[Epoch 0/200] [Batch 250/266] [D loss: 0.311733, acc:  52%] [G loss: 6.172218, adv: 0.530206, recon: 0.175263, id: 0.817275] time: 0:03:22.475793 \n",
      "[Epoch 0/200] [Batch 251/266] [D loss: 0.292680, acc:  51%] [G loss: 6.711730, adv: 0.502298, recon: 0.209959, id: 0.733040] time: 0:03:23.068276 \n",
      "[Epoch 0/200] [Batch 252/266] [D loss: 0.271134, acc:  60%] [G loss: 5.440966, adv: 0.688092, recon: 0.134524, id: 0.700955] time: 0:03:23.634086 \n",
      "[Epoch 0/200] [Batch 253/266] [D loss: 0.291667, acc:  61%] [G loss: 6.289199, adv: 0.533256, recon: 0.186225, id: 0.831058] time: 0:03:24.214102 \n",
      "[Epoch 0/200] [Batch 254/266] [D loss: 0.226330, acc:  67%] [G loss: 6.852333, adv: 0.672726, recon: 0.199055, id: 0.687584] time: 0:03:24.849081 \n",
      "[Epoch 0/200] [Batch 255/266] [D loss: 0.199303, acc:  71%] [G loss: 6.162102, adv: 0.598790, recon: 0.163888, id: 0.870339] time: 0:03:25.423953 \n",
      "[Epoch 0/200] [Batch 256/266] [D loss: 0.298802, acc:  53%] [G loss: 5.470848, adv: 0.515437, recon: 0.154399, id: 0.653078] time: 0:03:26.049813 \n",
      "[Epoch 0/200] [Batch 257/266] [D loss: 0.256219, acc:  58%] [G loss: 5.602238, adv: 0.498731, recon: 0.162582, id: 0.721502] time: 0:03:26.669815 \n",
      "[Epoch 0/200] [Batch 258/266] [D loss: 0.209806, acc:  66%] [G loss: 6.406862, adv: 0.587820, recon: 0.187816, id: 0.771408] time: 0:03:27.194272 \n",
      "[Epoch 0/200] [Batch 259/266] [D loss: 0.269065, acc:  55%] [G loss: 6.396005, adv: 0.540194, recon: 0.185046, id: 0.827869] time: 0:03:27.769644 \n",
      "[Epoch 0/200] [Batch 260/266] [D loss: 0.301314, acc:  47%] [G loss: 5.933478, adv: 0.497630, recon: 0.164609, id: 0.831154] time: 0:03:28.310423 \n",
      "[Epoch 0/200] [Batch 261/266] [D loss: 0.331030, acc:  46%] [G loss: 6.746183, adv: 0.497996, recon: 0.206513, id: 0.884896] time: 0:03:28.844914 \n",
      "[Epoch 0/200] [Batch 262/266] [D loss: 0.240539, acc:  61%] [G loss: 5.946092, adv: 0.540348, recon: 0.163960, id: 0.866695] time: 0:03:29.420767 \n",
      "[Epoch 0/200] [Batch 263/266] [D loss: 0.237651, acc:  56%] [G loss: 5.582623, adv: 0.550678, recon: 0.155277, id: 0.711192] time: 0:03:29.979645 \n",
      "[Epoch 0/200] [Batch 264/266] [D loss: 0.328366, acc:  44%] [G loss: 6.506387, adv: 0.626238, recon: 0.192696, id: 0.734984] time: 0:03:30.588657 \n",
      "[Epoch 1/200] [Batch 0/266] [D loss: 0.251568, acc:  57%] [G loss: 7.459016, adv: 0.597535, recon: 0.219208, id: 0.949994] time: 0:03:32.647921 \n",
      "[Epoch 1/200] [Batch 1/266] [D loss: 0.293032, acc:  54%] [G loss: 6.574972, adv: 0.528162, recon: 0.199200, id: 0.720438] time: 0:03:33.391323 \n",
      "[Epoch 1/200] [Batch 2/266] [D loss: 0.248011, acc:  63%] [G loss: 6.078496, adv: 0.577226, recon: 0.175262, id: 0.790462] time: 0:03:33.843522 \n",
      "[Epoch 1/200] [Batch 3/266] [D loss: 0.329519, acc:  39%] [G loss: 6.228762, adv: 0.606814, recon: 0.179846, id: 0.822207] time: 0:03:34.338214 \n",
      "[Epoch 1/200] [Batch 4/266] [D loss: 0.261601, acc:  56%] [G loss: 6.478550, adv: 0.591690, recon: 0.187460, id: 0.809597] time: 0:03:34.789354 \n",
      "[Epoch 1/200] [Batch 5/266] [D loss: 0.283717, acc:  56%] [G loss: 6.608894, adv: 0.533050, recon: 0.204228, id: 0.722112] time: 0:03:35.239500 \n",
      "[Epoch 1/200] [Batch 6/266] [D loss: 0.217573, acc:  71%] [G loss: 6.023202, adv: 0.657493, recon: 0.170559, id: 0.615395] time: 0:03:35.805353 \n",
      "[Epoch 1/200] [Batch 7/266] [D loss: 0.310785, acc:  60%] [G loss: 6.628966, adv: 0.621268, recon: 0.190800, id: 0.761759] time: 0:03:36.290449 \n",
      "[Epoch 1/200] [Batch 8/266] [D loss: 0.206898, acc:  69%] [G loss: 6.312142, adv: 0.649584, recon: 0.185702, id: 0.659715] time: 0:03:36.787419 \n",
      "[Epoch 1/200] [Batch 9/266] [D loss: 0.376821, acc:  39%] [G loss: 6.182754, adv: 0.705275, recon: 0.167250, id: 0.722999] time: 0:03:37.252235 \n",
      "[Epoch 1/200] [Batch 10/266] [D loss: 0.307858, acc:  48%] [G loss: 5.902438, adv: 0.782679, recon: 0.149089, id: 0.696811] time: 0:03:37.712442 \n",
      "[Epoch 1/200] [Batch 11/266] [D loss: 0.273562, acc:  62%] [G loss: 5.434123, adv: 0.574441, recon: 0.152437, id: 0.629288] time: 0:03:38.162913 \n",
      "[Epoch 1/200] [Batch 12/266] [D loss: 0.280700, acc:  57%] [G loss: 5.802208, adv: 0.658645, recon: 0.158065, id: 0.669383] time: 0:03:38.616659 \n",
      "[Epoch 1/200] [Batch 13/266] [D loss: 0.291659, acc:  54%] [G loss: 5.417510, adv: 0.536688, recon: 0.154874, id: 0.688102] time: 0:03:39.071449 \n",
      "[Epoch 1/200] [Batch 14/266] [D loss: 0.368520, acc:  41%] [G loss: 6.118973, adv: 0.498318, recon: 0.184648, id: 0.743966] time: 0:03:39.525279 \n",
      "[Epoch 1/200] [Batch 15/266] [D loss: 0.400627, acc:  43%] [G loss: 6.057062, adv: 0.659960, recon: 0.162539, id: 0.731754] time: 0:03:39.975775 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 16/266] [D loss: 0.473441, acc:  34%] [G loss: 7.209082, adv: 0.844408, recon: 0.187682, id: 0.962021] time: 0:03:40.482783 \n",
      "[Epoch 1/200] [Batch 17/266] [D loss: 0.421409, acc:  49%] [G loss: 6.951410, adv: 0.657262, recon: 0.211890, id: 0.722149] time: 0:03:40.957040 \n",
      "[Epoch 1/200] [Batch 18/266] [D loss: 0.305039, acc:  53%] [G loss: 5.663549, adv: 0.623479, recon: 0.147195, id: 0.802257] time: 0:03:41.456859 \n",
      "[Epoch 1/200] [Batch 19/266] [D loss: 0.285255, acc:  56%] [G loss: 5.943035, adv: 0.477244, recon: 0.175166, id: 0.766786] time: 0:03:41.942650 \n",
      "[Epoch 1/200] [Batch 20/266] [D loss: 0.262202, acc:  58%] [G loss: 7.012145, adv: 0.466845, recon: 0.217265, id: 0.851424] time: 0:03:42.395301 \n",
      "[Epoch 1/200] [Batch 21/266] [D loss: 0.270160, acc:  55%] [G loss: 6.804480, adv: 0.594135, recon: 0.210604, id: 0.635742] time: 0:03:42.851298 \n",
      "[Epoch 1/200] [Batch 22/266] [D loss: 0.226740, acc:  68%] [G loss: 6.023985, adv: 0.644710, recon: 0.164507, id: 0.741095] time: 0:03:43.302541 \n",
      "[Epoch 1/200] [Batch 23/266] [D loss: 0.233270, acc:  63%] [G loss: 6.575332, adv: 0.540320, recon: 0.195170, id: 0.703849] time: 0:03:43.758604 \n",
      "[Epoch 1/200] [Batch 24/266] [D loss: 0.195043, acc:  71%] [G loss: 6.108181, adv: 0.598506, recon: 0.168869, id: 0.695107] time: 0:03:44.331758 \n",
      "[Epoch 1/200] [Batch 25/266] [D loss: 0.195130, acc:  73%] [G loss: 6.342815, adv: 0.671847, recon: 0.180232, id: 0.592379] time: 0:03:44.812024 \n",
      "[Epoch 1/200] [Batch 26/266] [D loss: 0.330889, acc:  41%] [G loss: 6.382812, adv: 0.450206, recon: 0.192635, id: 0.803245] time: 0:03:45.320502 \n",
      "[Epoch 1/200] [Batch 27/266] [D loss: 0.320438, acc:  45%] [G loss: 5.847720, adv: 0.610116, recon: 0.164264, id: 0.624596] time: 0:03:45.776111 \n",
      "[Epoch 1/200] [Batch 28/266] [D loss: 0.289930, acc:  50%] [G loss: 6.276255, adv: 0.609748, recon: 0.186110, id: 0.747653] time: 0:03:46.256252 \n",
      "[Epoch 1/200] [Batch 29/266] [D loss: 0.170605, acc:  70%] [G loss: 6.507080, adv: 0.706003, recon: 0.179213, id: 0.762985] time: 0:03:46.758184 \n",
      "[Epoch 1/200] [Batch 30/266] [D loss: 0.256902, acc:  61%] [G loss: 5.856718, adv: 0.557431, recon: 0.168342, id: 0.592877] time: 0:03:47.234897 \n",
      "[Epoch 1/200] [Batch 31/266] [D loss: 0.326083, acc:  43%] [G loss: 6.233785, adv: 0.549900, recon: 0.178821, id: 0.619882] time: 0:03:47.707312 \n",
      "[Epoch 1/200] [Batch 32/266] [D loss: 0.241634, acc:  63%] [G loss: 5.897872, adv: 0.555823, recon: 0.161092, id: 0.692506] time: 0:03:48.168033 \n",
      "[Epoch 1/200] [Batch 33/266] [D loss: 0.345163, acc:  47%] [G loss: 6.088693, adv: 0.450060, recon: 0.183336, id: 0.743819] time: 0:03:48.666207 \n",
      "[Epoch 1/200] [Batch 34/266] [D loss: 0.312367, acc:  47%] [G loss: 6.287342, adv: 0.611082, recon: 0.184267, id: 0.669114] time: 0:03:49.119714 \n",
      "[Epoch 1/200] [Batch 35/266] [D loss: 0.313470, acc:  48%] [G loss: 5.285692, adv: 0.527815, recon: 0.147321, id: 0.665411] time: 0:03:49.619511 \n",
      "[Epoch 1/200] [Batch 36/266] [D loss: 0.267336, acc:  51%] [G loss: 6.109806, adv: 0.556508, recon: 0.175959, id: 0.853173] time: 0:03:50.073638 \n",
      "[Epoch 1/200] [Batch 37/266] [D loss: 0.278853, acc:  52%] [G loss: 5.668735, adv: 0.477869, recon: 0.170075, id: 0.711627] time: 0:03:50.525862 \n",
      "[Epoch 1/200] [Batch 38/266] [D loss: 0.247193, acc:  55%] [G loss: 5.603478, adv: 0.534957, recon: 0.157517, id: 0.745240] time: 0:03:50.980025 \n",
      "[Epoch 1/200] [Batch 39/266] [D loss: 0.294047, acc:  47%] [G loss: 5.268547, adv: 0.461931, recon: 0.151582, id: 0.716120] time: 0:03:51.429005 \n",
      "[Epoch 1/200] [Batch 40/266] [D loss: 0.190658, acc:  72%] [G loss: 5.489462, adv: 0.552011, recon: 0.156201, id: 0.647196] time: 0:03:51.882866 \n",
      "[Epoch 1/200] [Batch 41/266] [D loss: 0.273857, acc:  53%] [G loss: 5.692964, adv: 0.605941, recon: 0.157442, id: 0.717930] time: 0:03:52.406930 \n",
      "[Epoch 1/200] [Batch 42/266] [D loss: 0.259744, acc:  57%] [G loss: 6.394224, adv: 0.533284, recon: 0.193292, id: 0.690223] time: 0:03:52.920548 \n",
      "[Epoch 1/200] [Batch 43/266] [D loss: 0.287391, acc:  49%] [G loss: 5.291876, adv: 0.476669, recon: 0.149214, id: 0.642209] time: 0:03:53.380217 \n",
      "[Epoch 1/200] [Batch 44/266] [D loss: 0.291201, acc:  50%] [G loss: 6.176730, adv: 0.718365, recon: 0.164368, id: 0.831169] time: 0:03:53.854606 \n",
      "[Epoch 1/200] [Batch 45/266] [D loss: 0.294575, acc:  57%] [G loss: 5.687160, adv: 0.548126, recon: 0.162209, id: 0.615282] time: 0:03:54.300729 \n",
      "[Epoch 1/200] [Batch 46/266] [D loss: 0.277193, acc:  51%] [G loss: 5.773602, adv: 0.463551, recon: 0.169732, id: 0.662456] time: 0:03:54.750637 \n",
      "[Epoch 1/200] [Batch 47/266] [D loss: 0.279061, acc:  56%] [G loss: 6.233840, adv: 0.642364, recon: 0.173271, id: 0.649544] time: 0:03:55.201078 \n",
      "[Epoch 1/200] [Batch 48/266] [D loss: 0.175367, acc:  75%] [G loss: 6.423572, adv: 0.732914, recon: 0.169729, id: 0.713044] time: 0:03:55.672751 \n",
      "[Epoch 1/200] [Batch 49/266] [D loss: 0.357939, acc:  47%] [G loss: 6.272496, adv: 0.437646, recon: 0.189563, id: 0.663901] time: 0:03:56.125941 \n",
      "[Epoch 1/200] [Batch 50/266] [D loss: 0.207813, acc:  70%] [G loss: 6.483373, adv: 0.643680, recon: 0.186097, id: 0.674700] time: 0:03:56.706725 \n",
      "[Epoch 1/200] [Batch 51/266] [D loss: 0.339526, acc:  40%] [G loss: 5.906958, adv: 0.432353, recon: 0.175943, id: 0.737055] time: 0:03:57.156006 \n",
      "[Epoch 1/200] [Batch 52/266] [D loss: 0.178381, acc:  74%] [G loss: 6.659644, adv: 0.648744, recon: 0.180130, id: 0.890344] time: 0:03:57.609023 \n",
      "[Epoch 1/200] [Batch 53/266] [D loss: 0.304703, acc:  52%] [G loss: 5.771731, adv: 0.463512, recon: 0.163336, id: 0.813027] time: 0:03:58.059456 \n",
      "[Epoch 1/200] [Batch 54/266] [D loss: 0.167400, acc:  77%] [G loss: 6.199711, adv: 0.615340, recon: 0.173382, id: 0.835439] time: 0:03:58.539223 \n",
      "[Epoch 1/200] [Batch 55/266] [D loss: 0.151457, acc:  78%] [G loss: 5.838053, adv: 0.593658, recon: 0.161495, id: 0.689562] time: 0:03:59.023771 \n",
      "[Epoch 1/200] [Batch 56/266] [D loss: 0.320966, acc:  54%] [G loss: 6.282396, adv: 0.607971, recon: 0.184061, id: 0.730937] time: 0:03:59.475814 \n",
      "[Epoch 1/200] [Batch 57/266] [D loss: 0.242584, acc:  58%] [G loss: 5.510733, adv: 0.518169, recon: 0.151719, id: 0.889949] time: 0:03:59.925990 \n",
      "[Epoch 1/200] [Batch 58/266] [D loss: 0.195670, acc:  70%] [G loss: 5.238842, adv: 0.528261, recon: 0.144026, id: 0.780737] time: 0:04:00.378338 \n",
      "[Epoch 1/200] [Batch 59/266] [D loss: 0.306756, acc:  51%] [G loss: 6.561499, adv: 0.486501, recon: 0.207532, id: 0.705613] time: 0:04:00.829907 \n",
      "[Epoch 1/200] [Batch 60/266] [D loss: 0.366581, acc:  32%] [G loss: 5.528831, adv: 0.546089, recon: 0.155229, id: 0.680395] time: 0:04:01.371287 \n",
      "[Epoch 1/200] [Batch 61/266] [D loss: 0.282438, acc:  53%] [G loss: 5.884860, adv: 0.531943, recon: 0.170350, id: 0.685909] time: 0:04:01.822929 \n",
      "[Epoch 1/200] [Batch 62/266] [D loss: 0.285462, acc:  50%] [G loss: 6.241090, adv: 0.503726, recon: 0.192462, id: 0.705979] time: 0:04:02.328567 \n",
      "[Epoch 1/200] [Batch 63/266] [D loss: 0.211115, acc:  67%] [G loss: 6.085998, adv: 0.659331, recon: 0.168246, id: 0.603424] time: 0:04:02.808429 \n",
      "[Epoch 1/200] [Batch 64/266] [D loss: 0.227852, acc:  60%] [G loss: 6.021493, adv: 0.593239, recon: 0.174979, id: 0.680797] time: 0:04:03.260018 \n",
      "[Epoch 1/200] [Batch 65/266] [D loss: 0.210643, acc:  65%] [G loss: 6.110543, adv: 0.527866, recon: 0.180820, id: 0.727986] time: 0:04:03.738384 \n",
      "[Epoch 1/200] [Batch 66/266] [D loss: 0.184068, acc:  69%] [G loss: 5.651756, adv: 0.611982, recon: 0.153292, id: 0.674212] time: 0:04:04.210720 \n",
      "[Epoch 1/200] [Batch 67/266] [D loss: 0.332339, acc:  44%] [G loss: 5.597594, adv: 0.478432, recon: 0.165806, id: 0.563349] time: 0:04:04.662015 \n",
      "[Epoch 1/200] [Batch 68/266] [D loss: 0.304588, acc:  47%] [G loss: 6.693880, adv: 0.475389, recon: 0.204923, id: 0.813278] time: 0:04:05.118675 \n",
      "[Epoch 1/200] [Batch 69/266] [D loss: 0.209221, acc:  71%] [G loss: 5.715861, adv: 0.587176, recon: 0.158904, id: 0.694693] time: 0:04:05.571827 \n",
      "[Epoch 1/200] [Batch 70/266] [D loss: 0.230359, acc:  63%] [G loss: 5.511760, adv: 0.560689, recon: 0.151990, id: 0.587200] time: 0:04:06.022589 \n",
      "[Epoch 1/200] [Batch 71/266] [D loss: 0.262379, acc:  51%] [G loss: 5.513301, adv: 0.486766, recon: 0.156443, id: 0.680529] time: 0:04:06.475554 \n",
      "[Epoch 1/200] [Batch 72/266] [D loss: 0.186415, acc:  76%] [G loss: 6.610628, adv: 0.653250, recon: 0.188868, id: 0.756796] time: 0:04:07.026653 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 73/266] [D loss: 0.345324, acc:  47%] [G loss: 5.507188, adv: 0.403837, recon: 0.154481, id: 0.838285] time: 0:04:07.475875 \n",
      "[Epoch 1/200] [Batch 74/266] [D loss: 0.205974, acc:  68%] [G loss: 6.125255, adv: 0.584081, recon: 0.172625, id: 0.773468] time: 0:04:07.929253 \n",
      "[Epoch 1/200] [Batch 75/266] [D loss: 0.191654, acc:  70%] [G loss: 6.016517, adv: 0.636057, recon: 0.166977, id: 0.730344] time: 0:04:08.407027 \n",
      "[Epoch 1/200] [Batch 76/266] [D loss: 0.308805, acc:  60%] [G loss: 6.559493, adv: 0.722401, recon: 0.183535, id: 0.643570] time: 0:04:08.863157 \n",
      "[Epoch 1/200] [Batch 77/266] [D loss: 0.293371, acc:  56%] [G loss: 6.423879, adv: 0.575094, recon: 0.199370, id: 0.656420] time: 0:04:09.313641 \n",
      "[Epoch 1/200] [Batch 78/266] [D loss: 0.285030, acc:  56%] [G loss: 5.893487, adv: 0.508553, recon: 0.168302, id: 0.644010] time: 0:04:09.765588 \n",
      "[Epoch 1/200] [Batch 79/266] [D loss: 0.351949, acc:  45%] [G loss: 6.119298, adv: 0.565930, recon: 0.173994, id: 0.637361] time: 0:04:10.224836 \n",
      "[Epoch 1/200] [Batch 80/266] [D loss: 0.228325, acc:  62%] [G loss: 6.062943, adv: 0.637932, recon: 0.165300, id: 0.710657] time: 0:04:10.674254 \n",
      "[Epoch 1/200] [Batch 81/266] [D loss: 0.198652, acc:  76%] [G loss: 6.934429, adv: 0.772461, recon: 0.190379, id: 0.711665] time: 0:04:11.132500 \n",
      "[Epoch 1/200] [Batch 82/266] [D loss: 0.203974, acc:  80%] [G loss: 7.330361, adv: 0.805936, recon: 0.201487, id: 0.804047] time: 0:04:11.616525 \n",
      "[Epoch 1/200] [Batch 83/266] [D loss: 0.377182, acc:  37%] [G loss: 5.589181, adv: 0.489874, recon: 0.160121, id: 0.655688] time: 0:04:12.087935 \n",
      "[Epoch 1/200] [Batch 84/266] [D loss: 0.317023, acc:  64%] [G loss: 6.150958, adv: 0.689776, recon: 0.169159, id: 0.726429] time: 0:04:12.586871 \n",
      "[Epoch 1/200] [Batch 85/266] [D loss: 0.356395, acc:  39%] [G loss: 6.751889, adv: 0.481320, recon: 0.207362, id: 0.762100] time: 0:04:13.043675 \n",
      "[Epoch 1/200] [Batch 86/266] [D loss: 0.333224, acc:  51%] [G loss: 6.273077, adv: 0.580344, recon: 0.182929, id: 0.702765] time: 0:04:13.507389 \n",
      "[Epoch 1/200] [Batch 87/266] [D loss: 0.300082, acc:  50%] [G loss: 6.868839, adv: 0.501198, recon: 0.211829, id: 0.794485] time: 0:04:13.977552 \n",
      "[Epoch 1/200] [Batch 88/266] [D loss: 0.264304, acc:  68%] [G loss: 6.098993, adv: 0.656219, recon: 0.170373, id: 0.589152] time: 0:04:14.424468 \n",
      "[Epoch 1/200] [Batch 89/266] [D loss: 0.345289, acc:  41%] [G loss: 5.912248, adv: 0.533176, recon: 0.169394, id: 0.749519] time: 0:04:14.924338 \n",
      "[Epoch 1/200] [Batch 90/266] [D loss: 0.342392, acc:  48%] [G loss: 5.288147, adv: 0.453663, recon: 0.149824, id: 0.588081] time: 0:04:15.375001 \n",
      "[Epoch 1/200] [Batch 91/266] [D loss: 0.266018, acc:  59%] [G loss: 5.575617, adv: 0.534151, recon: 0.154712, id: 0.654940] time: 0:04:15.858097 \n",
      "[Epoch 1/200] [Batch 92/266] [D loss: 0.298098, acc:  49%] [G loss: 5.631866, adv: 0.516707, recon: 0.163136, id: 0.640778] time: 0:04:16.322561 \n",
      "[Epoch 1/200] [Batch 93/266] [D loss: 0.167106, acc:  77%] [G loss: 6.175254, adv: 0.673568, recon: 0.170696, id: 0.730238] time: 0:04:16.775017 \n",
      "[Epoch 1/200] [Batch 94/266] [D loss: 0.222504, acc:  68%] [G loss: 5.758582, adv: 0.501220, recon: 0.158388, id: 0.768656] time: 0:04:17.268730 \n",
      "[Epoch 1/200] [Batch 95/266] [D loss: 0.184210, acc:  73%] [G loss: 5.734826, adv: 0.544563, recon: 0.158611, id: 0.669599] time: 0:04:17.715307 \n",
      "[Epoch 1/200] [Batch 96/266] [D loss: 0.289986, acc:  45%] [G loss: 5.343963, adv: 0.471420, recon: 0.148327, id: 0.670672] time: 0:04:18.174605 \n",
      "[Epoch 1/200] [Batch 97/266] [D loss: 0.295029, acc:  47%] [G loss: 5.831986, adv: 0.551207, recon: 0.173650, id: 0.651557] time: 0:04:18.632462 \n",
      "[Epoch 1/200] [Batch 98/266] [D loss: 0.207364, acc:  67%] [G loss: 5.628001, adv: 0.696640, recon: 0.146828, id: 0.666090] time: 0:04:19.079235 \n",
      "[Epoch 1/200] [Batch 99/266] [D loss: 0.227963, acc:  69%] [G loss: 5.794678, adv: 0.483750, recon: 0.161834, id: 0.791152] time: 0:04:19.592477 \n",
      "[Epoch 1/200] [Batch 100/266] [D loss: 0.192875, acc:  74%] [G loss: 6.262383, adv: 0.575321, recon: 0.180868, id: 0.782941] time: 0:04:20.090682 \n",
      "[Epoch 1/200] [Batch 101/266] [D loss: 0.333845, acc:  40%] [G loss: 6.249081, adv: 0.493549, recon: 0.182838, id: 0.784876] time: 0:04:20.617062 \n",
      "[Epoch 1/200] [Batch 102/266] [D loss: 0.298109, acc:  52%] [G loss: 5.937879, adv: 0.509000, recon: 0.180081, id: 0.648989] time: 0:04:21.093334 \n",
      "[Epoch 1/200] [Batch 103/266] [D loss: 0.256567, acc:  57%] [G loss: 5.871492, adv: 0.567246, recon: 0.164476, id: 0.697186] time: 0:04:21.546558 \n",
      "[Epoch 1/200] [Batch 104/266] [D loss: 0.316392, acc:  45%] [G loss: 6.413692, adv: 0.589257, recon: 0.181586, id: 0.855692] time: 0:04:22.036331 \n",
      "[Epoch 1/200] [Batch 105/266] [D loss: 0.235490, acc:  66%] [G loss: 6.275542, adv: 0.590463, recon: 0.180999, id: 0.741368] time: 0:04:22.490535 \n",
      "[Epoch 1/200] [Batch 106/266] [D loss: 0.249605, acc:  57%] [G loss: 5.726834, adv: 0.534432, recon: 0.156301, id: 0.819157] time: 0:04:22.940158 \n",
      "[Epoch 1/200] [Batch 107/266] [D loss: 0.275507, acc:  56%] [G loss: 5.482761, adv: 0.555283, recon: 0.155236, id: 0.653972] time: 0:04:23.452439 \n",
      "[Epoch 1/200] [Batch 108/266] [D loss: 0.225669, acc:  67%] [G loss: 5.126637, adv: 0.560061, recon: 0.140142, id: 0.592456] time: 0:04:23.945838 \n",
      "[Epoch 1/200] [Batch 109/266] [D loss: 0.256051, acc:  59%] [G loss: 5.184035, adv: 0.501202, recon: 0.138624, id: 0.771082] time: 0:04:24.409788 \n",
      "[Epoch 1/200] [Batch 110/266] [D loss: 0.248134, acc:  58%] [G loss: 5.533410, adv: 0.535008, recon: 0.150450, id: 0.743439] time: 0:04:24.882821 \n",
      "[Epoch 1/200] [Batch 111/266] [D loss: 0.298520, acc:  55%] [G loss: 5.429982, adv: 0.596762, recon: 0.136024, id: 0.717247] time: 0:04:25.334910 \n",
      "[Epoch 1/200] [Batch 112/266] [D loss: 0.325418, acc:  52%] [G loss: 5.958406, adv: 0.604619, recon: 0.159107, id: 0.697685] time: 0:04:25.788111 \n",
      "[Epoch 1/200] [Batch 113/266] [D loss: 0.251927, acc:  59%] [G loss: 5.966805, adv: 0.573795, recon: 0.174875, id: 0.645834] time: 0:04:26.252306 \n",
      "[Epoch 1/200] [Batch 114/266] [D loss: 0.215876, acc:  64%] [G loss: 6.596603, adv: 0.584683, recon: 0.196248, id: 0.646065] time: 0:04:26.704902 \n",
      "[Epoch 1/200] [Batch 115/266] [D loss: 0.268114, acc:  55%] [G loss: 5.574245, adv: 0.491175, recon: 0.161220, id: 0.674621] time: 0:04:27.177394 \n",
      "[Epoch 1/200] [Batch 116/266] [D loss: 0.204229, acc:  70%] [G loss: 5.381331, adv: 0.641988, recon: 0.133810, id: 0.687187] time: 0:04:27.649175 \n",
      "[Epoch 1/200] [Batch 117/266] [D loss: 0.308398, acc:  45%] [G loss: 5.587937, adv: 0.478084, recon: 0.162839, id: 0.715106] time: 0:04:28.167342 \n",
      "[Epoch 1/200] [Batch 118/266] [D loss: 0.374224, acc:  38%] [G loss: 5.347715, adv: 0.449223, recon: 0.150201, id: 0.743450] time: 0:04:28.621978 \n",
      "[Epoch 1/200] [Batch 119/266] [D loss: 0.321829, acc:  48%] [G loss: 7.453356, adv: 0.635048, recon: 0.219416, id: 0.940996] time: 0:04:29.091174 \n",
      "[Epoch 1/200] [Batch 120/266] [D loss: 0.384554, acc:  41%] [G loss: 6.598913, adv: 0.716820, recon: 0.184992, id: 0.817736] time: 0:04:29.545541 \n",
      "[Epoch 1/200] [Batch 121/266] [D loss: 0.251467, acc:  57%] [G loss: 6.074014, adv: 0.587589, recon: 0.175100, id: 0.712464] time: 0:04:30.030221 \n",
      "[Epoch 1/200] [Batch 122/266] [D loss: 0.243729, acc:  64%] [G loss: 6.239872, adv: 0.674728, recon: 0.172435, id: 0.844358] time: 0:04:30.525956 \n",
      "[Epoch 1/200] [Batch 123/266] [D loss: 0.166345, acc:  75%] [G loss: 6.087592, adv: 0.609719, recon: 0.158463, id: 0.931733] time: 0:04:30.982375 \n",
      "[Epoch 1/200] [Batch 124/266] [D loss: 0.196407, acc:  73%] [G loss: 6.024477, adv: 0.577256, recon: 0.159138, id: 0.904044] time: 0:04:31.436570 \n",
      "[Epoch 1/200] [Batch 125/266] [D loss: 0.314183, acc:  45%] [G loss: 5.268543, adv: 0.570173, recon: 0.133140, id: 0.803523] time: 0:04:31.921305 \n",
      "[Epoch 1/200] [Batch 126/266] [D loss: 0.257744, acc:  62%] [G loss: 5.989443, adv: 0.569888, recon: 0.168809, id: 0.744514] time: 0:04:32.373349 \n",
      "[Epoch 1/200] [Batch 127/266] [D loss: 0.269043, acc:  57%] [G loss: 6.268789, adv: 0.726047, recon: 0.162918, id: 0.778463] time: 0:04:32.850383 \n",
      "[Epoch 1/200] [Batch 128/266] [D loss: 0.323956, acc:  53%] [G loss: 6.193588, adv: 0.492240, recon: 0.186037, id: 0.696796] time: 0:04:33.307607 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 129/266] [D loss: 0.219477, acc:  67%] [G loss: 6.089465, adv: 0.534953, recon: 0.175078, id: 0.810146] time: 0:04:33.773426 \n",
      "[Epoch 1/200] [Batch 130/266] [D loss: 0.234549, acc:  59%] [G loss: 5.983857, adv: 0.491003, recon: 0.172207, id: 0.767160] time: 0:04:34.275435 \n",
      "[Epoch 1/200] [Batch 131/266] [D loss: 0.275614, acc:  53%] [G loss: 6.344265, adv: 0.537466, recon: 0.187199, id: 0.800368] time: 0:04:34.732789 \n",
      "[Epoch 1/200] [Batch 132/266] [D loss: 0.318041, acc:  49%] [G loss: 5.889601, adv: 0.699783, recon: 0.152286, id: 0.799935] time: 0:04:35.182811 \n",
      "[Epoch 1/200] [Batch 133/266] [D loss: 0.317884, acc:  50%] [G loss: 6.894434, adv: 0.498777, recon: 0.203305, id: 0.932101] time: 0:04:35.682918 \n",
      "[Epoch 1/200] [Batch 134/266] [D loss: 0.283821, acc:  53%] [G loss: 5.165305, adv: 0.487097, recon: 0.138716, id: 0.658215] time: 0:04:36.179634 \n",
      "[Epoch 1/200] [Batch 135/266] [D loss: 0.291153, acc:  49%] [G loss: 5.568650, adv: 0.469085, recon: 0.161783, id: 0.626558] time: 0:04:36.636350 \n",
      "[Epoch 1/200] [Batch 136/266] [D loss: 0.204556, acc:  65%] [G loss: 5.263781, adv: 0.653212, recon: 0.127107, id: 0.634366] time: 0:04:37.123253 \n",
      "[Epoch 1/200] [Batch 137/266] [D loss: 0.313810, acc:  41%] [G loss: 6.062116, adv: 0.446119, recon: 0.177077, id: 0.755026] time: 0:04:37.598921 \n",
      "[Epoch 1/200] [Batch 138/266] [D loss: 0.290365, acc:  47%] [G loss: 5.796762, adv: 0.470892, recon: 0.177449, id: 0.653123] time: 0:04:38.121017 \n",
      "[Epoch 1/200] [Batch 139/266] [D loss: 0.213496, acc:  70%] [G loss: 6.016273, adv: 0.571483, recon: 0.176052, id: 0.673401] time: 0:04:38.601655 \n",
      "[Epoch 1/200] [Batch 140/266] [D loss: 0.266358, acc:  55%] [G loss: 6.580131, adv: 0.591165, recon: 0.197126, id: 0.731446] time: 0:04:39.058380 \n",
      "[Epoch 1/200] [Batch 141/266] [D loss: 0.356651, acc:  39%] [G loss: 5.570417, adv: 0.493536, recon: 0.155982, id: 0.726683] time: 0:04:39.515984 \n",
      "[Epoch 1/200] [Batch 142/266] [D loss: 0.311218, acc:  55%] [G loss: 5.595139, adv: 0.611618, recon: 0.155682, id: 0.667816] time: 0:04:39.969326 \n",
      "[Epoch 1/200] [Batch 143/266] [D loss: 0.349920, acc:  48%] [G loss: 5.528174, adv: 0.498517, recon: 0.155637, id: 0.699606] time: 0:04:40.423272 \n",
      "[Epoch 1/200] [Batch 144/266] [D loss: 0.239086, acc:  65%] [G loss: 5.852293, adv: 0.656050, recon: 0.166183, id: 0.564399] time: 0:04:40.876965 \n",
      "[Epoch 1/200] [Batch 145/266] [D loss: 0.282790, acc:  57%] [G loss: 6.138649, adv: 0.447148, recon: 0.189599, id: 0.728915] time: 0:04:41.336208 \n",
      "[Epoch 1/200] [Batch 146/266] [D loss: 0.228520, acc:  63%] [G loss: 5.117707, adv: 0.474789, recon: 0.143519, id: 0.627067] time: 0:04:41.824916 \n",
      "[Epoch 1/200] [Batch 147/266] [D loss: 0.219475, acc:  62%] [G loss: 6.820411, adv: 0.575233, recon: 0.205610, id: 0.650920] time: 0:04:42.279886 \n",
      "[Epoch 1/200] [Batch 148/266] [D loss: 0.222186, acc:  62%] [G loss: 5.849705, adv: 0.562922, recon: 0.166235, id: 0.564862] time: 0:04:42.782284 \n",
      "[Epoch 1/200] [Batch 149/266] [D loss: 0.183711, acc:  77%] [G loss: 6.102536, adv: 0.608340, recon: 0.169677, id: 0.714927] time: 0:04:43.266738 \n",
      "[Epoch 1/200] [Batch 150/266] [D loss: 0.246730, acc:  58%] [G loss: 5.816873, adv: 0.573566, recon: 0.167317, id: 0.682246] time: 0:04:43.726047 \n",
      "[Epoch 1/200] [Batch 151/266] [D loss: 0.213296, acc:  64%] [G loss: 5.543435, adv: 0.544384, recon: 0.154573, id: 0.705705] time: 0:04:44.197225 \n",
      "[Epoch 1/200] [Batch 152/266] [D loss: 0.218610, acc:  65%] [G loss: 5.491391, adv: 0.555689, recon: 0.148461, id: 0.709663] time: 0:04:44.779502 \n",
      "[Epoch 1/200] [Batch 153/266] [D loss: 0.207579, acc:  66%] [G loss: 5.451855, adv: 0.582198, recon: 0.141784, id: 0.702954] time: 0:04:45.263327 \n",
      "[Epoch 1/200] [Batch 154/266] [D loss: 0.257975, acc:  58%] [G loss: 5.692759, adv: 0.525390, recon: 0.160773, id: 0.673805] time: 0:04:45.726749 \n",
      "[Epoch 1/200] [Batch 155/266] [D loss: 0.249939, acc:  65%] [G loss: 5.697335, adv: 0.540981, recon: 0.167645, id: 0.541352] time: 0:04:46.239825 \n",
      "[Epoch 1/200] [Batch 156/266] [D loss: 0.198989, acc:  71%] [G loss: 5.502551, adv: 0.523765, recon: 0.152152, id: 0.695127] time: 0:04:46.763484 \n",
      "[Epoch 1/200] [Batch 157/266] [D loss: 0.253259, acc:  55%] [G loss: 5.411424, adv: 0.514941, recon: 0.155382, id: 0.590286] time: 0:04:47.214035 \n",
      "[Epoch 1/200] [Batch 158/266] [D loss: 0.223135, acc:  62%] [G loss: 5.732512, adv: 0.610778, recon: 0.160328, id: 0.631104] time: 0:04:47.698289 \n",
      "[Epoch 1/200] [Batch 159/266] [D loss: 0.234789, acc:  62%] [G loss: 6.038425, adv: 0.771161, recon: 0.155815, id: 0.713286] time: 0:04:48.183389 \n",
      "[Epoch 1/200] [Batch 160/266] [D loss: 0.444932, acc:  34%] [G loss: 4.993743, adv: 0.421609, recon: 0.131503, id: 0.738000] time: 0:04:48.675887 \n",
      "[Epoch 1/200] [Batch 161/266] [D loss: 0.245347, acc:  58%] [G loss: 5.477330, adv: 0.588553, recon: 0.149878, id: 0.641955] time: 0:04:49.161395 \n",
      "[Epoch 1/200] [Batch 162/266] [D loss: 0.242149, acc:  62%] [G loss: 6.240470, adv: 0.576460, recon: 0.175063, id: 0.684051] time: 0:04:49.610417 \n",
      "[Epoch 1/200] [Batch 163/266] [D loss: 0.229423, acc:  68%] [G loss: 5.683207, adv: 0.536655, recon: 0.159814, id: 0.742226] time: 0:04:50.099845 \n",
      "[Epoch 1/200] [Batch 164/266] [D loss: 0.251166, acc:  60%] [G loss: 5.251931, adv: 0.498133, recon: 0.155078, id: 0.547207] time: 0:04:50.583403 \n",
      "[Epoch 1/200] [Batch 165/266] [D loss: 0.379776, acc:  35%] [G loss: 5.961547, adv: 0.659645, recon: 0.166519, id: 0.555702] time: 0:04:51.046711 \n",
      "[Epoch 1/200] [Batch 166/266] [D loss: 0.238263, acc:  58%] [G loss: 5.817408, adv: 0.582194, recon: 0.163427, id: 0.555824] time: 0:04:51.555561 \n",
      "[Epoch 1/200] [Batch 167/266] [D loss: 0.194286, acc:  73%] [G loss: 6.340773, adv: 0.639316, recon: 0.175470, id: 0.695093] time: 0:04:52.005078 \n",
      "[Epoch 1/200] [Batch 168/266] [D loss: 0.338558, acc:  43%] [G loss: 5.662481, adv: 0.550019, recon: 0.154920, id: 0.665673] time: 0:04:52.497486 \n",
      "[Epoch 1/200] [Batch 169/266] [D loss: 0.275943, acc:  53%] [G loss: 5.965619, adv: 0.551419, recon: 0.171018, id: 0.681934] time: 0:04:53.004956 \n",
      "[Epoch 1/200] [Batch 170/266] [D loss: 0.274812, acc:  56%] [G loss: 4.835729, adv: 0.541947, recon: 0.126443, id: 0.596415] time: 0:04:53.457800 \n",
      "[Epoch 1/200] [Batch 171/266] [D loss: 0.217333, acc:  70%] [G loss: 6.255851, adv: 0.570551, recon: 0.184005, id: 0.693053] time: 0:04:53.909536 \n",
      "[Epoch 1/200] [Batch 172/266] [D loss: 0.346619, acc:  34%] [G loss: 5.443781, adv: 0.472277, recon: 0.153041, id: 0.713322] time: 0:04:54.398853 \n",
      "[Epoch 1/200] [Batch 173/266] [D loss: 0.277597, acc:  54%] [G loss: 5.785668, adv: 0.517724, recon: 0.158441, id: 0.703400] time: 0:04:54.905858 \n",
      "[Epoch 1/200] [Batch 174/266] [D loss: 0.274639, acc:  59%] [G loss: 5.634163, adv: 0.507317, recon: 0.160652, id: 0.666043] time: 0:04:55.386069 \n",
      "[Epoch 1/200] [Batch 175/266] [D loss: 0.187847, acc:  77%] [G loss: 5.789916, adv: 0.662224, recon: 0.149446, id: 0.756433] time: 0:04:55.835965 \n",
      "[Epoch 1/200] [Batch 176/266] [D loss: 0.336618, acc:  51%] [G loss: 5.817249, adv: 0.658908, recon: 0.158869, id: 0.583692] time: 0:04:56.292518 \n",
      "[Epoch 1/200] [Batch 177/266] [D loss: 0.311441, acc:  52%] [G loss: 5.871977, adv: 0.516313, recon: 0.170434, id: 0.697833] time: 0:04:56.812845 \n",
      "[Epoch 1/200] [Batch 178/266] [D loss: 0.277833, acc:  49%] [G loss: 5.883964, adv: 0.485730, recon: 0.168179, id: 0.710460] time: 0:04:57.280302 \n",
      "[Epoch 1/200] [Batch 179/266] [D loss: 0.319384, acc:  59%] [G loss: 5.910795, adv: 0.659026, recon: 0.169655, id: 0.544487] time: 0:04:57.775319 \n",
      "[Epoch 1/200] [Batch 180/266] [D loss: 0.393009, acc:  42%] [G loss: 5.136283, adv: 0.438103, recon: 0.140427, id: 0.642335] time: 0:04:58.229690 \n",
      "[Epoch 1/200] [Batch 181/266] [D loss: 0.220701, acc:  63%] [G loss: 5.817665, adv: 0.565160, recon: 0.163725, id: 0.636593] time: 0:04:58.695518 \n",
      "[Epoch 1/200] [Batch 182/266] [D loss: 0.221752, acc:  66%] [G loss: 5.621517, adv: 0.603189, recon: 0.149557, id: 0.667217] time: 0:04:59.161444 \n",
      "[Epoch 1/200] [Batch 183/266] [D loss: 0.231410, acc:  64%] [G loss: 5.754066, adv: 0.590394, recon: 0.162322, id: 0.556115] time: 0:04:59.667587 \n",
      "[Epoch 1/200] [Batch 184/266] [D loss: 0.142758, acc:  83%] [G loss: 6.476892, adv: 0.694231, recon: 0.174749, id: 0.733086] time: 0:05:00.116255 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 185/266] [D loss: 0.393803, acc:  38%] [G loss: 4.944589, adv: 0.449205, recon: 0.133095, id: 0.632446] time: 0:05:00.610910 \n",
      "[Epoch 1/200] [Batch 186/266] [D loss: 0.248999, acc:  62%] [G loss: 5.640735, adv: 0.641811, recon: 0.146209, id: 0.665682] time: 0:05:01.131307 \n",
      "[Epoch 1/200] [Batch 187/266] [D loss: 0.326554, acc:  51%] [G loss: 5.545335, adv: 0.527247, recon: 0.158237, id: 0.639434] time: 0:05:01.574822 \n",
      "[Epoch 1/200] [Batch 188/266] [D loss: 0.308917, acc:  51%] [G loss: 5.663992, adv: 0.473218, recon: 0.170961, id: 0.531928] time: 0:05:02.028074 \n",
      "[Epoch 1/200] [Batch 189/266] [D loss: 0.190794, acc:  76%] [G loss: 6.127961, adv: 0.694940, recon: 0.161764, id: 0.594841] time: 0:05:02.480568 \n",
      "[Epoch 1/200] [Batch 190/266] [D loss: 0.226058, acc:  71%] [G loss: 5.550495, adv: 0.616740, recon: 0.148124, id: 0.656219] time: 0:05:02.929831 \n",
      "[Epoch 1/200] [Batch 191/266] [D loss: 0.357822, acc:  44%] [G loss: 5.924380, adv: 0.392428, recon: 0.181376, id: 0.706809] time: 0:05:03.405037 \n",
      "[Epoch 1/200] [Batch 192/266] [D loss: 0.230687, acc:  62%] [G loss: 5.115443, adv: 0.467839, recon: 0.145025, id: 0.621914] time: 0:05:03.868636 \n",
      "[Epoch 1/200] [Batch 193/266] [D loss: 0.134120, acc:  85%] [G loss: 5.835875, adv: 0.754384, recon: 0.149884, id: 0.614382] time: 0:05:04.332817 \n",
      "[Epoch 1/200] [Batch 194/266] [D loss: 0.178855, acc:  75%] [G loss: 5.318305, adv: 0.579226, recon: 0.143877, id: 0.641202] time: 0:05:04.806491 \n",
      "[Epoch 1/200] [Batch 195/266] [D loss: 0.286301, acc:  49%] [G loss: 5.756031, adv: 0.561921, recon: 0.163142, id: 0.706734] time: 0:05:05.264759 \n",
      "[Epoch 1/200] [Batch 196/266] [D loss: 0.211782, acc:  68%] [G loss: 5.332745, adv: 0.553659, recon: 0.142874, id: 0.694993] time: 0:05:05.756749 \n",
      "[Epoch 1/200] [Batch 197/266] [D loss: 0.226771, acc:  64%] [G loss: 5.946952, adv: 0.571926, recon: 0.164210, id: 0.808280] time: 0:05:06.239141 \n",
      "[Epoch 1/200] [Batch 198/266] [D loss: 0.248303, acc:  66%] [G loss: 5.644148, adv: 0.625127, recon: 0.155994, id: 0.665233] time: 0:05:06.692670 \n",
      "[Epoch 1/200] [Batch 199/266] [D loss: 0.224661, acc:  65%] [G loss: 5.820664, adv: 0.565021, recon: 0.159849, id: 0.704649] time: 0:05:07.143929 \n",
      "[Epoch 1/200] [Batch 200/266] [D loss: 0.243389, acc:  61%] [G loss: 5.418580, adv: 0.531050, recon: 0.145440, id: 0.679022] time: 0:05:07.627444 \n",
      "[Epoch 1/200] [Batch 201/266] [D loss: 0.169915, acc:  76%] [G loss: 5.874880, adv: 0.613696, recon: 0.149615, id: 0.849518] time: 0:05:08.319328 \n",
      "[Epoch 1/200] [Batch 202/266] [D loss: 0.283805, acc:  55%] [G loss: 5.809011, adv: 0.449521, recon: 0.165189, id: 0.840150] time: 0:05:08.788834 \n",
      "[Epoch 1/200] [Batch 203/266] [D loss: 0.220568, acc:  67%] [G loss: 6.099386, adv: 0.618140, recon: 0.173966, id: 0.645903] time: 0:05:09.246961 \n",
      "[Epoch 1/200] [Batch 204/266] [D loss: 0.200196, acc:  70%] [G loss: 6.121856, adv: 0.666507, recon: 0.162047, id: 0.689706] time: 0:05:09.702577 \n",
      "[Epoch 1/200] [Batch 205/266] [D loss: 0.407689, acc:  28%] [G loss: 5.542005, adv: 0.536635, recon: 0.160073, id: 0.614244] time: 0:05:10.197156 \n",
      "[Epoch 1/200] [Batch 206/266] [D loss: 0.271124, acc:  52%] [G loss: 5.568033, adv: 0.662590, recon: 0.148889, id: 0.680122] time: 0:05:10.708348 \n",
      "[Epoch 1/200] [Batch 207/266] [D loss: 0.192170, acc:  70%] [G loss: 5.984771, adv: 0.626493, recon: 0.173207, id: 0.658953] time: 0:05:11.207984 \n",
      "[Epoch 1/200] [Batch 208/266] [D loss: 0.280070, acc:  61%] [G loss: 5.595245, adv: 0.522168, recon: 0.156297, id: 0.724196] time: 0:05:11.663433 \n",
      "[Epoch 1/200] [Batch 209/266] [D loss: 0.304263, acc:  51%] [G loss: 5.702062, adv: 0.549172, recon: 0.163625, id: 0.676903] time: 0:05:12.145734 \n",
      "[Epoch 1/200] [Batch 210/266] [D loss: 0.365270, acc:  44%] [G loss: 5.547711, adv: 0.564596, recon: 0.151148, id: 0.694335] time: 0:05:12.602253 \n",
      "[Epoch 1/200] [Batch 211/266] [D loss: 0.249343, acc:  62%] [G loss: 5.546580, adv: 0.479821, recon: 0.156875, id: 0.762722] time: 0:05:13.102265 \n",
      "[Epoch 1/200] [Batch 212/266] [D loss: 0.264246, acc:  53%] [G loss: 5.862780, adv: 0.513088, recon: 0.166922, id: 0.684077] time: 0:05:13.593169 \n",
      "[Epoch 1/200] [Batch 213/266] [D loss: 0.206276, acc:  67%] [G loss: 5.202292, adv: 0.498423, recon: 0.138747, id: 0.698858] time: 0:05:14.049767 \n",
      "[Epoch 1/200] [Batch 214/266] [D loss: 0.260173, acc:  57%] [G loss: 5.048434, adv: 0.549361, recon: 0.141285, id: 0.552035] time: 0:05:14.517439 \n",
      "[Epoch 1/200] [Batch 215/266] [D loss: 0.236957, acc:  66%] [G loss: 5.667782, adv: 0.527616, recon: 0.158166, id: 0.677753] time: 0:05:15.019201 \n",
      "[Epoch 1/200] [Batch 216/266] [D loss: 0.214436, acc:  64%] [G loss: 5.504786, adv: 0.597144, recon: 0.147398, id: 0.585150] time: 0:05:15.494531 \n",
      "[Epoch 1/200] [Batch 217/266] [D loss: 0.196271, acc:  68%] [G loss: 5.983840, adv: 0.573082, recon: 0.167542, id: 0.694831] time: 0:05:15.973157 \n",
      "[Epoch 1/200] [Batch 218/266] [D loss: 0.211490, acc:  67%] [G loss: 5.615042, adv: 0.560478, recon: 0.158965, id: 0.569357] time: 0:05:16.420098 \n",
      "[Epoch 1/200] [Batch 219/266] [D loss: 0.319183, acc:  41%] [G loss: 4.953676, adv: 0.444491, recon: 0.136420, id: 0.634338] time: 0:05:16.957593 \n",
      "[Epoch 1/200] [Batch 220/266] [D loss: 0.164690, acc:  78%] [G loss: 5.417345, adv: 0.610432, recon: 0.144412, id: 0.587632] time: 0:05:17.468698 \n",
      "[Epoch 1/200] [Batch 221/266] [D loss: 0.107434, acc:  89%] [G loss: 6.040985, adv: 0.791070, recon: 0.152366, id: 0.689913] time: 0:05:17.924717 \n",
      "[Epoch 1/200] [Batch 222/266] [D loss: 0.313215, acc:  58%] [G loss: 6.149524, adv: 0.489072, recon: 0.181891, id: 0.711068] time: 0:05:18.373580 \n",
      "[Epoch 1/200] [Batch 223/266] [D loss: 0.360700, acc:  42%] [G loss: 5.707138, adv: 0.461424, recon: 0.166546, id: 0.796737] time: 0:05:18.828060 \n",
      "[Epoch 1/200] [Batch 224/266] [D loss: 0.236931, acc:  69%] [G loss: 5.905742, adv: 0.620005, recon: 0.155405, id: 0.783349] time: 0:05:19.313827 \n",
      "[Epoch 1/200] [Batch 225/266] [D loss: 0.269756, acc:  63%] [G loss: 5.643631, adv: 0.560767, recon: 0.155839, id: 0.620105] time: 0:05:19.764809 \n",
      "[Epoch 1/200] [Batch 226/266] [D loss: 0.247879, acc:  63%] [G loss: 5.916539, adv: 0.661319, recon: 0.167168, id: 0.519496] time: 0:05:20.218388 \n",
      "[Epoch 1/200] [Batch 227/266] [D loss: 0.276310, acc:  55%] [G loss: 6.018115, adv: 0.501815, recon: 0.176635, id: 0.640058] time: 0:05:20.667910 \n",
      "[Epoch 1/200] [Batch 228/266] [D loss: 0.305552, acc:  51%] [G loss: 5.186064, adv: 0.442468, recon: 0.135449, id: 0.777572] time: 0:05:21.120943 \n",
      "[Epoch 1/200] [Batch 229/266] [D loss: 0.244756, acc:  58%] [G loss: 5.145904, adv: 0.486463, recon: 0.141571, id: 0.646026] time: 0:05:21.603324 \n",
      "[Epoch 1/200] [Batch 230/266] [D loss: 0.252288, acc:  57%] [G loss: 5.591895, adv: 0.549915, recon: 0.151766, id: 0.707371] time: 0:05:22.111784 \n",
      "[Epoch 1/200] [Batch 231/266] [D loss: 0.199682, acc:  69%] [G loss: 5.441675, adv: 0.546486, recon: 0.151960, id: 0.565369] time: 0:05:22.611475 \n",
      "[Epoch 1/200] [Batch 232/266] [D loss: 0.343670, acc:  46%] [G loss: 5.962933, adv: 0.462209, recon: 0.175556, id: 0.762241] time: 0:05:23.123398 \n",
      "[Epoch 1/200] [Batch 233/266] [D loss: 0.293335, acc:  52%] [G loss: 6.230203, adv: 0.560504, recon: 0.186966, id: 0.542531] time: 0:05:23.573281 \n",
      "[Epoch 1/200] [Batch 234/266] [D loss: 0.237311, acc:  61%] [G loss: 5.423770, adv: 0.562504, recon: 0.141355, id: 0.711649] time: 0:05:24.029801 \n",
      "[Epoch 1/200] [Batch 235/266] [D loss: 0.204303, acc:  70%] [G loss: 6.201766, adv: 0.681817, recon: 0.158612, id: 0.788986] time: 0:05:24.481428 \n",
      "[Epoch 1/200] [Batch 236/266] [D loss: 0.330946, acc:  55%] [G loss: 5.707970, adv: 0.519899, recon: 0.154679, id: 0.666250] time: 0:05:24.989413 \n",
      "[Epoch 1/200] [Batch 237/266] [D loss: 0.263102, acc:  56%] [G loss: 5.327439, adv: 0.465695, recon: 0.142754, id: 0.707350] time: 0:05:25.471308 \n",
      "[Epoch 1/200] [Batch 238/266] [D loss: 0.191815, acc:  75%] [G loss: 5.983157, adv: 0.678917, recon: 0.164236, id: 0.520136] time: 0:05:25.940806 \n",
      "[Epoch 1/200] [Batch 239/266] [D loss: 0.318432, acc:  49%] [G loss: 5.669314, adv: 0.476828, recon: 0.161139, id: 0.646324] time: 0:05:26.396571 \n",
      "[Epoch 1/200] [Batch 240/266] [D loss: 0.242864, acc:  61%] [G loss: 6.235442, adv: 0.747644, recon: 0.165103, id: 0.693384] time: 0:05:26.852923 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 241/266] [D loss: 0.339700, acc:  43%] [G loss: 5.172503, adv: 0.463824, recon: 0.143297, id: 0.702882] time: 0:05:27.306878 \n",
      "[Epoch 1/200] [Batch 242/266] [D loss: 0.305501, acc:  46%] [G loss: 5.539175, adv: 0.562605, recon: 0.152681, id: 0.703972] time: 0:05:27.784611 \n",
      "[Epoch 1/200] [Batch 243/266] [D loss: 0.347754, acc:  45%] [G loss: 5.574523, adv: 0.492208, recon: 0.158047, id: 0.621852] time: 0:05:28.240817 \n",
      "[Epoch 1/200] [Batch 244/266] [D loss: 0.271873, acc:  56%] [G loss: 5.412644, adv: 0.487504, recon: 0.149250, id: 0.749017] time: 0:05:28.723994 \n",
      "[Epoch 1/200] [Batch 245/266] [D loss: 0.184927, acc:  75%] [G loss: 5.549406, adv: 0.539279, recon: 0.158908, id: 0.627006] time: 0:05:29.182041 \n",
      "[Epoch 1/200] [Batch 246/266] [D loss: 0.194714, acc:  72%] [G loss: 5.751025, adv: 0.590879, recon: 0.164614, id: 0.634071] time: 0:05:29.643359 \n",
      "[Epoch 1/200] [Batch 247/266] [D loss: 0.216235, acc:  63%] [G loss: 5.515943, adv: 0.601429, recon: 0.147905, id: 0.633634] time: 0:05:30.135363 \n",
      "[Epoch 1/200] [Batch 248/266] [D loss: 0.207819, acc:  69%] [G loss: 5.945041, adv: 0.592969, recon: 0.166335, id: 0.679434] time: 0:05:30.596101 \n",
      "[Epoch 1/200] [Batch 249/266] [D loss: 0.250737, acc:  58%] [G loss: 5.880804, adv: 0.501629, recon: 0.170598, id: 0.654874] time: 0:05:31.095079 \n",
      "[Epoch 1/200] [Batch 250/266] [D loss: 0.212007, acc:  66%] [G loss: 4.921990, adv: 0.535693, recon: 0.129694, id: 0.588488] time: 0:05:31.550783 \n",
      "[Epoch 1/200] [Batch 251/266] [D loss: 0.163329, acc:  78%] [G loss: 5.694406, adv: 0.728667, recon: 0.141915, id: 0.691301] time: 0:05:31.998752 \n",
      "[Epoch 1/200] [Batch 252/266] [D loss: 0.211222, acc:  66%] [G loss: 5.395477, adv: 0.586985, recon: 0.144273, id: 0.642004] time: 0:05:32.480412 \n",
      "[Epoch 1/200] [Batch 253/266] [D loss: 0.311227, acc:  47%] [G loss: 5.265735, adv: 0.446159, recon: 0.149971, id: 0.670173] time: 0:05:32.957921 \n",
      "[Epoch 1/200] [Batch 254/266] [D loss: 0.264882, acc:  55%] [G loss: 5.209014, adv: 0.496503, recon: 0.141210, id: 0.691479] time: 0:05:33.449873 \n",
      "[Epoch 1/200] [Batch 255/266] [D loss: 0.204890, acc:  70%] [G loss: 5.418012, adv: 0.543873, recon: 0.145624, id: 0.702280] time: 0:05:33.906502 \n",
      "[Epoch 1/200] [Batch 256/266] [D loss: 0.219401, acc:  64%] [G loss: 5.499491, adv: 0.547334, recon: 0.144980, id: 0.751302] time: 0:05:34.423010 \n",
      "[Epoch 1/200] [Batch 257/266] [D loss: 0.254162, acc:  56%] [G loss: 5.486588, adv: 0.506005, recon: 0.157061, id: 0.830185] time: 0:05:34.880001 \n",
      "[Epoch 1/200] [Batch 258/266] [D loss: 0.188808, acc:  75%] [G loss: 5.479338, adv: 0.641143, recon: 0.140129, id: 0.697004] time: 0:05:35.377408 \n",
      "[Epoch 1/200] [Batch 259/266] [D loss: 0.246734, acc:  60%] [G loss: 5.800972, adv: 0.547201, recon: 0.167349, id: 0.725520] time: 0:05:35.861779 \n",
      "[Epoch 1/200] [Batch 260/266] [D loss: 0.224407, acc:  71%] [G loss: 5.964480, adv: 0.559556, recon: 0.159245, id: 0.940145] time: 0:05:36.310069 \n",
      "[Epoch 1/200] [Batch 261/266] [D loss: 0.179581, acc:  77%] [G loss: 6.821424, adv: 0.638265, recon: 0.195879, id: 0.870367] time: 0:05:36.788170 \n",
      "[Epoch 1/200] [Batch 262/266] [D loss: 0.164955, acc:  78%] [G loss: 6.347118, adv: 0.560642, recon: 0.187476, id: 0.715618] time: 0:05:37.247002 \n",
      "[Epoch 1/200] [Batch 263/266] [D loss: 0.205323, acc:  73%] [G loss: 6.649755, adv: 0.646634, recon: 0.204305, id: 0.661793] time: 0:05:37.705278 \n",
      "[Epoch 1/200] [Batch 264/266] [D loss: 0.235092, acc:  66%] [G loss: 6.345469, adv: 0.702463, recon: 0.179056, id: 0.663052] time: 0:05:38.199552 \n",
      "[Epoch 2/200] [Batch 0/266] [D loss: 0.311469, acc:  48%] [G loss: 6.097334, adv: 0.522555, recon: 0.185292, id: 0.669132] time: 0:05:38.930327 \n",
      "[Epoch 2/200] [Batch 1/266] [D loss: 0.210365, acc:  65%] [G loss: 5.855395, adv: 0.623864, recon: 0.162556, id: 0.644435] time: 0:05:39.663292 \n",
      "[Epoch 2/200] [Batch 2/266] [D loss: 0.279069, acc:  51%] [G loss: 5.379362, adv: 0.532082, recon: 0.151114, id: 0.617963] time: 0:05:40.122006 \n",
      "[Epoch 2/200] [Batch 3/266] [D loss: 0.156623, acc:  79%] [G loss: 5.297526, adv: 0.646464, recon: 0.131042, id: 0.655480] time: 0:05:40.576522 \n",
      "[Epoch 2/200] [Batch 4/266] [D loss: 0.344488, acc:  41%] [G loss: 4.902772, adv: 0.443863, recon: 0.142174, id: 0.569246] time: 0:05:41.032852 \n",
      "[Epoch 2/200] [Batch 5/266] [D loss: 0.147617, acc:  80%] [G loss: 5.832249, adv: 0.665570, recon: 0.150282, id: 0.604528] time: 0:05:41.490942 \n",
      "[Epoch 2/200] [Batch 6/266] [D loss: 0.214466, acc:  66%] [G loss: 5.401392, adv: 0.607714, recon: 0.150617, id: 0.574600] time: 0:05:41.946082 \n",
      "[Epoch 2/200] [Batch 7/266] [D loss: 0.233997, acc:  63%] [G loss: 4.926389, adv: 0.521709, recon: 0.128888, id: 0.571137] time: 0:05:42.400673 \n",
      "[Epoch 2/200] [Batch 8/266] [D loss: 0.235384, acc:  61%] [G loss: 5.066799, adv: 0.546015, recon: 0.136528, id: 0.499036] time: 0:05:42.859776 \n",
      "[Epoch 2/200] [Batch 9/266] [D loss: 0.199322, acc:  70%] [G loss: 4.870659, adv: 0.532563, recon: 0.130103, id: 0.569127] time: 0:05:43.317712 \n",
      "[Epoch 2/200] [Batch 10/266] [D loss: 0.255979, acc:  63%] [G loss: 5.197647, adv: 0.563810, recon: 0.132186, id: 0.701846] time: 0:05:43.774087 \n",
      "[Epoch 2/200] [Batch 11/266] [D loss: 0.247962, acc:  66%] [G loss: 5.469928, adv: 0.577958, recon: 0.146284, id: 0.646456] time: 0:05:44.232717 \n",
      "[Epoch 2/200] [Batch 12/266] [D loss: 0.260459, acc:  59%] [G loss: 4.779955, adv: 0.461263, recon: 0.123502, id: 0.678445] time: 0:05:44.688574 \n",
      "[Epoch 2/200] [Batch 13/266] [D loss: 0.205236, acc:  68%] [G loss: 4.970265, adv: 0.542873, recon: 0.121821, id: 0.704434] time: 0:05:45.134612 \n",
      "[Epoch 2/200] [Batch 14/266] [D loss: 0.178658, acc:  78%] [G loss: 5.431884, adv: 0.696096, recon: 0.134958, id: 0.629090] time: 0:05:45.586432 \n",
      "[Epoch 2/200] [Batch 15/266] [D loss: 0.342622, acc:  41%] [G loss: 5.092072, adv: 0.388849, recon: 0.147336, id: 0.678507] time: 0:05:46.066972 \n",
      "[Epoch 2/200] [Batch 16/266] [D loss: 0.202672, acc:  69%] [G loss: 5.896921, adv: 0.597732, recon: 0.162233, id: 0.756992] time: 0:05:46.572924 \n",
      "[Epoch 2/200] [Batch 17/266] [D loss: 0.253677, acc:  59%] [G loss: 5.690094, adv: 0.499531, recon: 0.156286, id: 0.852110] time: 0:05:47.024556 \n",
      "[Epoch 2/200] [Batch 18/266] [D loss: 0.199655, acc:  68%] [G loss: 6.620279, adv: 0.757573, recon: 0.187285, id: 0.680120] time: 0:05:47.476664 \n",
      "[Epoch 2/200] [Batch 19/266] [D loss: 0.291052, acc:  53%] [G loss: 5.939984, adv: 0.596874, recon: 0.170809, id: 0.766746] time: 0:05:47.985109 \n",
      "[Epoch 2/200] [Batch 20/266] [D loss: 0.182540, acc:  75%] [G loss: 6.157581, adv: 0.699140, recon: 0.168242, id: 0.706393] time: 0:05:48.462050 \n",
      "[Epoch 2/200] [Batch 21/266] [D loss: 0.327477, acc:  51%] [G loss: 6.219425, adv: 0.568717, recon: 0.177231, id: 0.709326] time: 0:05:48.922681 \n",
      "[Epoch 2/200] [Batch 22/266] [D loss: 0.238949, acc:  61%] [G loss: 5.392798, adv: 0.597906, recon: 0.147939, id: 0.599979] time: 0:05:49.376583 \n",
      "[Epoch 2/200] [Batch 23/266] [D loss: 0.202404, acc:  72%] [G loss: 6.064860, adv: 0.577437, recon: 0.167568, id: 0.716036] time: 0:05:49.831064 \n",
      "[Epoch 2/200] [Batch 24/266] [D loss: 0.229745, acc:  66%] [G loss: 6.186028, adv: 0.494024, recon: 0.182204, id: 0.696562] time: 0:05:50.287121 \n",
      "[Epoch 2/200] [Batch 25/266] [D loss: 0.270272, acc:  53%] [G loss: 5.813214, adv: 0.427941, recon: 0.166143, id: 0.733024] time: 0:05:50.780014 \n",
      "[Epoch 2/200] [Batch 26/266] [D loss: 0.177122, acc:  76%] [G loss: 6.327956, adv: 0.607237, recon: 0.179179, id: 0.714547] time: 0:05:51.230032 \n",
      "[Epoch 2/200] [Batch 27/266] [D loss: 0.314807, acc:  45%] [G loss: 6.195139, adv: 0.708385, recon: 0.160983, id: 0.715637] time: 0:05:51.684233 \n",
      "[Epoch 2/200] [Batch 28/266] [D loss: 0.311534, acc:  51%] [G loss: 5.259094, adv: 0.567009, recon: 0.138645, id: 0.646755] time: 0:05:52.143283 \n",
      "[Epoch 2/200] [Batch 29/266] [D loss: 0.234240, acc:  67%] [G loss: 6.158426, adv: 0.572285, recon: 0.181170, id: 0.659985] time: 0:05:52.597080 \n",
      "[Epoch 2/200] [Batch 30/266] [D loss: 0.231561, acc:  64%] [G loss: 6.201201, adv: 0.606199, recon: 0.169960, id: 0.776927] time: 0:05:53.049364 \n",
      "[Epoch 2/200] [Batch 31/266] [D loss: 0.202042, acc:  73%] [G loss: 5.721440, adv: 0.620352, recon: 0.146363, id: 0.800760] time: 0:05:53.506105 \n",
      "[Epoch 2/200] [Batch 32/266] [D loss: 0.181668, acc:  74%] [G loss: 5.889484, adv: 0.591918, recon: 0.159082, id: 0.672748] time: 0:05:53.968663 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 33/266] [D loss: 0.285302, acc:  55%] [G loss: 5.346214, adv: 0.507385, recon: 0.142329, id: 0.703148] time: 0:05:54.425344 \n",
      "[Epoch 2/200] [Batch 34/266] [D loss: 0.241417, acc:  58%] [G loss: 6.465559, adv: 0.640938, recon: 0.175763, id: 0.791115] time: 0:05:54.881766 \n",
      "[Epoch 2/200] [Batch 35/266] [D loss: 0.310099, acc:  55%] [G loss: 5.635594, adv: 0.522451, recon: 0.156625, id: 0.755935] time: 0:05:55.338342 \n",
      "[Epoch 2/200] [Batch 36/266] [D loss: 0.303152, acc:  44%] [G loss: 5.488545, adv: 0.538023, recon: 0.152110, id: 0.639735] time: 0:05:55.793983 \n",
      "[Epoch 2/200] [Batch 37/266] [D loss: 0.211694, acc:  66%] [G loss: 5.272080, adv: 0.516824, recon: 0.143372, id: 0.610702] time: 0:05:56.244542 \n",
      "[Epoch 2/200] [Batch 38/266] [D loss: 0.214653, acc:  70%] [G loss: 5.747068, adv: 0.595882, recon: 0.160090, id: 0.685825] time: 0:05:56.698503 \n",
      "[Epoch 2/200] [Batch 39/266] [D loss: 0.337205, acc:  46%] [G loss: 4.828582, adv: 0.413959, recon: 0.136616, id: 0.562573] time: 0:05:57.150869 \n",
      "[Epoch 2/200] [Batch 40/266] [D loss: 0.321714, acc:  40%] [G loss: 5.197155, adv: 0.477987, recon: 0.145649, id: 0.694002] time: 0:05:57.607567 \n",
      "[Epoch 2/200] [Batch 41/266] [D loss: 0.260032, acc:  62%] [G loss: 4.976393, adv: 0.559809, recon: 0.131235, id: 0.657874] time: 0:05:58.057823 \n",
      "[Epoch 2/200] [Batch 42/266] [D loss: 0.222938, acc:  69%] [G loss: 5.872426, adv: 0.580995, recon: 0.161349, id: 0.745155] time: 0:05:58.514286 \n",
      "[Epoch 2/200] [Batch 43/266] [D loss: 0.244653, acc:  62%] [G loss: 5.635682, adv: 0.512578, recon: 0.159958, id: 0.693601] time: 0:05:58.971592 \n",
      "[Epoch 2/200] [Batch 44/266] [D loss: 0.203628, acc:  64%] [G loss: 5.415672, adv: 0.563913, recon: 0.144463, id: 0.736051] time: 0:05:59.450334 \n",
      "[Epoch 2/200] [Batch 45/266] [D loss: 0.206951, acc:  68%] [G loss: 5.730559, adv: 0.564955, recon: 0.156919, id: 0.743889] time: 0:05:59.902124 \n",
      "[Epoch 2/200] [Batch 46/266] [D loss: 0.264518, acc:  51%] [G loss: 5.478605, adv: 0.478474, recon: 0.153992, id: 0.730048] time: 0:06:00.351148 \n",
      "[Epoch 2/200] [Batch 47/266] [D loss: 0.141438, acc:  82%] [G loss: 6.117737, adv: 0.663418, recon: 0.162084, id: 0.660882] time: 0:06:00.809420 \n",
      "[Epoch 2/200] [Batch 48/266] [D loss: 0.221584, acc:  67%] [G loss: 5.273429, adv: 0.599345, recon: 0.130589, id: 0.675012] time: 0:06:01.263905 \n",
      "[Epoch 2/200] [Batch 49/266] [D loss: 0.230181, acc:  64%] [G loss: 5.688962, adv: 0.586694, recon: 0.148743, id: 0.680118] time: 0:06:01.715759 \n",
      "[Epoch 2/200] [Batch 50/266] [D loss: 0.370096, acc:  40%] [G loss: 5.440470, adv: 0.552468, recon: 0.140516, id: 0.738351] time: 0:06:02.166710 \n",
      "[Epoch 2/200] [Batch 51/266] [D loss: 0.259124, acc:  51%] [G loss: 5.418404, adv: 0.563973, recon: 0.142727, id: 0.777655] time: 0:06:02.622645 \n",
      "[Epoch 2/200] [Batch 52/266] [D loss: 0.205598, acc:  74%] [G loss: 5.389929, adv: 0.594305, recon: 0.137207, id: 0.702947] time: 0:06:03.070200 \n",
      "[Epoch 2/200] [Batch 53/266] [D loss: 0.173339, acc:  74%] [G loss: 6.119803, adv: 0.669329, recon: 0.164921, id: 0.628975] time: 0:06:03.554659 \n",
      "[Epoch 2/200] [Batch 54/266] [D loss: 0.283027, acc:  53%] [G loss: 5.272303, adv: 0.512515, recon: 0.142800, id: 0.688738] time: 0:06:04.009396 \n",
      "[Epoch 2/200] [Batch 55/266] [D loss: 0.266555, acc:  58%] [G loss: 4.856625, adv: 0.420927, recon: 0.127592, id: 0.792783] time: 0:06:04.463367 \n",
      "[Epoch 2/200] [Batch 56/266] [D loss: 0.219817, acc:  61%] [G loss: 5.338195, adv: 0.544661, recon: 0.140232, id: 0.696225] time: 0:06:04.917282 \n",
      "[Epoch 2/200] [Batch 57/266] [D loss: 0.196022, acc:  68%] [G loss: 5.730296, adv: 0.763705, recon: 0.139806, id: 0.667770] time: 0:06:05.383499 \n",
      "[Epoch 2/200] [Batch 58/266] [D loss: 0.246211, acc:  62%] [G loss: 5.108277, adv: 0.577510, recon: 0.141874, id: 0.526889] time: 0:06:05.833275 \n",
      "[Epoch 2/200] [Batch 59/266] [D loss: 0.157046, acc:  77%] [G loss: 5.883095, adv: 0.589580, recon: 0.160953, id: 0.684305] time: 0:06:06.284255 \n",
      "[Epoch 2/200] [Batch 60/266] [D loss: 0.300731, acc:  47%] [G loss: 5.461090, adv: 0.513153, recon: 0.156353, id: 0.726185] time: 0:06:06.741736 \n",
      "[Epoch 2/200] [Batch 61/266] [D loss: 0.239649, acc:  69%] [G loss: 5.829731, adv: 0.586906, recon: 0.165604, id: 0.645995] time: 0:06:07.210570 \n",
      "[Epoch 2/200] [Batch 62/266] [D loss: 0.224221, acc:  63%] [G loss: 5.306267, adv: 0.564751, recon: 0.137358, id: 0.718734] time: 0:06:07.668909 \n",
      "[Epoch 2/200] [Batch 63/266] [D loss: 0.294528, acc:  51%] [G loss: 6.020115, adv: 0.551988, recon: 0.170201, id: 0.733230] time: 0:06:08.123448 \n",
      "[Epoch 2/200] [Batch 64/266] [D loss: 0.168666, acc:  75%] [G loss: 5.527194, adv: 0.661701, recon: 0.142341, id: 0.607939] time: 0:06:08.598534 \n",
      "[Epoch 2/200] [Batch 65/266] [D loss: 0.382433, acc:  37%] [G loss: 5.314525, adv: 0.375392, recon: 0.157083, id: 0.644361] time: 0:06:09.047509 \n",
      "[Epoch 2/200] [Batch 66/266] [D loss: 0.199855, acc:  66%] [G loss: 5.659098, adv: 0.571538, recon: 0.162008, id: 0.702439] time: 0:06:09.494675 \n",
      "[Epoch 2/200] [Batch 67/266] [D loss: 0.181383, acc:  74%] [G loss: 5.621721, adv: 0.754861, recon: 0.145549, id: 0.604941] time: 0:06:09.950294 \n",
      "[Epoch 2/200] [Batch 68/266] [D loss: 0.415449, acc:  34%] [G loss: 5.767294, adv: 0.404630, recon: 0.174642, id: 0.641406] time: 0:06:10.405252 \n",
      "[Epoch 2/200] [Batch 69/266] [D loss: 0.185634, acc:  74%] [G loss: 5.345407, adv: 0.535105, recon: 0.141798, id: 0.635875] time: 0:06:10.858739 \n",
      "[Epoch 2/200] [Batch 70/266] [D loss: 0.264317, acc:  49%] [G loss: 5.179522, adv: 0.513551, recon: 0.141649, id: 0.598801] time: 0:06:11.318816 \n",
      "[Epoch 2/200] [Batch 71/266] [D loss: 0.165170, acc:  81%] [G loss: 5.559815, adv: 0.671244, recon: 0.137045, id: 0.635327] time: 0:06:11.777097 \n",
      "[Epoch 2/200] [Batch 72/266] [D loss: 0.341970, acc:  45%] [G loss: 5.549720, adv: 0.403945, recon: 0.168155, id: 0.659068] time: 0:06:12.225911 \n",
      "[Epoch 2/200] [Batch 73/266] [D loss: 0.191870, acc:  74%] [G loss: 6.251915, adv: 0.531712, recon: 0.176593, id: 0.840861] time: 0:06:12.704628 \n",
      "[Epoch 2/200] [Batch 74/266] [D loss: 0.282302, acc:  57%] [G loss: 5.608598, adv: 0.488215, recon: 0.154828, id: 0.632431] time: 0:06:13.154499 \n",
      "[Epoch 2/200] [Batch 75/266] [D loss: 0.324710, acc:  39%] [G loss: 5.743866, adv: 0.422014, recon: 0.169845, id: 0.752315] time: 0:06:13.611999 \n",
      "[Epoch 2/200] [Batch 76/266] [D loss: 0.222089, acc:  65%] [G loss: 5.477570, adv: 0.529130, recon: 0.150464, id: 0.690590] time: 0:06:14.081958 \n",
      "[Epoch 2/200] [Batch 77/266] [D loss: 0.285901, acc:  53%] [G loss: 5.299021, adv: 0.461941, recon: 0.146425, id: 0.691539] time: 0:06:14.571484 \n",
      "[Epoch 2/200] [Batch 78/266] [D loss: 0.210696, acc:  65%] [G loss: 5.558345, adv: 0.637147, recon: 0.142178, id: 0.688660] time: 0:06:15.023597 \n",
      "[Epoch 2/200] [Batch 79/266] [D loss: 0.214745, acc:  65%] [G loss: 6.362265, adv: 0.505185, recon: 0.194576, id: 0.758045] time: 0:06:15.470696 \n",
      "[Epoch 2/200] [Batch 80/266] [D loss: 0.139291, acc:  83%] [G loss: 5.263681, adv: 0.632999, recon: 0.129921, id: 0.676444] time: 0:06:15.925577 \n",
      "[Epoch 2/200] [Batch 81/266] [D loss: 0.220313, acc:  67%] [G loss: 6.213188, adv: 0.561371, recon: 0.181459, id: 0.737366] time: 0:06:16.371903 \n",
      "[Epoch 2/200] [Batch 82/266] [D loss: 0.216874, acc:  63%] [G loss: 5.736187, adv: 0.621274, recon: 0.155714, id: 0.605884] time: 0:06:16.826850 \n",
      "[Epoch 2/200] [Batch 83/266] [D loss: 0.187502, acc:  68%] [G loss: 5.685800, adv: 0.701459, recon: 0.138440, id: 0.686526] time: 0:06:17.275249 \n",
      "[Epoch 2/200] [Batch 84/266] [D loss: 0.263445, acc:  53%] [G loss: 5.446025, adv: 0.555910, recon: 0.142906, id: 0.697909] time: 0:06:17.794958 \n",
      "[Epoch 2/200] [Batch 85/266] [D loss: 0.191663, acc:  74%] [G loss: 5.864200, adv: 0.696611, recon: 0.147242, id: 0.673706] time: 0:06:18.282161 \n",
      "[Epoch 2/200] [Batch 86/266] [D loss: 0.216408, acc:  64%] [G loss: 5.954834, adv: 0.535612, recon: 0.169936, id: 0.614821] time: 0:06:18.738139 \n",
      "[Epoch 2/200] [Batch 87/266] [D loss: 0.159300, acc:  79%] [G loss: 5.688229, adv: 0.669039, recon: 0.150769, id: 0.512230] time: 0:06:19.208972 \n",
      "[Epoch 2/200] [Batch 88/266] [D loss: 0.199144, acc:  69%] [G loss: 5.235879, adv: 0.669228, recon: 0.136932, id: 0.483102] time: 0:06:19.666503 \n",
      "[Epoch 2/200] [Batch 89/266] [D loss: 0.375562, acc:  43%] [G loss: 5.275868, adv: 0.444116, recon: 0.149450, id: 0.624456] time: 0:06:20.117837 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 90/266] [D loss: 0.225420, acc:  62%] [G loss: 5.684486, adv: 0.600249, recon: 0.155254, id: 0.669599] time: 0:06:20.565560 \n",
      "[Epoch 2/200] [Batch 91/266] [D loss: 0.206732, acc:  70%] [G loss: 5.910592, adv: 0.723797, recon: 0.143835, id: 0.806739] time: 0:06:21.017274 \n",
      "[Epoch 2/200] [Batch 92/266] [D loss: 0.151392, acc:  81%] [G loss: 6.185270, adv: 0.629687, recon: 0.163370, id: 0.871441] time: 0:06:21.466625 \n",
      "[Epoch 2/200] [Batch 93/266] [D loss: 0.258961, acc:  61%] [G loss: 5.425792, adv: 0.483098, recon: 0.150586, id: 0.702467] time: 0:06:21.923432 \n",
      "[Epoch 2/200] [Batch 94/266] [D loss: 0.165321, acc:  77%] [G loss: 5.592198, adv: 0.641449, recon: 0.137333, id: 0.752811] time: 0:06:22.370799 \n",
      "[Epoch 2/200] [Batch 95/266] [D loss: 0.109719, acc:  87%] [G loss: 6.045214, adv: 0.859100, recon: 0.147443, id: 0.767460] time: 0:06:22.821478 \n",
      "[Epoch 2/200] [Batch 96/266] [D loss: 0.241071, acc:  65%] [G loss: 5.991017, adv: 0.532722, recon: 0.166765, id: 0.727608] time: 0:06:23.332978 \n",
      "[Epoch 2/200] [Batch 97/266] [D loss: 0.221152, acc:  69%] [G loss: 4.973034, adv: 0.467837, recon: 0.128676, id: 0.810479] time: 0:06:23.793584 \n",
      "[Epoch 2/200] [Batch 98/266] [D loss: 0.175871, acc:  74%] [G loss: 6.217426, adv: 0.811060, recon: 0.156378, id: 0.767688] time: 0:06:24.248421 \n",
      "[Epoch 2/200] [Batch 99/266] [D loss: 0.177301, acc:  75%] [G loss: 5.801028, adv: 0.714667, recon: 0.146012, id: 0.778758] time: 0:06:24.704127 \n",
      "[Epoch 2/200] [Batch 100/266] [D loss: 0.169250, acc:  76%] [G loss: 5.367585, adv: 0.667658, recon: 0.131436, id: 0.777066] time: 0:06:25.160235 \n",
      "[Epoch 2/200] [Batch 101/266] [D loss: 0.140112, acc:  83%] [G loss: 6.028965, adv: 0.676930, recon: 0.163442, id: 0.666547] time: 0:06:25.610708 \n",
      "[Epoch 2/200] [Batch 102/266] [D loss: 0.286802, acc:  63%] [G loss: 5.155460, adv: 0.530200, recon: 0.137021, id: 0.576408] time: 0:06:26.065350 \n",
      "[Epoch 2/200] [Batch 103/266] [D loss: 0.255471, acc:  66%] [G loss: 6.036242, adv: 0.749871, recon: 0.159372, id: 0.563719] time: 0:06:26.518563 \n",
      "[Epoch 2/200] [Batch 104/266] [D loss: 0.224768, acc:  68%] [G loss: 6.030757, adv: 0.691028, recon: 0.156950, id: 0.650658] time: 0:06:26.975693 \n",
      "[Epoch 2/200] [Batch 105/266] [D loss: 0.254694, acc:  62%] [G loss: 5.558635, adv: 0.538562, recon: 0.155193, id: 0.694997] time: 0:06:27.449198 \n",
      "[Epoch 2/200] [Batch 106/266] [D loss: 0.243062, acc:  62%] [G loss: 5.077374, adv: 0.565838, recon: 0.137515, id: 0.555417] time: 0:06:27.902520 \n",
      "[Epoch 2/200] [Batch 107/266] [D loss: 0.258000, acc:  57%] [G loss: 5.295249, adv: 0.493193, recon: 0.144608, id: 0.740998] time: 0:06:28.357491 \n",
      "[Epoch 2/200] [Batch 108/266] [D loss: 0.291965, acc:  56%] [G loss: 5.352607, adv: 0.524339, recon: 0.146155, id: 0.633618] time: 0:06:28.820052 \n",
      "[Epoch 2/200] [Batch 109/266] [D loss: 0.221162, acc:  66%] [G loss: 5.673718, adv: 0.480155, recon: 0.159383, id: 0.782188] time: 0:06:29.287639 \n",
      "[Epoch 2/200] [Batch 110/266] [D loss: 0.184097, acc:  72%] [G loss: 5.357100, adv: 0.606569, recon: 0.146490, id: 0.630252] time: 0:06:29.753056 \n",
      "[Epoch 2/200] [Batch 111/266] [D loss: 0.210674, acc:  69%] [G loss: 5.223424, adv: 0.588789, recon: 0.135158, id: 0.586021] time: 0:06:30.218127 \n",
      "[Epoch 2/200] [Batch 112/266] [D loss: 0.344112, acc:  39%] [G loss: 5.651068, adv: 0.514673, recon: 0.161221, id: 0.625704] time: 0:06:30.676361 \n",
      "[Epoch 2/200] [Batch 113/266] [D loss: 0.270081, acc:  52%] [G loss: 4.798890, adv: 0.459932, recon: 0.126066, id: 0.606434] time: 0:06:31.130331 \n",
      "[Epoch 2/200] [Batch 114/266] [D loss: 0.192413, acc:  70%] [G loss: 5.642311, adv: 0.614995, recon: 0.147861, id: 0.714799] time: 0:06:31.586151 \n",
      "[Epoch 2/200] [Batch 115/266] [D loss: 0.197318, acc:  70%] [G loss: 5.683970, adv: 0.656668, recon: 0.154734, id: 0.593265] time: 0:06:32.037185 \n",
      "[Epoch 2/200] [Batch 116/266] [D loss: 0.198473, acc:  72%] [G loss: 5.730592, adv: 0.585819, recon: 0.158873, id: 0.698843] time: 0:06:32.494469 \n",
      "[Epoch 2/200] [Batch 117/266] [D loss: 0.246688, acc:  60%] [G loss: 5.307931, adv: 0.554421, recon: 0.147233, id: 0.580997] time: 0:06:32.953289 \n",
      "[Epoch 2/200] [Batch 118/266] [D loss: 0.177446, acc:  73%] [G loss: 5.574693, adv: 0.623231, recon: 0.143084, id: 0.697043] time: 0:06:33.397861 \n",
      "[Epoch 2/200] [Batch 119/266] [D loss: 0.286715, acc:  54%] [G loss: 5.523924, adv: 0.508580, recon: 0.158453, id: 0.688107] time: 0:06:33.851042 \n",
      "[Epoch 2/200] [Batch 120/266] [D loss: 0.209044, acc:  64%] [G loss: 5.896646, adv: 0.537666, recon: 0.164467, id: 0.807546] time: 0:06:34.310122 \n",
      "[Epoch 2/200] [Batch 121/266] [D loss: 0.260084, acc:  53%] [G loss: 5.045953, adv: 0.498766, recon: 0.137570, id: 0.623320] time: 0:06:34.765769 \n",
      "[Epoch 2/200] [Batch 122/266] [D loss: 0.228121, acc:  67%] [G loss: 5.415522, adv: 0.591131, recon: 0.147989, id: 0.576082] time: 0:06:35.224722 \n",
      "[Epoch 2/200] [Batch 123/266] [D loss: 0.223865, acc:  69%] [G loss: 5.070652, adv: 0.553841, recon: 0.131388, id: 0.723220] time: 0:06:35.684940 \n",
      "[Epoch 2/200] [Batch 124/266] [D loss: 0.155324, acc:  79%] [G loss: 5.406959, adv: 0.665323, recon: 0.137378, id: 0.580325] time: 0:06:36.146810 \n",
      "[Epoch 2/200] [Batch 125/266] [D loss: 0.165802, acc:  74%] [G loss: 6.099664, adv: 0.696567, recon: 0.165231, id: 0.643182] time: 0:06:36.616403 \n",
      "[Epoch 2/200] [Batch 126/266] [D loss: 0.299966, acc:  53%] [G loss: 5.361731, adv: 0.470657, recon: 0.151827, id: 0.596488] time: 0:06:37.093575 \n",
      "[Epoch 2/200] [Batch 127/266] [D loss: 0.169927, acc:  75%] [G loss: 5.589679, adv: 0.668273, recon: 0.150220, id: 0.624062] time: 0:06:37.567961 \n",
      "[Epoch 2/200] [Batch 128/266] [D loss: 0.237107, acc:  59%] [G loss: 5.739699, adv: 0.602461, recon: 0.156384, id: 0.740856] time: 0:06:38.047189 \n",
      "[Epoch 2/200] [Batch 129/266] [D loss: 0.151974, acc:  78%] [G loss: 5.715300, adv: 0.759715, recon: 0.136261, id: 0.691982] time: 0:06:38.517011 \n",
      "[Epoch 2/200] [Batch 130/266] [D loss: 0.170560, acc:  78%] [G loss: 5.216055, adv: 0.678408, recon: 0.129552, id: 0.627690] time: 0:06:38.969176 \n",
      "[Epoch 2/200] [Batch 131/266] [D loss: 0.314861, acc:  49%] [G loss: 5.277287, adv: 0.495331, recon: 0.146902, id: 0.601700] time: 0:06:39.428071 \n",
      "[Epoch 2/200] [Batch 132/266] [D loss: 0.259895, acc:  59%] [G loss: 5.491470, adv: 0.604838, recon: 0.146997, id: 0.572165] time: 0:06:39.881264 \n",
      "[Epoch 2/200] [Batch 133/266] [D loss: 0.234879, acc:  64%] [G loss: 4.962354, adv: 0.584739, recon: 0.123702, id: 0.604944] time: 0:06:40.371657 \n",
      "[Epoch 2/200] [Batch 134/266] [D loss: 0.261332, acc:  57%] [G loss: 6.145507, adv: 0.638985, recon: 0.169975, id: 0.805440] time: 0:06:40.833561 \n",
      "[Epoch 2/200] [Batch 135/266] [D loss: 0.251919, acc:  61%] [G loss: 5.426464, adv: 0.567361, recon: 0.146094, id: 0.594856] time: 0:06:41.338245 \n",
      "[Epoch 2/200] [Batch 136/266] [D loss: 0.284075, acc:  54%] [G loss: 5.560025, adv: 0.549252, recon: 0.155637, id: 0.682427] time: 0:06:41.798392 \n",
      "[Epoch 2/200] [Batch 137/266] [D loss: 0.223463, acc:  65%] [G loss: 5.779053, adv: 0.552465, recon: 0.156795, id: 0.730440] time: 0:06:42.254116 \n",
      "[Epoch 2/200] [Batch 138/266] [D loss: 0.170166, acc:  78%] [G loss: 5.852663, adv: 0.593819, recon: 0.156460, id: 0.668897] time: 0:06:42.705504 \n",
      "[Epoch 2/200] [Batch 139/266] [D loss: 0.239436, acc:  65%] [G loss: 5.013798, adv: 0.557024, recon: 0.130693, id: 0.665613] time: 0:06:43.155388 \n",
      "[Epoch 2/200] [Batch 140/266] [D loss: 0.276180, acc:  53%] [G loss: 5.856971, adv: 0.464633, recon: 0.168654, id: 0.856654] time: 0:06:43.614949 \n",
      "[Epoch 2/200] [Batch 141/266] [D loss: 0.295371, acc:  45%] [G loss: 5.815192, adv: 0.418414, recon: 0.175450, id: 0.711693] time: 0:06:44.071751 \n",
      "[Epoch 2/200] [Batch 142/266] [D loss: 0.129153, acc:  83%] [G loss: 6.310490, adv: 0.729412, recon: 0.175803, id: 0.636534] time: 0:06:44.528976 \n",
      "[Epoch 2/200] [Batch 143/266] [D loss: 0.307556, acc:  48%] [G loss: 6.463665, adv: 0.440731, recon: 0.194992, id: 0.733945] time: 0:06:44.985041 \n",
      "[Epoch 2/200] [Batch 144/266] [D loss: 0.301499, acc:  48%] [G loss: 4.749264, adv: 0.436412, recon: 0.121271, id: 0.607436] time: 0:06:45.439585 \n",
      "[Epoch 2/200] [Batch 145/266] [D loss: 0.214332, acc:  67%] [G loss: 4.907309, adv: 0.647434, recon: 0.115938, id: 0.667728] time: 0:06:45.906717 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 146/266] [D loss: 0.225010, acc:  71%] [G loss: 5.570290, adv: 0.588978, recon: 0.152085, id: 0.634538] time: 0:06:46.375928 \n",
      "[Epoch 2/200] [Batch 147/266] [D loss: 0.300108, acc:  59%] [G loss: 5.069637, adv: 0.458129, recon: 0.140220, id: 0.668533] time: 0:06:46.837415 \n",
      "[Epoch 2/200] [Batch 148/266] [D loss: 0.148829, acc:  83%] [G loss: 5.144131, adv: 0.584777, recon: 0.128662, id: 0.662960] time: 0:06:47.306669 \n",
      "[Epoch 2/200] [Batch 149/266] [D loss: 0.278453, acc:  49%] [G loss: 4.767002, adv: 0.472076, recon: 0.126749, id: 0.622291] time: 0:06:47.857410 \n",
      "[Epoch 2/200] [Batch 150/266] [D loss: 0.162829, acc:  81%] [G loss: 5.724934, adv: 0.602074, recon: 0.149147, id: 0.725476] time: 0:06:48.325187 \n",
      "[Epoch 2/200] [Batch 151/266] [D loss: 0.164924, acc:  75%] [G loss: 5.946816, adv: 0.661315, recon: 0.157184, id: 0.650458] time: 0:06:48.779834 \n",
      "[Epoch 2/200] [Batch 152/266] [D loss: 0.264878, acc:  54%] [G loss: 5.509465, adv: 0.567740, recon: 0.154270, id: 0.691331] time: 0:06:49.235172 \n",
      "[Epoch 2/200] [Batch 153/266] [D loss: 0.220666, acc:  66%] [G loss: 6.295824, adv: 0.590049, recon: 0.175165, id: 0.878630] time: 0:06:49.684401 \n",
      "[Epoch 2/200] [Batch 154/266] [D loss: 0.200451, acc:  70%] [G loss: 5.774062, adv: 0.577517, recon: 0.154963, id: 0.811403] time: 0:06:50.136541 \n",
      "[Epoch 2/200] [Batch 155/266] [D loss: 0.249416, acc:  67%] [G loss: 5.160120, adv: 0.655750, recon: 0.127206, id: 0.746974] time: 0:06:50.589010 \n",
      "[Epoch 2/200] [Batch 156/266] [D loss: 0.183391, acc:  76%] [G loss: 5.798986, adv: 0.647509, recon: 0.154067, id: 0.709480] time: 0:06:51.042690 \n",
      "[Epoch 2/200] [Batch 157/266] [D loss: 0.261144, acc:  56%] [G loss: 5.129423, adv: 0.582625, recon: 0.132831, id: 0.647707] time: 0:06:51.497084 \n",
      "[Epoch 2/200] [Batch 158/266] [D loss: 0.220334, acc:  64%] [G loss: 5.154010, adv: 0.604053, recon: 0.129564, id: 0.671448] time: 0:06:51.949197 \n",
      "[Epoch 2/200] [Batch 159/266] [D loss: 0.141218, acc:  81%] [G loss: 5.871286, adv: 0.708029, recon: 0.151588, id: 0.610193] time: 0:06:52.406428 \n",
      "[Epoch 2/200] [Batch 160/266] [D loss: 0.168397, acc:  76%] [G loss: 5.463754, adv: 0.561558, recon: 0.146238, id: 0.674534] time: 0:06:52.859479 \n",
      "[Epoch 2/200] [Batch 161/266] [D loss: 0.276703, acc:  54%] [G loss: 5.732720, adv: 0.748256, recon: 0.150234, id: 0.599744] time: 0:06:53.313321 \n",
      "[Epoch 2/200] [Batch 162/266] [D loss: 0.226933, acc:  68%] [G loss: 5.818250, adv: 0.642603, recon: 0.159247, id: 0.655331] time: 0:06:53.766201 \n",
      "[Epoch 2/200] [Batch 163/266] [D loss: 0.285311, acc:  51%] [G loss: 5.323805, adv: 0.547482, recon: 0.147870, id: 0.512918] time: 0:06:54.217132 \n",
      "[Epoch 2/200] [Batch 164/266] [D loss: 0.201322, acc:  73%] [G loss: 5.962255, adv: 0.735801, recon: 0.163581, id: 0.542740] time: 0:06:54.670614 \n",
      "[Epoch 2/200] [Batch 165/266] [D loss: 0.168101, acc:  80%] [G loss: 5.826684, adv: 0.707638, recon: 0.148979, id: 0.577822] time: 0:06:55.119696 \n",
      "[Epoch 2/200] [Batch 166/266] [D loss: 0.374563, acc:  41%] [G loss: 6.207153, adv: 0.609738, recon: 0.175591, id: 0.685136] time: 0:06:55.576640 \n",
      "[Epoch 2/200] [Batch 167/266] [D loss: 0.248914, acc:  69%] [G loss: 6.186362, adv: 0.634520, recon: 0.173971, id: 0.633050] time: 0:06:56.033276 \n",
      "[Epoch 2/200] [Batch 168/266] [D loss: 0.303448, acc:  64%] [G loss: 5.040476, adv: 0.547535, recon: 0.134223, id: 0.608804] time: 0:06:56.489129 \n",
      "[Epoch 2/200] [Batch 169/266] [D loss: 0.167002, acc:  77%] [G loss: 5.504887, adv: 0.663873, recon: 0.136775, id: 0.606786] time: 0:06:56.946675 \n",
      "[Epoch 2/200] [Batch 170/266] [D loss: 0.245185, acc:  66%] [G loss: 5.745623, adv: 0.607984, recon: 0.162373, id: 0.532551] time: 0:06:57.397100 \n",
      "[Epoch 2/200] [Batch 171/266] [D loss: 0.187023, acc:  72%] [G loss: 5.816315, adv: 0.615435, recon: 0.162475, id: 0.569182] time: 0:06:57.930596 \n",
      "[Epoch 2/200] [Batch 172/266] [D loss: 0.239345, acc:  59%] [G loss: 5.250144, adv: 0.567282, recon: 0.131881, id: 0.731591] time: 0:06:58.379918 \n",
      "[Epoch 2/200] [Batch 173/266] [D loss: 0.256731, acc:  57%] [G loss: 5.500955, adv: 0.656552, recon: 0.133581, id: 0.791653] time: 0:06:58.831816 \n",
      "[Epoch 2/200] [Batch 174/266] [D loss: 0.245022, acc:  63%] [G loss: 6.099626, adv: 0.675231, recon: 0.165593, id: 0.585861] time: 0:06:59.287981 \n",
      "[Epoch 2/200] [Batch 175/266] [D loss: 0.215669, acc:  65%] [G loss: 5.191090, adv: 0.531322, recon: 0.131127, id: 0.746592] time: 0:06:59.747013 \n",
      "[Epoch 2/200] [Batch 176/266] [D loss: 0.279765, acc:  52%] [G loss: 5.439518, adv: 0.454174, recon: 0.159157, id: 0.640783] time: 0:07:00.200506 \n",
      "[Epoch 2/200] [Batch 177/266] [D loss: 0.210331, acc:  65%] [G loss: 6.111593, adv: 0.569911, recon: 0.174395, id: 0.638125] time: 0:07:00.656128 \n",
      "[Epoch 2/200] [Batch 178/266] [D loss: 0.196767, acc:  74%] [G loss: 5.818390, adv: 0.574316, recon: 0.157904, id: 0.737292] time: 0:07:01.111323 \n",
      "[Epoch 2/200] [Batch 179/266] [D loss: 0.187019, acc:  72%] [G loss: 5.903835, adv: 0.725130, recon: 0.148452, id: 0.760494] time: 0:07:01.568418 \n",
      "[Epoch 2/200] [Batch 180/266] [D loss: 0.214833, acc:  66%] [G loss: 5.447943, adv: 0.597842, recon: 0.141993, id: 0.799551] time: 0:07:02.019861 \n",
      "[Epoch 2/200] [Batch 181/266] [D loss: 0.282548, acc:  52%] [G loss: 5.123484, adv: 0.472900, recon: 0.146414, id: 0.663520] time: 0:07:02.477895 \n",
      "[Epoch 2/200] [Batch 182/266] [D loss: 0.149177, acc:  78%] [G loss: 5.681884, adv: 0.764678, recon: 0.141706, id: 0.599437] time: 0:07:02.968646 \n",
      "[Epoch 2/200] [Batch 183/266] [D loss: 0.330558, acc:  52%] [G loss: 5.132161, adv: 0.482245, recon: 0.142084, id: 0.657194] time: 0:07:03.422476 \n",
      "[Epoch 2/200] [Batch 184/266] [D loss: 0.271417, acc:  65%] [G loss: 5.094540, adv: 0.480766, recon: 0.138779, id: 0.641227] time: 0:07:03.877489 \n",
      "[Epoch 2/200] [Batch 185/266] [D loss: 0.278214, acc:  59%] [G loss: 5.521255, adv: 0.546445, recon: 0.147201, id: 0.787639] time: 0:07:04.326968 \n",
      "[Epoch 2/200] [Batch 186/266] [D loss: 0.200774, acc:  72%] [G loss: 6.585359, adv: 0.551307, recon: 0.192846, id: 0.857026] time: 0:07:04.782710 \n",
      "[Epoch 2/200] [Batch 187/266] [D loss: 0.223938, acc:  63%] [G loss: 5.541203, adv: 0.586231, recon: 0.153106, id: 0.629081] time: 0:07:05.235200 \n",
      "[Epoch 2/200] [Batch 188/266] [D loss: 0.195457, acc:  72%] [G loss: 5.252102, adv: 0.573567, recon: 0.137961, id: 0.697206] time: 0:07:05.705605 \n",
      "[Epoch 2/200] [Batch 189/266] [D loss: 0.228415, acc:  63%] [G loss: 6.245766, adv: 0.637821, recon: 0.176929, id: 0.695186] time: 0:07:06.156104 \n",
      "[Epoch 2/200] [Batch 190/266] [D loss: 0.340698, acc:  46%] [G loss: 5.315808, adv: 0.483888, recon: 0.149698, id: 0.741485] time: 0:07:06.612203 \n",
      "[Epoch 2/200] [Batch 191/266] [D loss: 0.228874, acc:  64%] [G loss: 5.225293, adv: 0.590455, recon: 0.137816, id: 0.602220] time: 0:07:07.061493 \n",
      "[Epoch 2/200] [Batch 192/266] [D loss: 0.186832, acc:  73%] [G loss: 5.935964, adv: 0.551400, recon: 0.169506, id: 0.698522] time: 0:07:07.514596 \n",
      "[Epoch 2/200] [Batch 193/266] [D loss: 0.128258, acc:  86%] [G loss: 5.773759, adv: 0.722911, recon: 0.150210, id: 0.548019] time: 0:07:07.966557 \n",
      "[Epoch 2/200] [Batch 194/266] [D loss: 0.156515, acc:  80%] [G loss: 5.509792, adv: 0.688300, recon: 0.134025, id: 0.699028] time: 0:07:08.418581 \n",
      "[Epoch 2/200] [Batch 195/266] [D loss: 0.150940, acc:  78%] [G loss: 5.984058, adv: 0.699019, recon: 0.154404, id: 0.788366] time: 0:07:08.865330 \n",
      "[Epoch 2/200] [Batch 196/266] [D loss: 0.173701, acc:  77%] [G loss: 5.510366, adv: 0.628697, recon: 0.140061, id: 0.629969] time: 0:07:09.318953 \n",
      "[Epoch 2/200] [Batch 197/266] [D loss: 0.264504, acc:  61%] [G loss: 5.408407, adv: 0.553320, recon: 0.148217, id: 0.597723] time: 0:07:09.792396 \n",
      "[Epoch 2/200] [Batch 198/266] [D loss: 0.214281, acc:  68%] [G loss: 5.432470, adv: 0.581988, recon: 0.139578, id: 0.612757] time: 0:07:10.247712 \n",
      "[Epoch 2/200] [Batch 199/266] [D loss: 0.173092, acc:  75%] [G loss: 5.277031, adv: 0.632299, recon: 0.123725, id: 0.641869] time: 0:07:10.702509 \n",
      "[Epoch 2/200] [Batch 200/266] [D loss: 0.241813, acc:  74%] [G loss: 5.287296, adv: 0.603659, recon: 0.146725, id: 0.460866] time: 0:07:11.155087 \n",
      "[Epoch 2/200] [Batch 201/266] [D loss: 0.175731, acc:  73%] [G loss: 5.669206, adv: 0.683470, recon: 0.147411, id: 0.575458] time: 0:07:11.854412 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 202/266] [D loss: 0.258296, acc:  58%] [G loss: 5.549342, adv: 0.680128, recon: 0.137907, id: 0.562119] time: 0:07:12.304339 \n",
      "[Epoch 2/200] [Batch 203/266] [D loss: 0.231908, acc:  65%] [G loss: 4.947065, adv: 0.602592, recon: 0.120371, id: 0.589802] time: 0:07:12.760226 \n",
      "[Epoch 2/200] [Batch 204/266] [D loss: 0.256149, acc:  58%] [G loss: 5.366032, adv: 0.600651, recon: 0.145581, id: 0.680454] time: 0:07:13.229391 \n",
      "[Epoch 2/200] [Batch 205/266] [D loss: 0.166506, acc:  79%] [G loss: 5.608142, adv: 0.596043, recon: 0.149366, id: 0.567942] time: 0:07:13.676120 \n",
      "[Epoch 2/200] [Batch 206/266] [D loss: 0.274882, acc:  53%] [G loss: 5.911067, adv: 0.513385, recon: 0.170979, id: 0.606429] time: 0:07:14.127755 \n",
      "[Epoch 2/200] [Batch 207/266] [D loss: 0.187035, acc:  71%] [G loss: 5.695488, adv: 0.590984, recon: 0.159043, id: 0.592834] time: 0:07:14.583322 \n",
      "[Epoch 2/200] [Batch 208/266] [D loss: 0.254214, acc:  55%] [G loss: 5.902806, adv: 0.587337, recon: 0.161345, id: 0.735990] time: 0:07:15.053741 \n",
      "[Epoch 2/200] [Batch 209/266] [D loss: 0.192103, acc:  71%] [G loss: 5.352964, adv: 0.588859, recon: 0.137221, id: 0.639287] time: 0:07:15.508111 \n",
      "[Epoch 2/200] [Batch 210/266] [D loss: 0.228210, acc:  66%] [G loss: 4.998602, adv: 0.563711, recon: 0.122991, id: 0.735034] time: 0:07:15.958457 \n",
      "[Epoch 2/200] [Batch 211/266] [D loss: 0.205722, acc:  72%] [G loss: 5.449771, adv: 0.617606, recon: 0.137853, id: 0.715671] time: 0:07:16.413350 \n",
      "[Epoch 2/200] [Batch 212/266] [D loss: 0.248406, acc:  67%] [G loss: 5.168996, adv: 0.726231, recon: 0.125792, id: 0.550608] time: 0:07:16.869685 \n",
      "[Epoch 2/200] [Batch 213/266] [D loss: 0.291724, acc:  51%] [G loss: 4.863484, adv: 0.479624, recon: 0.128510, id: 0.733871] time: 0:07:17.317770 \n",
      "[Epoch 2/200] [Batch 214/266] [D loss: 0.163756, acc:  75%] [G loss: 6.614965, adv: 0.606818, recon: 0.188584, id: 0.679563] time: 0:07:17.770419 \n",
      "[Epoch 2/200] [Batch 215/266] [D loss: 0.135862, acc:  84%] [G loss: 5.665855, adv: 0.678276, recon: 0.143982, id: 0.645620] time: 0:07:18.250366 \n",
      "[Epoch 2/200] [Batch 216/266] [D loss: 0.174415, acc:  72%] [G loss: 5.161271, adv: 0.613245, recon: 0.131958, id: 0.653068] time: 0:07:18.735941 \n",
      "[Epoch 2/200] [Batch 217/266] [D loss: 0.122335, acc:  84%] [G loss: 5.217569, adv: 0.741802, recon: 0.124953, id: 0.515560] time: 0:07:19.185738 \n",
      "[Epoch 2/200] [Batch 218/266] [D loss: 0.125988, acc:  84%] [G loss: 6.235756, adv: 0.752059, recon: 0.162878, id: 0.621878] time: 0:07:19.639220 \n",
      "[Epoch 2/200] [Batch 219/266] [D loss: 0.123842, acc:  85%] [G loss: 5.827475, adv: 0.719139, recon: 0.154115, id: 0.595329] time: 0:07:20.099361 \n",
      "[Epoch 2/200] [Batch 220/266] [D loss: 0.229624, acc:  67%] [G loss: 5.243820, adv: 0.568022, recon: 0.139042, id: 0.679283] time: 0:07:20.549069 \n",
      "[Epoch 2/200] [Batch 221/266] [D loss: 0.188719, acc:  71%] [G loss: 5.478760, adv: 0.585312, recon: 0.147511, id: 0.611641] time: 0:07:21.028906 \n",
      "[Epoch 2/200] [Batch 222/266] [D loss: 0.215198, acc:  64%] [G loss: 5.514186, adv: 0.585474, recon: 0.150496, id: 0.674878] time: 0:07:21.481661 \n",
      "[Epoch 2/200] [Batch 223/266] [D loss: 0.264812, acc:  56%] [G loss: 4.830508, adv: 0.603937, recon: 0.115313, id: 0.676459] time: 0:07:21.941620 \n",
      "[Epoch 2/200] [Batch 224/266] [D loss: 0.197450, acc:  70%] [G loss: 5.271555, adv: 0.613715, recon: 0.138813, id: 0.610473] time: 0:07:22.396910 \n",
      "[Epoch 2/200] [Batch 225/266] [D loss: 0.273814, acc:  58%] [G loss: 5.931102, adv: 0.523510, recon: 0.172506, id: 0.552278] time: 0:07:22.859991 \n",
      "[Epoch 2/200] [Batch 226/266] [D loss: 0.282778, acc:  49%] [G loss: 5.578037, adv: 0.599326, recon: 0.142895, id: 0.637431] time: 0:07:23.310370 \n",
      "[Epoch 2/200] [Batch 227/266] [D loss: 0.307670, acc:  54%] [G loss: 5.704455, adv: 0.494334, recon: 0.158321, id: 0.685863] time: 0:07:23.766340 \n",
      "[Epoch 2/200] [Batch 228/266] [D loss: 0.172488, acc:  73%] [G loss: 5.414268, adv: 0.626210, recon: 0.146628, id: 0.515375] time: 0:07:24.221247 \n",
      "[Epoch 2/200] [Batch 229/266] [D loss: 0.158335, acc:  77%] [G loss: 5.928739, adv: 0.650903, recon: 0.160505, id: 0.675996] time: 0:07:24.684680 \n",
      "[Epoch 2/200] [Batch 230/266] [D loss: 0.307580, acc:  50%] [G loss: 5.004226, adv: 0.574533, recon: 0.128721, id: 0.640755] time: 0:07:25.142841 \n",
      "[Epoch 2/200] [Batch 231/266] [D loss: 0.178910, acc:  76%] [G loss: 5.129539, adv: 0.621423, recon: 0.130615, id: 0.559867] time: 0:07:25.594567 \n",
      "[Epoch 2/200] [Batch 232/266] [D loss: 0.269096, acc:  63%] [G loss: 5.257398, adv: 0.471740, recon: 0.144444, id: 0.668359] time: 0:07:26.048822 \n",
      "[Epoch 2/200] [Batch 233/266] [D loss: 0.243419, acc:  62%] [G loss: 5.413413, adv: 0.656292, recon: 0.138366, id: 0.680938] time: 0:07:26.500157 \n",
      "[Epoch 2/200] [Batch 234/266] [D loss: 0.185264, acc:  70%] [G loss: 6.216400, adv: 0.648847, recon: 0.173809, id: 0.638216] time: 0:07:26.953714 \n",
      "[Epoch 2/200] [Batch 235/266] [D loss: 0.119968, acc:  84%] [G loss: 5.313881, adv: 0.694033, recon: 0.128087, id: 0.620441] time: 0:07:27.410328 \n",
      "[Epoch 2/200] [Batch 236/266] [D loss: 0.192525, acc:  72%] [G loss: 5.384432, adv: 0.600136, recon: 0.139653, id: 0.624694] time: 0:07:27.858668 \n",
      "[Epoch 2/200] [Batch 237/266] [D loss: 0.171355, acc:  74%] [G loss: 5.410738, adv: 0.612771, recon: 0.140656, id: 0.531500] time: 0:07:28.306948 \n",
      "[Epoch 2/200] [Batch 238/266] [D loss: 0.214329, acc:  66%] [G loss: 5.676676, adv: 0.702553, recon: 0.145806, id: 0.643364] time: 0:07:28.762489 \n",
      "[Epoch 2/200] [Batch 239/266] [D loss: 0.168674, acc:  78%] [G loss: 5.989263, adv: 0.648059, recon: 0.164141, id: 0.680557] time: 0:07:29.218387 \n",
      "[Epoch 2/200] [Batch 240/266] [D loss: 0.255900, acc:  59%] [G loss: 4.793068, adv: 0.495412, recon: 0.122641, id: 0.724107] time: 0:07:29.678556 \n",
      "[Epoch 2/200] [Batch 241/266] [D loss: 0.253381, acc:  55%] [G loss: 5.663709, adv: 0.627454, recon: 0.148752, id: 0.735522] time: 0:07:30.133291 \n",
      "[Epoch 2/200] [Batch 242/266] [D loss: 0.226418, acc:  66%] [G loss: 5.060201, adv: 0.578083, recon: 0.131562, id: 0.618547] time: 0:07:30.582260 \n",
      "[Epoch 2/200] [Batch 243/266] [D loss: 0.134850, acc:  82%] [G loss: 5.492256, adv: 0.697468, recon: 0.136117, id: 0.611822] time: 0:07:31.064398 \n",
      "[Epoch 2/200] [Batch 244/266] [D loss: 0.345635, acc:  50%] [G loss: 5.554583, adv: 0.530279, recon: 0.148416, id: 0.739354] time: 0:07:31.517566 \n",
      "[Epoch 2/200] [Batch 245/266] [D loss: 0.186567, acc:  77%] [G loss: 5.669499, adv: 0.626963, recon: 0.154428, id: 0.580265] time: 0:07:31.975498 \n",
      "[Epoch 2/200] [Batch 246/266] [D loss: 0.098174, acc:  90%] [G loss: 6.064416, adv: 0.799697, recon: 0.150048, id: 0.591385] time: 0:07:32.427149 \n",
      "[Epoch 2/200] [Batch 247/266] [D loss: 0.333741, acc:  45%] [G loss: 5.470108, adv: 0.554670, recon: 0.149329, id: 0.584180] time: 0:07:32.887589 \n",
      "[Epoch 2/200] [Batch 248/266] [D loss: 0.246100, acc:  66%] [G loss: 5.352351, adv: 0.579557, recon: 0.140891, id: 0.630017] time: 0:07:33.399012 \n",
      "[Epoch 2/200] [Batch 249/266] [D loss: 0.145143, acc:  84%] [G loss: 5.239277, adv: 0.799103, recon: 0.119062, id: 0.531888] time: 0:07:33.852573 \n",
      "[Epoch 2/200] [Batch 250/266] [D loss: 0.281402, acc:  59%] [G loss: 5.338370, adv: 0.516402, recon: 0.144606, id: 0.580384] time: 0:07:34.295982 \n",
      "[Epoch 2/200] [Batch 251/266] [D loss: 0.331579, acc:  48%] [G loss: 4.839675, adv: 0.559318, recon: 0.123738, id: 0.517990] time: 0:07:34.748026 \n",
      "[Epoch 2/200] [Batch 252/266] [D loss: 0.218427, acc:  70%] [G loss: 5.642821, adv: 0.685898, recon: 0.148197, id: 0.573994] time: 0:07:35.201738 \n",
      "[Epoch 2/200] [Batch 253/266] [D loss: 0.157119, acc:  80%] [G loss: 5.988216, adv: 0.635262, recon: 0.160932, id: 0.630335] time: 0:07:35.649211 \n",
      "[Epoch 2/200] [Batch 254/266] [D loss: 0.275708, acc:  57%] [G loss: 5.124794, adv: 0.482305, recon: 0.129701, id: 0.717751] time: 0:07:36.107371 \n",
      "[Epoch 2/200] [Batch 255/266] [D loss: 0.201534, acc:  66%] [G loss: 5.289143, adv: 0.619010, recon: 0.140157, id: 0.575905] time: 0:07:36.558748 \n",
      "[Epoch 2/200] [Batch 256/266] [D loss: 0.270657, acc:  60%] [G loss: 5.429936, adv: 0.627447, recon: 0.145067, id: 0.607932] time: 0:07:37.009176 \n",
      "[Epoch 2/200] [Batch 257/266] [D loss: 0.174093, acc:  71%] [G loss: 6.014387, adv: 0.719774, recon: 0.151012, id: 0.601213] time: 0:07:37.463836 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 258/266] [D loss: 0.167458, acc:  75%] [G loss: 5.185044, adv: 0.647614, recon: 0.132435, id: 0.611313] time: 0:07:37.955860 \n",
      "[Epoch 2/200] [Batch 259/266] [D loss: 0.316172, acc:  43%] [G loss: 4.711365, adv: 0.496803, recon: 0.119481, id: 0.673755] time: 0:07:38.408720 \n",
      "[Epoch 2/200] [Batch 260/266] [D loss: 0.265986, acc:  54%] [G loss: 5.267325, adv: 0.669522, recon: 0.140215, id: 0.500813] time: 0:07:38.863552 \n",
      "[Epoch 2/200] [Batch 261/266] [D loss: 0.153394, acc:  79%] [G loss: 6.300383, adv: 0.739005, recon: 0.180195, id: 0.657074] time: 0:07:39.316130 \n",
      "[Epoch 2/200] [Batch 262/266] [D loss: 0.254475, acc:  61%] [G loss: 5.257874, adv: 0.526122, recon: 0.140457, id: 0.698027] time: 0:07:39.772235 \n",
      "[Epoch 2/200] [Batch 263/266] [D loss: 0.160365, acc:  80%] [G loss: 5.652988, adv: 0.646072, recon: 0.142758, id: 0.762292] time: 0:07:40.232053 \n",
      "[Epoch 2/200] [Batch 264/266] [D loss: 0.251564, acc:  64%] [G loss: 5.971096, adv: 0.558548, recon: 0.162068, id: 0.887795] time: 0:07:40.687592 \n",
      "[Epoch 3/200] [Batch 0/266] [D loss: 0.136958, acc:  83%] [G loss: 5.270044, adv: 0.647650, recon: 0.128371, id: 0.732038] time: 0:07:41.415452 \n",
      "[Epoch 3/200] [Batch 1/266] [D loss: 0.232681, acc:  62%] [G loss: 5.376783, adv: 0.657026, recon: 0.139382, id: 0.614161] time: 0:07:42.118702 \n",
      "[Epoch 3/200] [Batch 2/266] [D loss: 0.223683, acc:  70%] [G loss: 4.963345, adv: 0.554148, recon: 0.128236, id: 0.625214] time: 0:07:42.579216 \n",
      "[Epoch 3/200] [Batch 3/266] [D loss: 0.184784, acc:  73%] [G loss: 5.520032, adv: 0.635705, recon: 0.145738, id: 0.499723] time: 0:07:43.033548 \n",
      "[Epoch 3/200] [Batch 4/266] [D loss: 0.207979, acc:  73%] [G loss: 5.619820, adv: 0.569112, recon: 0.149912, id: 0.648279] time: 0:07:43.480772 \n",
      "[Epoch 3/200] [Batch 5/266] [D loss: 0.222784, acc:  65%] [G loss: 5.008916, adv: 0.535721, recon: 0.134124, id: 0.534564] time: 0:07:43.938839 \n",
      "[Epoch 3/200] [Batch 6/266] [D loss: 0.186798, acc:  74%] [G loss: 4.883938, adv: 0.611377, recon: 0.119187, id: 0.493046] time: 0:07:44.394729 \n",
      "[Epoch 3/200] [Batch 7/266] [D loss: 0.242683, acc:  67%] [G loss: 5.393474, adv: 0.623023, recon: 0.145266, id: 0.472978] time: 0:07:44.846923 \n",
      "[Epoch 3/200] [Batch 8/266] [D loss: 0.218930, acc:  64%] [G loss: 4.571722, adv: 0.511607, recon: 0.115806, id: 0.541392] time: 0:07:45.300378 \n",
      "[Epoch 3/200] [Batch 9/266] [D loss: 0.284867, acc:  52%] [G loss: 4.842332, adv: 0.584750, recon: 0.122809, id: 0.628352] time: 0:07:45.756161 \n",
      "[Epoch 3/200] [Batch 10/266] [D loss: 0.136686, acc:  78%] [G loss: 5.648279, adv: 0.733094, recon: 0.140613, id: 0.672804] time: 0:07:46.207599 \n",
      "[Epoch 3/200] [Batch 11/266] [D loss: 0.189811, acc:  74%] [G loss: 5.791466, adv: 0.667852, recon: 0.147537, id: 0.700260] time: 0:07:46.659345 \n",
      "[Epoch 3/200] [Batch 12/266] [D loss: 0.251147, acc:  57%] [G loss: 5.285028, adv: 0.491003, recon: 0.136958, id: 0.741184] time: 0:07:47.114140 \n",
      "[Epoch 3/200] [Batch 13/266] [D loss: 0.099945, acc:  90%] [G loss: 5.465758, adv: 0.711548, recon: 0.130477, id: 0.692076] time: 0:07:47.569437 \n",
      "[Epoch 3/200] [Batch 14/266] [D loss: 0.112284, acc:  85%] [G loss: 6.385673, adv: 0.738601, recon: 0.163973, id: 0.692452] time: 0:07:48.022145 \n",
      "[Epoch 3/200] [Batch 15/266] [D loss: 0.199388, acc:  70%] [G loss: 5.551372, adv: 0.562920, recon: 0.148961, id: 0.621569] time: 0:07:48.477230 \n",
      "[Epoch 3/200] [Batch 16/266] [D loss: 0.137972, acc:  81%] [G loss: 5.691773, adv: 0.687917, recon: 0.145863, id: 0.633572] time: 0:07:48.934654 \n",
      "[Epoch 3/200] [Batch 17/266] [D loss: 0.227996, acc:  68%] [G loss: 5.587574, adv: 0.636911, recon: 0.136789, id: 0.747299] time: 0:07:49.393988 \n",
      "[Epoch 3/200] [Batch 18/266] [D loss: 0.155327, acc:  78%] [G loss: 5.579513, adv: 0.774561, recon: 0.138725, id: 0.610654] time: 0:07:49.856290 \n",
      "[Epoch 3/200] [Batch 19/266] [D loss: 0.230309, acc:  66%] [G loss: 5.637892, adv: 0.654860, recon: 0.144951, id: 0.600051] time: 0:07:50.311198 \n",
      "[Epoch 3/200] [Batch 20/266] [D loss: 0.195687, acc:  70%] [G loss: 6.338427, adv: 0.602389, recon: 0.177984, id: 0.810988] time: 0:07:50.762649 \n",
      "[Epoch 3/200] [Batch 21/266] [D loss: 0.235980, acc:  67%] [G loss: 5.933346, adv: 0.590117, recon: 0.160424, id: 0.749070] time: 0:07:51.223256 \n",
      "[Epoch 3/200] [Batch 22/266] [D loss: 0.223503, acc:  64%] [G loss: 6.147897, adv: 0.627422, recon: 0.179522, id: 0.583851] time: 0:07:51.670247 \n",
      "[Epoch 3/200] [Batch 23/266] [D loss: 0.221744, acc:  67%] [G loss: 5.197123, adv: 0.669335, recon: 0.133851, id: 0.445995] time: 0:07:52.125093 \n",
      "[Epoch 3/200] [Batch 24/266] [D loss: 0.401078, acc:  39%] [G loss: 5.690692, adv: 0.853287, recon: 0.132979, id: 0.699266] time: 0:07:52.582095 \n",
      "[Epoch 3/200] [Batch 25/266] [D loss: 0.588003, acc:  29%] [G loss: 4.897015, adv: 0.495361, recon: 0.126787, id: 0.607977] time: 0:07:53.034451 \n",
      "[Epoch 3/200] [Batch 26/266] [D loss: 0.356307, acc:  46%] [G loss: 4.994365, adv: 0.447996, recon: 0.133382, id: 0.695905] time: 0:07:53.482701 \n",
      "[Epoch 3/200] [Batch 27/266] [D loss: 0.287985, acc:  53%] [G loss: 4.977346, adv: 0.594146, recon: 0.116494, id: 0.778628] time: 0:07:53.934356 \n",
      "[Epoch 3/200] [Batch 28/266] [D loss: 0.248507, acc:  59%] [G loss: 5.910918, adv: 0.536722, recon: 0.161516, id: 0.823990] time: 0:07:54.386021 \n",
      "[Epoch 3/200] [Batch 29/266] [D loss: 0.256442, acc:  56%] [G loss: 5.503288, adv: 0.620715, recon: 0.141153, id: 0.717211] time: 0:07:54.840140 \n",
      "[Epoch 3/200] [Batch 30/266] [D loss: 0.299047, acc:  51%] [G loss: 4.619020, adv: 0.412125, recon: 0.118489, id: 0.741871] time: 0:07:55.287246 \n",
      "[Epoch 3/200] [Batch 31/266] [D loss: 0.251793, acc:  60%] [G loss: 5.407373, adv: 0.480264, recon: 0.166502, id: 0.423245] time: 0:07:55.736286 \n",
      "[Epoch 3/200] [Batch 32/266] [D loss: 0.202510, acc:  70%] [G loss: 5.437986, adv: 0.507526, recon: 0.163695, id: 0.522796] time: 0:07:56.190629 \n",
      "[Epoch 3/200] [Batch 33/266] [D loss: 0.193231, acc:  70%] [G loss: 5.270498, adv: 0.609977, recon: 0.138598, id: 0.582852] time: 0:07:56.645510 \n",
      "[Epoch 3/200] [Batch 34/266] [D loss: 0.210340, acc:  67%] [G loss: 5.250895, adv: 0.539116, recon: 0.137447, id: 0.671376] time: 0:07:57.099227 \n",
      "[Epoch 3/200] [Batch 35/266] [D loss: 0.251024, acc:  64%] [G loss: 5.010932, adv: 0.480573, recon: 0.133544, id: 0.620768] time: 0:07:57.549090 \n",
      "[Epoch 3/200] [Batch 36/266] [D loss: 0.264520, acc:  61%] [G loss: 5.055229, adv: 0.480366, recon: 0.131049, id: 0.651596] time: 0:07:57.996910 \n",
      "[Epoch 3/200] [Batch 37/266] [D loss: 0.192157, acc:  70%] [G loss: 5.218590, adv: 0.520715, recon: 0.141074, id: 0.588400] time: 0:07:58.450370 \n",
      "[Epoch 3/200] [Batch 38/266] [D loss: 0.179114, acc:  75%] [G loss: 5.670637, adv: 0.626538, recon: 0.146880, id: 0.701151] time: 0:07:58.905545 \n",
      "[Epoch 3/200] [Batch 39/266] [D loss: 0.188413, acc:  73%] [G loss: 4.788105, adv: 0.560106, recon: 0.121441, id: 0.602209] time: 0:07:59.356474 \n",
      "[Epoch 3/200] [Batch 40/266] [D loss: 0.148050, acc:  80%] [G loss: 5.377496, adv: 0.656953, recon: 0.129780, id: 0.660595] time: 0:07:59.811179 \n",
      "[Epoch 3/200] [Batch 41/266] [D loss: 0.262712, acc:  54%] [G loss: 5.208345, adv: 0.514997, recon: 0.138498, id: 0.601288] time: 0:08:00.308513 \n",
      "[Epoch 3/200] [Batch 42/266] [D loss: 0.153331, acc:  79%] [G loss: 5.727531, adv: 0.670298, recon: 0.149188, id: 0.468041] time: 0:08:00.765045 \n",
      "[Epoch 3/200] [Batch 43/266] [D loss: 0.222593, acc:  61%] [G loss: 5.756945, adv: 0.597572, recon: 0.159285, id: 0.663141] time: 0:08:01.209396 \n",
      "[Epoch 3/200] [Batch 44/266] [D loss: 0.177083, acc:  76%] [G loss: 5.575663, adv: 0.662422, recon: 0.149838, id: 0.693365] time: 0:08:01.662460 \n",
      "[Epoch 3/200] [Batch 45/266] [D loss: 0.126035, acc:  84%] [G loss: 6.097562, adv: 0.733413, recon: 0.161482, id: 0.608585] time: 0:08:02.111805 \n",
      "[Epoch 3/200] [Batch 46/266] [D loss: 0.158491, acc:  82%] [G loss: 5.676608, adv: 0.655487, recon: 0.151612, id: 0.561046] time: 0:08:02.564951 \n",
      "[Epoch 3/200] [Batch 47/266] [D loss: 0.169019, acc:  78%] [G loss: 6.219765, adv: 0.730254, recon: 0.158789, id: 0.785447] time: 0:08:03.014849 \n",
      "[Epoch 3/200] [Batch 48/266] [D loss: 0.272233, acc:  59%] [G loss: 5.134150, adv: 0.497482, recon: 0.128977, id: 0.759320] time: 0:08:03.469894 \n",
      "[Epoch 3/200] [Batch 49/266] [D loss: 0.248389, acc:  57%] [G loss: 5.316988, adv: 0.475926, recon: 0.143321, id: 0.664254] time: 0:08:03.928107 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 50/266] [D loss: 0.161020, acc:  78%] [G loss: 5.273507, adv: 0.709291, recon: 0.127275, id: 0.628021] time: 0:08:04.383423 \n",
      "[Epoch 3/200] [Batch 51/266] [D loss: 0.165609, acc:  73%] [G loss: 5.267579, adv: 0.650696, recon: 0.127215, id: 0.657707] time: 0:08:04.835454 \n",
      "[Epoch 3/200] [Batch 52/266] [D loss: 0.254120, acc:  60%] [G loss: 5.547364, adv: 0.589298, recon: 0.149084, id: 0.653902] time: 0:08:05.295650 \n",
      "[Epoch 3/200] [Batch 53/266] [D loss: 0.155153, acc:  78%] [G loss: 5.415925, adv: 0.726197, recon: 0.128025, id: 0.577205] time: 0:08:05.745878 \n",
      "[Epoch 3/200] [Batch 54/266] [D loss: 0.158519, acc:  80%] [G loss: 5.129499, adv: 0.683467, recon: 0.120285, id: 0.669326] time: 0:08:06.195136 \n",
      "[Epoch 3/200] [Batch 55/266] [D loss: 0.236394, acc:  60%] [G loss: 4.915581, adv: 0.612435, recon: 0.121226, id: 0.566349] time: 0:08:06.651508 \n",
      "[Epoch 3/200] [Batch 56/266] [D loss: 0.158357, acc:  79%] [G loss: 5.010299, adv: 0.569914, recon: 0.119339, id: 0.744685] time: 0:08:07.103180 \n",
      "[Epoch 3/200] [Batch 57/266] [D loss: 0.164114, acc:  76%] [G loss: 5.925071, adv: 0.628426, recon: 0.154874, id: 0.688208] time: 0:08:07.564183 \n",
      "[Epoch 3/200] [Batch 58/266] [D loss: 0.183473, acc:  72%] [G loss: 5.575474, adv: 0.643013, recon: 0.141531, id: 0.568818] time: 0:08:08.019770 \n",
      "[Epoch 3/200] [Batch 59/266] [D loss: 0.280167, acc:  51%] [G loss: 5.061767, adv: 0.599843, recon: 0.116294, id: 0.609769] time: 0:08:08.471994 \n",
      "[Epoch 3/200] [Batch 60/266] [D loss: 0.141145, acc:  81%] [G loss: 5.994602, adv: 0.779677, recon: 0.137619, id: 0.708798] time: 0:08:08.931200 \n",
      "[Epoch 3/200] [Batch 61/266] [D loss: 0.264074, acc:  56%] [G loss: 5.260411, adv: 0.628384, recon: 0.126818, id: 0.661285] time: 0:08:09.388627 \n",
      "[Epoch 3/200] [Batch 62/266] [D loss: 0.102190, acc:  87%] [G loss: 6.238262, adv: 0.879258, recon: 0.146034, id: 0.693969] time: 0:08:09.840697 \n",
      "[Epoch 3/200] [Batch 63/266] [D loss: 0.312815, acc:  52%] [G loss: 5.358229, adv: 0.600334, recon: 0.141036, id: 0.662501] time: 0:08:10.296948 \n",
      "[Epoch 3/200] [Batch 64/266] [D loss: 0.232084, acc:  60%] [G loss: 5.153766, adv: 0.664506, recon: 0.129071, id: 0.556457] time: 0:08:10.754256 \n",
      "[Epoch 3/200] [Batch 65/266] [D loss: 0.178465, acc:  74%] [G loss: 6.563848, adv: 0.711317, recon: 0.185995, id: 0.681528] time: 0:08:11.210482 \n",
      "[Epoch 3/200] [Batch 66/266] [D loss: 0.270863, acc:  57%] [G loss: 5.097770, adv: 0.487279, recon: 0.134808, id: 0.668331] time: 0:08:11.666185 \n",
      "[Epoch 3/200] [Batch 67/266] [D loss: 0.225628, acc:  67%] [G loss: 5.883509, adv: 0.595851, recon: 0.160002, id: 0.726732] time: 0:08:12.122048 \n",
      "[Epoch 3/200] [Batch 68/266] [D loss: 0.157120, acc:  79%] [G loss: 5.654121, adv: 0.669778, recon: 0.151766, id: 0.568042] time: 0:08:12.581561 \n",
      "[Epoch 3/200] [Batch 69/266] [D loss: 0.103084, acc:  89%] [G loss: 5.906310, adv: 0.785274, recon: 0.149204, id: 0.638431] time: 0:08:13.035342 \n",
      "[Epoch 3/200] [Batch 70/266] [D loss: 0.176656, acc:  74%] [G loss: 5.384370, adv: 0.731233, recon: 0.130558, id: 0.618043] time: 0:08:13.486794 \n",
      "[Epoch 3/200] [Batch 71/266] [D loss: 0.186839, acc:  73%] [G loss: 5.117748, adv: 0.595209, recon: 0.133338, id: 0.538812] time: 0:08:13.940384 \n",
      "[Epoch 3/200] [Batch 72/266] [D loss: 0.065225, acc:  94%] [G loss: 5.109350, adv: 0.834353, recon: 0.104294, id: 0.570780] time: 0:08:14.393655 \n",
      "[Epoch 3/200] [Batch 73/266] [D loss: 0.215060, acc:  73%] [G loss: 5.787047, adv: 0.645423, recon: 0.156424, id: 0.630941] time: 0:08:14.857913 \n",
      "[Epoch 3/200] [Batch 74/266] [D loss: 0.259274, acc:  62%] [G loss: 4.694450, adv: 0.575656, recon: 0.113834, id: 0.591015] time: 0:08:15.311464 \n",
      "[Epoch 3/200] [Batch 75/266] [D loss: 0.198544, acc:  69%] [G loss: 5.079498, adv: 0.675997, recon: 0.122512, id: 0.559319] time: 0:08:15.765455 \n",
      "[Epoch 3/200] [Batch 76/266] [D loss: 0.224449, acc:  65%] [G loss: 5.052707, adv: 0.633510, recon: 0.118739, id: 0.681206] time: 0:08:16.215313 \n",
      "[Epoch 3/200] [Batch 77/266] [D loss: 0.199868, acc:  67%] [G loss: 4.953339, adv: 0.583474, recon: 0.124732, id: 0.630376] time: 0:08:16.662969 \n",
      "[Epoch 3/200] [Batch 78/266] [D loss: 0.198445, acc:  68%] [G loss: 5.397400, adv: 0.601013, recon: 0.148149, id: 0.548001] time: 0:08:17.118256 \n",
      "[Epoch 3/200] [Batch 79/266] [D loss: 0.182565, acc:  75%] [G loss: 5.496697, adv: 0.617997, recon: 0.146237, id: 0.552547] time: 0:08:17.568576 \n",
      "[Epoch 3/200] [Batch 80/266] [D loss: 0.193040, acc:  73%] [G loss: 5.853564, adv: 0.763300, recon: 0.142277, id: 0.638792] time: 0:08:18.023979 \n",
      "[Epoch 3/200] [Batch 81/266] [D loss: 0.295587, acc:  57%] [G loss: 4.859513, adv: 0.491252, recon: 0.128093, id: 0.626955] time: 0:08:18.477055 \n",
      "[Epoch 3/200] [Batch 82/266] [D loss: 0.218598, acc:  66%] [G loss: 5.468233, adv: 0.542623, recon: 0.145330, id: 0.707474] time: 0:08:18.934050 \n",
      "[Epoch 3/200] [Batch 83/266] [D loss: 0.216917, acc:  65%] [G loss: 5.078788, adv: 0.543941, recon: 0.119110, id: 0.791205] time: 0:08:19.378398 \n",
      "[Epoch 3/200] [Batch 84/266] [D loss: 0.162188, acc:  76%] [G loss: 5.396996, adv: 0.654567, recon: 0.133753, id: 0.694829] time: 0:08:19.849142 \n",
      "[Epoch 3/200] [Batch 85/266] [D loss: 0.245945, acc:  59%] [G loss: 5.928899, adv: 0.620233, recon: 0.156738, id: 0.725672] time: 0:08:20.298139 \n",
      "[Epoch 3/200] [Batch 86/266] [D loss: 0.275064, acc:  51%] [G loss: 5.464649, adv: 0.613504, recon: 0.140962, id: 0.643276] time: 0:08:20.749795 \n",
      "[Epoch 3/200] [Batch 87/266] [D loss: 0.176454, acc:  71%] [G loss: 5.505589, adv: 0.691216, recon: 0.130599, id: 0.659380] time: 0:08:21.203152 \n",
      "[Epoch 3/200] [Batch 88/266] [D loss: 0.221894, acc:  64%] [G loss: 4.980410, adv: 0.623946, recon: 0.117012, id: 0.640763] time: 0:08:21.697253 \n",
      "[Epoch 3/200] [Batch 89/266] [D loss: 0.263287, acc:  64%] [G loss: 5.173301, adv: 0.561972, recon: 0.129144, id: 0.546282] time: 0:08:22.150778 \n",
      "[Epoch 3/200] [Batch 90/266] [D loss: 0.141937, acc:  81%] [G loss: 6.182032, adv: 0.858923, recon: 0.153295, id: 0.608010] time: 0:08:22.606236 \n",
      "[Epoch 3/200] [Batch 91/266] [D loss: 0.200165, acc:  71%] [G loss: 6.163985, adv: 0.665654, recon: 0.178221, id: 0.516887] time: 0:08:23.061708 \n",
      "[Epoch 3/200] [Batch 92/266] [D loss: 0.194317, acc:  70%] [G loss: 6.207214, adv: 0.611721, recon: 0.173601, id: 0.655949] time: 0:08:23.518615 \n",
      "[Epoch 3/200] [Batch 93/266] [D loss: 0.181588, acc:  76%] [G loss: 5.841097, adv: 0.696811, recon: 0.150291, id: 0.632473] time: 0:08:23.972136 \n",
      "[Epoch 3/200] [Batch 94/266] [D loss: 0.182956, acc:  70%] [G loss: 5.654772, adv: 0.694399, recon: 0.146646, id: 0.664146] time: 0:08:24.424765 \n",
      "[Epoch 3/200] [Batch 95/266] [D loss: 0.124182, acc:  82%] [G loss: 5.642889, adv: 0.653803, recon: 0.142006, id: 0.563336] time: 0:08:24.875868 \n",
      "[Epoch 3/200] [Batch 96/266] [D loss: 0.169231, acc:  75%] [G loss: 5.528954, adv: 0.676931, recon: 0.138381, id: 0.615805] time: 0:08:25.324678 \n",
      "[Epoch 3/200] [Batch 97/266] [D loss: 0.187605, acc:  72%] [G loss: 5.754478, adv: 0.709955, recon: 0.156865, id: 0.477792] time: 0:08:25.774376 \n",
      "[Epoch 3/200] [Batch 98/266] [D loss: 0.193981, acc:  70%] [G loss: 5.191433, adv: 0.590901, recon: 0.135718, id: 0.631402] time: 0:08:26.230150 \n",
      "[Epoch 3/200] [Batch 99/266] [D loss: 0.210974, acc:  63%] [G loss: 6.235997, adv: 0.682288, recon: 0.175530, id: 0.600552] time: 0:08:26.683770 \n",
      "[Epoch 3/200] [Batch 100/266] [D loss: 0.171137, acc:  71%] [G loss: 5.467534, adv: 0.701460, recon: 0.140358, id: 0.604634] time: 0:08:27.133136 \n",
      "[Epoch 3/200] [Batch 101/266] [D loss: 0.160923, acc:  81%] [G loss: 5.247453, adv: 0.651856, recon: 0.133169, id: 0.557098] time: 0:08:27.585957 \n",
      "[Epoch 3/200] [Batch 102/266] [D loss: 0.138890, acc:  79%] [G loss: 5.736503, adv: 0.647542, recon: 0.151042, id: 0.602715] time: 0:08:28.038065 \n",
      "[Epoch 3/200] [Batch 103/266] [D loss: 0.245790, acc:  64%] [G loss: 5.307961, adv: 0.619319, recon: 0.135599, id: 0.638595] time: 0:08:28.486997 \n",
      "[Epoch 3/200] [Batch 104/266] [D loss: 0.139899, acc:  80%] [G loss: 5.688690, adv: 0.715047, recon: 0.142400, id: 0.632911] time: 0:08:28.936819 \n",
      "[Epoch 3/200] [Batch 105/266] [D loss: 0.147894, acc:  78%] [G loss: 5.556078, adv: 0.695846, recon: 0.135979, id: 0.754466] time: 0:08:29.387732 \n",
      "[Epoch 3/200] [Batch 106/266] [D loss: 0.109190, acc:  87%] [G loss: 5.592126, adv: 0.762428, recon: 0.132244, id: 0.652854] time: 0:08:29.844454 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 107/266] [D loss: 0.132917, acc:  81%] [G loss: 6.545441, adv: 0.736922, recon: 0.182095, id: 0.681293] time: 0:08:30.308933 \n",
      "[Epoch 3/200] [Batch 108/266] [D loss: 0.186904, acc:  72%] [G loss: 5.590049, adv: 0.632372, recon: 0.145024, id: 0.692375] time: 0:08:30.760298 \n",
      "[Epoch 3/200] [Batch 109/266] [D loss: 0.219520, acc:  64%] [G loss: 5.869432, adv: 0.775288, recon: 0.151552, id: 0.638889] time: 0:08:31.214572 \n",
      "[Epoch 3/200] [Batch 110/266] [D loss: 0.239966, acc:  60%] [G loss: 5.343834, adv: 0.627404, recon: 0.136288, id: 0.730084] time: 0:08:31.668410 \n",
      "[Epoch 3/200] [Batch 111/266] [D loss: 0.165750, acc:  77%] [G loss: 5.470853, adv: 0.727329, recon: 0.136459, id: 0.664325] time: 0:08:32.128325 \n",
      "[Epoch 3/200] [Batch 112/266] [D loss: 0.179021, acc:  74%] [G loss: 5.759476, adv: 0.631620, recon: 0.156243, id: 0.684138] time: 0:08:32.580720 \n",
      "[Epoch 3/200] [Batch 113/266] [D loss: 0.243629, acc:  68%] [G loss: 5.572892, adv: 0.697464, recon: 0.141746, id: 0.499766] time: 0:08:33.027061 \n",
      "[Epoch 3/200] [Batch 114/266] [D loss: 0.090129, acc:  89%] [G loss: 6.406143, adv: 0.840818, recon: 0.169016, id: 0.648791] time: 0:08:33.479510 \n",
      "[Epoch 3/200] [Batch 115/266] [D loss: 0.100900, acc:  88%] [G loss: 6.386119, adv: 0.826961, recon: 0.175310, id: 0.512789] time: 0:08:33.934400 \n",
      "[Epoch 3/200] [Batch 116/266] [D loss: 0.393451, acc:  36%] [G loss: 7.662224, adv: 0.754779, recon: 0.235058, id: 0.794125] time: 0:08:34.390101 \n",
      "[Epoch 3/200] [Batch 117/266] [D loss: 0.202590, acc:  72%] [G loss: 6.571843, adv: 0.646778, recon: 0.190221, id: 0.693707] time: 0:08:34.845447 \n",
      "[Epoch 3/200] [Batch 118/266] [D loss: 0.241406, acc:  68%] [G loss: 5.993444, adv: 0.666728, recon: 0.166971, id: 0.660032] time: 0:08:35.299221 \n",
      "[Epoch 3/200] [Batch 119/266] [D loss: 0.152581, acc:  80%] [G loss: 5.858611, adv: 0.713855, recon: 0.152165, id: 0.652743] time: 0:08:35.748594 \n",
      "[Epoch 3/200] [Batch 120/266] [D loss: 0.138320, acc:  82%] [G loss: 5.277456, adv: 0.718364, recon: 0.127975, id: 0.600854] time: 0:08:36.203787 \n",
      "[Epoch 3/200] [Batch 121/266] [D loss: 0.128691, acc:  82%] [G loss: 6.343840, adv: 0.812783, recon: 0.157782, id: 0.716802] time: 0:08:36.657102 \n",
      "[Epoch 3/200] [Batch 122/266] [D loss: 0.154922, acc:  78%] [G loss: 5.340099, adv: 0.716532, recon: 0.139118, id: 0.567643] time: 0:08:37.107924 \n",
      "[Epoch 3/200] [Batch 123/266] [D loss: 0.140165, acc:  80%] [G loss: 5.583583, adv: 0.680139, recon: 0.141751, id: 0.607535] time: 0:08:37.562372 \n",
      "[Epoch 3/200] [Batch 124/266] [D loss: 0.111974, acc:  85%] [G loss: 6.017145, adv: 0.832094, recon: 0.144143, id: 0.703082] time: 0:08:38.020134 \n",
      "[Epoch 3/200] [Batch 125/266] [D loss: 0.231303, acc:  66%] [G loss: 5.008654, adv: 0.594298, recon: 0.129530, id: 0.587276] time: 0:08:38.480519 \n",
      "[Epoch 3/200] [Batch 126/266] [D loss: 0.207279, acc:  68%] [G loss: 5.987463, adv: 0.603384, recon: 0.164236, id: 0.649663] time: 0:08:38.939280 \n",
      "[Epoch 3/200] [Batch 127/266] [D loss: 0.140085, acc:  80%] [G loss: 6.047552, adv: 0.750652, recon: 0.150172, id: 0.711145] time: 0:08:39.385789 \n",
      "[Epoch 3/200] [Batch 128/266] [D loss: 0.165218, acc:  81%] [G loss: 6.142651, adv: 0.722072, recon: 0.161372, id: 0.730528] time: 0:08:39.839401 \n",
      "[Epoch 3/200] [Batch 129/266] [D loss: 0.256114, acc:  59%] [G loss: 5.434810, adv: 0.669352, recon: 0.132807, id: 0.719741] time: 0:08:40.292444 \n",
      "[Epoch 3/200] [Batch 130/266] [D loss: 0.127845, acc:  83%] [G loss: 5.618454, adv: 0.760226, recon: 0.134773, id: 0.723549] time: 0:08:40.745170 \n",
      "[Epoch 3/200] [Batch 131/266] [D loss: 0.295479, acc:  54%] [G loss: 5.219726, adv: 0.664002, recon: 0.137673, id: 0.645592] time: 0:08:41.203393 \n",
      "[Epoch 3/200] [Batch 132/266] [D loss: 0.177952, acc:  73%] [G loss: 5.763300, adv: 0.673153, recon: 0.150911, id: 0.680627] time: 0:08:41.658692 \n",
      "[Epoch 3/200] [Batch 133/266] [D loss: 0.104625, acc:  89%] [G loss: 5.767201, adv: 0.804022, recon: 0.134547, id: 0.718122] time: 0:08:42.110988 \n",
      "[Epoch 3/200] [Batch 134/266] [D loss: 0.148256, acc:  79%] [G loss: 5.561440, adv: 0.734139, recon: 0.126751, id: 0.695235] time: 0:08:42.571037 \n",
      "[Epoch 3/200] [Batch 135/266] [D loss: 0.096496, acc:  90%] [G loss: 6.284330, adv: 0.788351, recon: 0.159481, id: 0.588126] time: 0:08:43.067935 \n",
      "[Epoch 3/200] [Batch 136/266] [D loss: 0.206533, acc:  69%] [G loss: 5.753397, adv: 0.566852, recon: 0.153399, id: 0.679221] time: 0:08:43.526896 \n",
      "[Epoch 3/200] [Batch 137/266] [D loss: 0.269239, acc:  58%] [G loss: 6.442317, adv: 0.825553, recon: 0.169980, id: 0.683752] time: 0:08:43.980542 \n",
      "[Epoch 3/200] [Batch 138/266] [D loss: 0.202318, acc:  70%] [G loss: 6.073816, adv: 0.640344, recon: 0.162622, id: 0.694553] time: 0:08:44.434092 \n",
      "[Epoch 3/200] [Batch 139/266] [D loss: 0.138577, acc:  84%] [G loss: 5.485384, adv: 0.724685, recon: 0.134681, id: 0.604893] time: 0:08:44.888196 \n",
      "[Epoch 3/200] [Batch 140/266] [D loss: 0.148152, acc:  82%] [G loss: 5.176498, adv: 0.715847, recon: 0.114117, id: 0.657280] time: 0:08:45.340165 \n",
      "[Epoch 3/200] [Batch 141/266] [D loss: 0.211137, acc:  71%] [G loss: 6.161447, adv: 0.605419, recon: 0.171479, id: 0.663051] time: 0:08:45.798151 \n",
      "[Epoch 3/200] [Batch 142/266] [D loss: 0.206935, acc:  67%] [G loss: 5.613752, adv: 0.655631, recon: 0.150748, id: 0.500312] time: 0:08:46.246864 \n",
      "[Epoch 3/200] [Batch 143/266] [D loss: 0.234605, acc:  63%] [G loss: 5.192677, adv: 0.664291, recon: 0.126063, id: 0.656412] time: 0:08:46.703983 \n",
      "[Epoch 3/200] [Batch 144/266] [D loss: 0.121951, acc:  83%] [G loss: 5.466820, adv: 0.729983, recon: 0.136505, id: 0.655034] time: 0:08:47.158407 \n",
      "[Epoch 3/200] [Batch 145/266] [D loss: 0.336443, acc:  44%] [G loss: 5.317347, adv: 0.589474, recon: 0.139585, id: 0.641452] time: 0:08:47.610308 \n",
      "[Epoch 3/200] [Batch 146/266] [D loss: 0.165573, acc:  77%] [G loss: 5.562358, adv: 0.656789, recon: 0.133341, id: 0.788297] time: 0:08:48.060351 \n",
      "[Epoch 3/200] [Batch 147/266] [D loss: 0.210924, acc:  64%] [G loss: 5.196828, adv: 0.625994, recon: 0.125840, id: 0.673821] time: 0:08:48.516287 \n",
      "[Epoch 3/200] [Batch 148/266] [D loss: 0.094626, acc:  93%] [G loss: 5.993247, adv: 0.871204, recon: 0.147019, id: 0.669671] time: 0:08:48.970927 \n",
      "[Epoch 3/200] [Batch 149/266] [D loss: 0.189660, acc:  75%] [G loss: 5.905997, adv: 0.686669, recon: 0.146929, id: 0.719753] time: 0:08:49.447797 \n",
      "[Epoch 3/200] [Batch 150/266] [D loss: 0.154303, acc:  77%] [G loss: 5.925930, adv: 0.728355, recon: 0.157178, id: 0.806178] time: 0:08:49.900702 \n",
      "[Epoch 3/200] [Batch 151/266] [D loss: 0.146664, acc:  77%] [G loss: 6.453931, adv: 0.672313, recon: 0.186991, id: 0.626319] time: 0:08:50.362911 \n",
      "[Epoch 3/200] [Batch 152/266] [D loss: 0.195552, acc:  71%] [G loss: 5.847788, adv: 0.617927, recon: 0.159409, id: 0.664995] time: 0:08:50.819134 \n",
      "[Epoch 3/200] [Batch 153/266] [D loss: 0.220334, acc:  70%] [G loss: 6.375139, adv: 1.074340, recon: 0.141519, id: 0.690956] time: 0:08:51.286810 \n",
      "[Epoch 3/200] [Batch 154/266] [D loss: 0.222482, acc:  72%] [G loss: 5.498192, adv: 0.693086, recon: 0.135668, id: 0.667987] time: 0:08:51.738831 \n",
      "[Epoch 3/200] [Batch 155/266] [D loss: 0.633808, acc:  50%] [G loss: 5.389483, adv: 0.736981, recon: 0.122486, id: 0.721886] time: 0:08:52.193680 \n",
      "[Epoch 3/200] [Batch 156/266] [D loss: 0.392173, acc:  58%] [G loss: 5.379368, adv: 0.519104, recon: 0.146648, id: 0.634365] time: 0:08:52.644981 \n",
      "[Epoch 3/200] [Batch 157/266] [D loss: 0.309968, acc:  53%] [G loss: 5.495313, adv: 0.513028, recon: 0.150676, id: 0.652216] time: 0:08:53.102234 \n",
      "[Epoch 3/200] [Batch 158/266] [D loss: 0.233173, acc:  62%] [G loss: 5.498855, adv: 0.513240, recon: 0.158117, id: 0.440205] time: 0:08:53.559858 \n",
      "[Epoch 3/200] [Batch 159/266] [D loss: 0.249941, acc:  58%] [G loss: 5.029335, adv: 0.600847, recon: 0.129339, id: 0.542237] time: 0:08:54.015029 \n",
      "[Epoch 3/200] [Batch 160/266] [D loss: 0.254791, acc:  54%] [G loss: 4.934433, adv: 0.503544, recon: 0.131688, id: 0.633094] time: 0:08:54.470774 \n",
      "[Epoch 3/200] [Batch 161/266] [D loss: 0.251074, acc:  57%] [G loss: 4.956279, adv: 0.471999, recon: 0.132294, id: 0.619301] time: 0:08:54.921010 \n",
      "[Epoch 3/200] [Batch 162/266] [D loss: 0.198208, acc:  71%] [G loss: 5.331639, adv: 0.611409, recon: 0.133076, id: 0.603192] time: 0:08:55.375149 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 163/266] [D loss: 0.204582, acc:  69%] [G loss: 5.383156, adv: 0.606088, recon: 0.141957, id: 0.500746] time: 0:08:55.827570 \n",
      "[Epoch 3/200] [Batch 164/266] [D loss: 0.225719, acc:  69%] [G loss: 4.845709, adv: 0.578053, recon: 0.119905, id: 0.652610] time: 0:08:56.279489 \n",
      "[Epoch 3/200] [Batch 165/266] [D loss: 0.223627, acc:  63%] [G loss: 4.817412, adv: 0.462896, recon: 0.130839, id: 0.616529] time: 0:08:56.735437 \n",
      "[Epoch 3/200] [Batch 166/266] [D loss: 0.229621, acc:  69%] [G loss: 6.459067, adv: 0.511473, recon: 0.188034, id: 0.752584] time: 0:08:57.188959 \n",
      "[Epoch 3/200] [Batch 167/266] [D loss: 0.231625, acc:  61%] [G loss: 5.250994, adv: 0.490600, recon: 0.134208, id: 0.815680] time: 0:08:57.639636 \n",
      "[Epoch 3/200] [Batch 168/266] [D loss: 0.288813, acc:  55%] [G loss: 5.012706, adv: 0.432902, recon: 0.138458, id: 0.620644] time: 0:08:58.099668 \n",
      "[Epoch 3/200] [Batch 169/266] [D loss: 0.156063, acc:  79%] [G loss: 5.405766, adv: 0.599050, recon: 0.136162, id: 0.625341] time: 0:08:58.558371 \n",
      "[Epoch 3/200] [Batch 170/266] [D loss: 0.224824, acc:  68%] [G loss: 5.095052, adv: 0.536349, recon: 0.133193, id: 0.608009] time: 0:08:59.014066 \n",
      "[Epoch 3/200] [Batch 171/266] [D loss: 0.149001, acc:  79%] [G loss: 5.194321, adv: 0.631425, recon: 0.125284, id: 0.574784] time: 0:08:59.459658 \n",
      "[Epoch 3/200] [Batch 172/266] [D loss: 0.249829, acc:  59%] [G loss: 5.101624, adv: 0.494589, recon: 0.132286, id: 0.734620] time: 0:08:59.918625 \n",
      "[Epoch 3/200] [Batch 173/266] [D loss: 0.202243, acc:  68%] [G loss: 5.582308, adv: 0.737142, recon: 0.150926, id: 0.571484] time: 0:09:00.365710 \n",
      "[Epoch 3/200] [Batch 174/266] [D loss: 0.146930, acc:  82%] [G loss: 5.262497, adv: 0.684494, recon: 0.128366, id: 0.671425] time: 0:09:00.810768 \n",
      "[Epoch 3/200] [Batch 175/266] [D loss: 0.107482, acc:  87%] [G loss: 6.195970, adv: 0.770667, recon: 0.168152, id: 0.565483] time: 0:09:01.262197 \n",
      "[Epoch 3/200] [Batch 176/266] [D loss: 0.290466, acc:  64%] [G loss: 5.298941, adv: 0.580815, recon: 0.144102, id: 0.538122] time: 0:09:01.714608 \n",
      "[Epoch 3/200] [Batch 177/266] [D loss: 0.109397, acc:  87%] [G loss: 5.131486, adv: 0.680247, recon: 0.127583, id: 0.537787] time: 0:09:02.163930 \n",
      "[Epoch 3/200] [Batch 178/266] [D loss: 0.340583, acc:  45%] [G loss: 5.198108, adv: 0.499376, recon: 0.138724, id: 0.567587] time: 0:09:02.617329 \n",
      "[Epoch 3/200] [Batch 179/266] [D loss: 0.274860, acc:  54%] [G loss: 4.701052, adv: 0.538664, recon: 0.115115, id: 0.622059] time: 0:09:03.076565 \n",
      "[Epoch 3/200] [Batch 180/266] [D loss: 0.184146, acc:  76%] [G loss: 5.065747, adv: 0.709137, recon: 0.117123, id: 0.617530] time: 0:09:03.529259 \n",
      "[Epoch 3/200] [Batch 181/266] [D loss: 0.186750, acc:  70%] [G loss: 6.426060, adv: 0.671170, recon: 0.175879, id: 0.625820] time: 0:09:03.980393 \n",
      "[Epoch 3/200] [Batch 182/266] [D loss: 0.152146, acc:  77%] [G loss: 4.824011, adv: 0.654486, recon: 0.114023, id: 0.560288] time: 0:09:04.435207 \n",
      "[Epoch 3/200] [Batch 183/266] [D loss: 0.139224, acc:  79%] [G loss: 5.608982, adv: 0.805672, recon: 0.131290, id: 0.517734] time: 0:09:04.884110 \n",
      "[Epoch 3/200] [Batch 184/266] [D loss: 0.187551, acc:  69%] [G loss: 5.221079, adv: 0.605605, recon: 0.127758, id: 0.570946] time: 0:09:05.336572 \n",
      "[Epoch 3/200] [Batch 185/266] [D loss: 0.139351, acc:  81%] [G loss: 5.373098, adv: 0.763636, recon: 0.129615, id: 0.535248] time: 0:09:05.798592 \n",
      "[Epoch 3/200] [Batch 186/266] [D loss: 0.187738, acc:  72%] [G loss: 5.728725, adv: 0.637863, recon: 0.142943, id: 0.696362] time: 0:09:06.253942 \n",
      "[Epoch 3/200] [Batch 187/266] [D loss: 0.204334, acc:  69%] [G loss: 5.884465, adv: 0.578905, recon: 0.160646, id: 0.663350] time: 0:09:06.714036 \n",
      "[Epoch 3/200] [Batch 188/266] [D loss: 0.238558, acc:  60%] [G loss: 5.317837, adv: 0.579193, recon: 0.132046, id: 0.707960] time: 0:09:07.169795 \n",
      "[Epoch 3/200] [Batch 189/266] [D loss: 0.185438, acc:  74%] [G loss: 5.190677, adv: 0.617719, recon: 0.128966, id: 0.694947] time: 0:09:07.629169 \n",
      "[Epoch 3/200] [Batch 190/266] [D loss: 0.123322, acc:  83%] [G loss: 5.803143, adv: 0.715132, recon: 0.150564, id: 0.605927] time: 0:09:08.090393 \n",
      "[Epoch 3/200] [Batch 191/266] [D loss: 0.186451, acc:  73%] [G loss: 6.042725, adv: 0.870719, recon: 0.144765, id: 0.600731] time: 0:09:08.539576 \n",
      "[Epoch 3/200] [Batch 192/266] [D loss: 0.181029, acc:  73%] [G loss: 5.751208, adv: 0.693418, recon: 0.138189, id: 0.681458] time: 0:09:08.994947 \n",
      "[Epoch 3/200] [Batch 193/266] [D loss: 0.170043, acc:  74%] [G loss: 5.885762, adv: 0.613799, recon: 0.162521, id: 0.655016] time: 0:09:09.440146 \n",
      "[Epoch 3/200] [Batch 194/266] [D loss: 0.151117, acc:  79%] [G loss: 5.405769, adv: 0.643144, recon: 0.138391, id: 0.658728] time: 0:09:09.896072 \n",
      "[Epoch 3/200] [Batch 195/266] [D loss: 0.190358, acc:  73%] [G loss: 5.529428, adv: 0.560527, recon: 0.144672, id: 0.785827] time: 0:09:10.349738 \n",
      "[Epoch 3/200] [Batch 196/266] [D loss: 0.172414, acc:  75%] [G loss: 5.387903, adv: 0.667151, recon: 0.132458, id: 0.644441] time: 0:09:10.801449 \n",
      "[Epoch 3/200] [Batch 197/266] [D loss: 0.257931, acc:  60%] [G loss: 5.494864, adv: 0.581910, recon: 0.138569, id: 0.684959] time: 0:09:11.251150 \n",
      "[Epoch 3/200] [Batch 198/266] [D loss: 0.177524, acc:  73%] [G loss: 5.950749, adv: 0.659856, recon: 0.153237, id: 0.773242] time: 0:09:11.706996 \n",
      "[Epoch 3/200] [Batch 199/266] [D loss: 0.157238, acc:  78%] [G loss: 5.969189, adv: 0.757739, recon: 0.146693, id: 0.679557] time: 0:09:12.159983 \n",
      "[Epoch 3/200] [Batch 200/266] [D loss: 0.208710, acc:  65%] [G loss: 6.057396, adv: 0.707381, recon: 0.165545, id: 0.533319] time: 0:09:12.617395 \n",
      "[Epoch 3/200] [Batch 201/266] [D loss: 0.194191, acc:  67%] [G loss: 4.591331, adv: 0.584398, recon: 0.102777, id: 0.603946] time: 0:09:13.311689 \n",
      "[Epoch 3/200] [Batch 202/266] [D loss: 0.144960, acc:  83%] [G loss: 5.925713, adv: 0.821247, recon: 0.150958, id: 0.519219] time: 0:09:13.767129 \n",
      "[Epoch 3/200] [Batch 203/266] [D loss: 0.191817, acc:  72%] [G loss: 5.282263, adv: 0.685221, recon: 0.129810, id: 0.645652] time: 0:09:14.220840 \n",
      "[Epoch 3/200] [Batch 204/266] [D loss: 0.167463, acc:  74%] [G loss: 5.775483, adv: 0.660111, recon: 0.156104, id: 0.543821] time: 0:09:14.677381 \n",
      "[Epoch 3/200] [Batch 205/266] [D loss: 0.170886, acc:  72%] [G loss: 4.920982, adv: 0.725666, recon: 0.116901, id: 0.503796] time: 0:09:15.128801 \n",
      "[Epoch 3/200] [Batch 206/266] [D loss: 0.215063, acc:  72%] [G loss: 5.081944, adv: 0.640083, recon: 0.128172, id: 0.574476] time: 0:09:15.584151 \n",
      "[Epoch 3/200] [Batch 207/266] [D loss: 0.101311, acc:  86%] [G loss: 5.910039, adv: 0.740466, recon: 0.158598, id: 0.608447] time: 0:09:16.039469 \n",
      "[Epoch 3/200] [Batch 208/266] [D loss: 0.192202, acc:  73%] [G loss: 5.238981, adv: 0.723811, recon: 0.126577, id: 0.558496] time: 0:09:16.494801 \n",
      "[Epoch 3/200] [Batch 209/266] [D loss: 0.268307, acc:  55%] [G loss: 5.381698, adv: 0.564473, recon: 0.143010, id: 0.671514] time: 0:09:16.954196 \n",
      "[Epoch 3/200] [Batch 210/266] [D loss: 0.241894, acc:  63%] [G loss: 5.319252, adv: 0.591804, recon: 0.134252, id: 0.695952] time: 0:09:17.406870 \n",
      "[Epoch 3/200] [Batch 211/266] [D loss: 0.192544, acc:  71%] [G loss: 5.776455, adv: 0.583774, recon: 0.158499, id: 0.694575] time: 0:09:17.856673 \n",
      "[Epoch 3/200] [Batch 212/266] [D loss: 0.172816, acc:  72%] [G loss: 5.980148, adv: 0.683997, recon: 0.156231, id: 0.732974] time: 0:09:18.308927 \n",
      "[Epoch 3/200] [Batch 213/266] [D loss: 0.184224, acc:  71%] [G loss: 5.272589, adv: 0.628623, recon: 0.127660, id: 0.660440] time: 0:09:18.760630 \n",
      "[Epoch 3/200] [Batch 214/266] [D loss: 0.178274, acc:  75%] [G loss: 5.342738, adv: 0.712407, recon: 0.128027, id: 0.651700] time: 0:09:19.212909 \n",
      "[Epoch 3/200] [Batch 215/266] [D loss: 0.143901, acc:  81%] [G loss: 5.338129, adv: 0.706891, recon: 0.135650, id: 0.596567] time: 0:09:19.663995 \n",
      "[Epoch 3/200] [Batch 216/266] [D loss: 0.111294, acc:  87%] [G loss: 5.854801, adv: 0.845361, recon: 0.138857, id: 0.611213] time: 0:09:20.120669 \n",
      "[Epoch 3/200] [Batch 217/266] [D loss: 0.302589, acc:  51%] [G loss: 5.780344, adv: 0.639605, recon: 0.147395, id: 0.845944] time: 0:09:20.568615 \n",
      "[Epoch 3/200] [Batch 218/266] [D loss: 0.143031, acc:  82%] [G loss: 5.691008, adv: 0.809257, recon: 0.135295, id: 0.693383] time: 0:09:21.022608 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 219/266] [D loss: 0.120338, acc:  85%] [G loss: 5.885072, adv: 0.826057, recon: 0.140340, id: 0.680113] time: 0:09:21.471863 \n",
      "[Epoch 3/200] [Batch 220/266] [D loss: 0.255950, acc:  57%] [G loss: 5.638949, adv: 0.700995, recon: 0.141338, id: 0.688595] time: 0:09:21.922893 \n",
      "[Epoch 3/200] [Batch 221/266] [D loss: 0.251455, acc:  59%] [G loss: 5.147276, adv: 0.612478, recon: 0.130008, id: 0.644379] time: 0:09:22.376966 \n",
      "[Epoch 3/200] [Batch 222/266] [D loss: 0.095372, acc:  93%] [G loss: 5.976891, adv: 0.976278, recon: 0.129228, id: 0.578390] time: 0:09:22.823936 \n",
      "[Epoch 3/200] [Batch 223/266] [D loss: 0.217362, acc:  67%] [G loss: 6.400440, adv: 0.710105, recon: 0.178492, id: 0.631210] time: 0:09:23.275754 \n",
      "[Epoch 3/200] [Batch 224/266] [D loss: 0.231004, acc:  65%] [G loss: 5.490818, adv: 0.662684, recon: 0.130423, id: 0.793167] time: 0:09:23.730983 \n",
      "[Epoch 3/200] [Batch 225/266] [D loss: 0.224526, acc:  63%] [G loss: 5.603827, adv: 0.638431, recon: 0.145224, id: 0.695627] time: 0:09:24.176022 \n",
      "[Epoch 3/200] [Batch 226/266] [D loss: 0.140223, acc:  82%] [G loss: 5.832339, adv: 0.697600, recon: 0.152908, id: 0.484414] time: 0:09:24.627747 \n",
      "[Epoch 3/200] [Batch 227/266] [D loss: 0.179400, acc:  73%] [G loss: 5.454498, adv: 0.684871, recon: 0.134275, id: 0.559929] time: 0:09:25.072824 \n",
      "[Epoch 3/200] [Batch 228/266] [D loss: 0.164761, acc:  78%] [G loss: 5.715599, adv: 0.681536, recon: 0.150560, id: 0.567985] time: 0:09:25.523357 \n",
      "[Epoch 3/200] [Batch 229/266] [D loss: 0.198905, acc:  70%] [G loss: 6.021002, adv: 0.732079, recon: 0.154766, id: 0.628534] time: 0:09:25.978084 \n",
      "[Epoch 3/200] [Batch 230/266] [D loss: 0.161021, acc:  77%] [G loss: 6.542447, adv: 0.718739, recon: 0.179008, id: 0.605279] time: 0:09:26.429152 \n",
      "[Epoch 3/200] [Batch 231/266] [D loss: 0.176644, acc:  77%] [G loss: 6.075846, adv: 0.804599, recon: 0.152887, id: 0.698904] time: 0:09:26.888060 \n",
      "[Epoch 3/200] [Batch 232/266] [D loss: 0.213077, acc:  71%] [G loss: 5.338511, adv: 0.689060, recon: 0.129839, id: 0.584832] time: 0:09:27.339492 \n",
      "[Epoch 3/200] [Batch 233/266] [D loss: 0.266974, acc:  60%] [G loss: 5.283316, adv: 0.579398, recon: 0.130626, id: 0.713452] time: 0:09:27.792454 \n",
      "[Epoch 3/200] [Batch 234/266] [D loss: 0.215827, acc:  68%] [G loss: 5.346759, adv: 0.625997, recon: 0.137735, id: 0.579593] time: 0:09:28.247566 \n",
      "[Epoch 3/200] [Batch 235/266] [D loss: 0.213009, acc:  67%] [G loss: 5.051288, adv: 0.620152, recon: 0.120880, id: 0.604181] time: 0:09:28.699249 \n",
      "[Epoch 3/200] [Batch 236/266] [D loss: 0.281688, acc:  49%] [G loss: 6.247937, adv: 0.815970, recon: 0.153924, id: 0.722198] time: 0:09:29.157694 \n",
      "[Epoch 3/200] [Batch 237/266] [D loss: 0.718689, acc:  39%] [G loss: 6.427518, adv: 0.961728, recon: 0.143912, id: 0.741621] time: 0:09:29.614756 \n",
      "[Epoch 3/200] [Batch 238/266] [D loss: 0.556060, acc:  64%] [G loss: 5.245234, adv: 0.639483, recon: 0.121991, id: 0.648758] time: 0:09:30.071901 \n",
      "[Epoch 3/200] [Batch 239/266] [D loss: 0.294200, acc:  59%] [G loss: 4.924828, adv: 0.485451, recon: 0.135549, id: 0.600645] time: 0:09:30.526726 \n",
      "[Epoch 3/200] [Batch 240/266] [D loss: 0.243290, acc:  62%] [G loss: 5.048282, adv: 0.563486, recon: 0.128677, id: 0.559371] time: 0:09:30.978311 \n",
      "[Epoch 3/200] [Batch 241/266] [D loss: 0.271893, acc:  50%] [G loss: 5.690866, adv: 0.521484, recon: 0.155535, id: 0.561361] time: 0:09:31.432393 \n",
      "[Epoch 3/200] [Batch 242/266] [D loss: 0.214799, acc:  65%] [G loss: 5.601108, adv: 0.504180, recon: 0.158966, id: 0.633205] time: 0:09:31.877277 \n",
      "[Epoch 3/200] [Batch 243/266] [D loss: 0.218278, acc:  62%] [G loss: 5.129562, adv: 0.532003, recon: 0.132467, id: 0.635024] time: 0:09:32.325642 \n",
      "[Epoch 3/200] [Batch 244/266] [D loss: 0.232465, acc:  57%] [G loss: 5.456246, adv: 0.494399, recon: 0.145520, id: 0.767429] time: 0:09:32.780393 \n",
      "[Epoch 3/200] [Batch 245/266] [D loss: 0.236365, acc:  62%] [G loss: 4.988576, adv: 0.532684, recon: 0.124916, id: 0.752930] time: 0:09:33.233741 \n",
      "[Epoch 3/200] [Batch 246/266] [D loss: 0.232654, acc:  61%] [G loss: 5.106476, adv: 0.465935, recon: 0.135718, id: 0.739140] time: 0:09:33.685665 \n",
      "[Epoch 3/200] [Batch 247/266] [D loss: 0.204046, acc:  72%] [G loss: 5.168825, adv: 0.566005, recon: 0.129565, id: 0.685295] time: 0:09:34.131035 \n",
      "[Epoch 3/200] [Batch 248/266] [D loss: 0.216901, acc:  61%] [G loss: 5.518649, adv: 0.575340, recon: 0.145631, id: 0.601066] time: 0:09:34.586682 \n",
      "[Epoch 3/200] [Batch 249/266] [D loss: 0.263618, acc:  58%] [G loss: 4.649659, adv: 0.565623, recon: 0.108759, id: 0.711270] time: 0:09:35.034799 \n",
      "[Epoch 3/200] [Batch 250/266] [D loss: 0.207901, acc:  71%] [G loss: 5.037902, adv: 0.548946, recon: 0.129851, id: 0.574282] time: 0:09:35.485910 \n",
      "[Epoch 3/200] [Batch 251/266] [D loss: 0.166816, acc:  76%] [G loss: 4.897718, adv: 0.591870, recon: 0.114568, id: 0.746008] time: 0:09:35.936191 \n",
      "[Epoch 3/200] [Batch 252/266] [D loss: 0.201945, acc:  70%] [G loss: 5.809909, adv: 0.547620, recon: 0.162307, id: 0.722567] time: 0:09:36.386150 \n",
      "[Epoch 3/200] [Batch 253/266] [D loss: 0.096860, acc:  91%] [G loss: 5.823683, adv: 0.783434, recon: 0.141395, id: 0.690285] time: 0:09:36.837413 \n",
      "[Epoch 3/200] [Batch 254/266] [D loss: 0.113936, acc:  86%] [G loss: 5.511333, adv: 0.721880, recon: 0.133921, id: 0.650531] time: 0:09:37.332769 \n",
      "[Epoch 3/200] [Batch 255/266] [D loss: 0.204972, acc:  69%] [G loss: 5.036942, adv: 0.540688, recon: 0.132566, id: 0.588750] time: 0:09:37.782732 \n",
      "[Epoch 3/200] [Batch 256/266] [D loss: 0.157690, acc:  78%] [G loss: 5.210140, adv: 0.718680, recon: 0.123057, id: 0.589962] time: 0:09:38.238912 \n",
      "[Epoch 3/200] [Batch 257/266] [D loss: 0.165584, acc:  79%] [G loss: 5.274671, adv: 0.705800, recon: 0.115749, id: 0.736180] time: 0:09:38.695433 \n",
      "[Epoch 3/200] [Batch 258/266] [D loss: 0.204977, acc:  70%] [G loss: 5.612877, adv: 0.629491, recon: 0.134132, id: 0.902296] time: 0:09:39.139631 \n",
      "[Epoch 3/200] [Batch 259/266] [D loss: 0.174704, acc:  76%] [G loss: 6.045269, adv: 0.762809, recon: 0.155823, id: 0.710772] time: 0:09:39.602604 \n",
      "[Epoch 3/200] [Batch 260/266] [D loss: 0.195770, acc:  77%] [G loss: 5.551928, adv: 0.668419, recon: 0.135535, id: 0.740259] time: 0:09:40.054812 \n",
      "[Epoch 3/200] [Batch 261/266] [D loss: 0.221998, acc:  63%] [G loss: 5.529697, adv: 0.584694, recon: 0.142745, id: 0.693827] time: 0:09:40.512250 \n",
      "[Epoch 3/200] [Batch 262/266] [D loss: 0.195645, acc:  70%] [G loss: 5.889122, adv: 0.726318, recon: 0.149259, id: 0.661216] time: 0:09:40.970254 \n",
      "[Epoch 3/200] [Batch 263/266] [D loss: 0.167275, acc:  77%] [G loss: 5.303391, adv: 0.660010, recon: 0.127535, id: 0.632826] time: 0:09:41.425437 \n",
      "[Epoch 3/200] [Batch 264/266] [D loss: 0.184883, acc:  70%] [G loss: 5.843678, adv: 0.683270, recon: 0.155068, id: 0.678892] time: 0:09:41.876571 \n",
      "[Epoch 4/200] [Batch 0/266] [D loss: 0.202602, acc:  70%] [G loss: 5.545605, adv: 0.628982, recon: 0.141805, id: 0.727404] time: 0:09:42.607144 \n",
      "[Epoch 4/200] [Batch 1/266] [D loss: 0.143887, acc:  81%] [G loss: 5.391537, adv: 0.760827, recon: 0.128402, id: 0.592603] time: 0:09:43.274238 \n",
      "[Epoch 4/200] [Batch 2/266] [D loss: 0.192344, acc:  80%] [G loss: 5.220849, adv: 0.610091, recon: 0.130385, id: 0.638527] time: 0:09:43.723192 \n",
      "[Epoch 4/200] [Batch 3/266] [D loss: 0.149402, acc:  78%] [G loss: 5.163199, adv: 0.675703, recon: 0.122876, id: 0.701503] time: 0:09:44.170471 \n",
      "[Epoch 4/200] [Batch 4/266] [D loss: 0.167960, acc:  77%] [G loss: 5.258249, adv: 0.693392, recon: 0.128576, id: 0.650622] time: 0:09:44.621835 \n",
      "[Epoch 4/200] [Batch 5/266] [D loss: 0.192673, acc:  70%] [G loss: 4.994592, adv: 0.621349, recon: 0.124869, id: 0.605772] time: 0:09:45.079541 \n",
      "[Epoch 4/200] [Batch 6/266] [D loss: 0.282294, acc:  52%] [G loss: 4.854989, adv: 0.558809, recon: 0.122311, id: 0.643301] time: 0:09:45.533092 \n",
      "[Epoch 4/200] [Batch 7/266] [D loss: 0.271364, acc:  66%] [G loss: 5.492043, adv: 0.737301, recon: 0.139236, id: 0.556445] time: 0:09:45.989732 \n",
      "[Epoch 4/200] [Batch 8/266] [D loss: 0.191592, acc:  72%] [G loss: 5.750443, adv: 0.626515, recon: 0.150883, id: 0.615999] time: 0:09:46.451991 \n",
      "[Epoch 4/200] [Batch 9/266] [D loss: 0.251954, acc:  62%] [G loss: 5.541964, adv: 0.838819, recon: 0.132921, id: 0.494666] time: 0:09:46.902519 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 10/266] [D loss: 0.197620, acc:  67%] [G loss: 5.362734, adv: 0.803356, recon: 0.125199, id: 0.568750] time: 0:09:47.352520 \n",
      "[Epoch 4/200] [Batch 11/266] [D loss: 0.162469, acc:  76%] [G loss: 5.200065, adv: 0.548695, recon: 0.131948, id: 0.680004] time: 0:09:47.807891 \n",
      "[Epoch 4/200] [Batch 12/266] [D loss: 0.168025, acc:  75%] [G loss: 5.553541, adv: 0.648118, recon: 0.138495, id: 0.688555] time: 0:09:48.258505 \n",
      "[Epoch 4/200] [Batch 13/266] [D loss: 0.160114, acc:  74%] [G loss: 5.340955, adv: 0.670537, recon: 0.130756, id: 0.657136] time: 0:09:48.712879 \n",
      "[Epoch 4/200] [Batch 14/266] [D loss: 0.137210, acc:  81%] [G loss: 5.881241, adv: 0.824588, recon: 0.148921, id: 0.651968] time: 0:09:49.162964 \n",
      "[Epoch 4/200] [Batch 15/266] [D loss: 0.196509, acc:  72%] [G loss: 5.378125, adv: 0.774339, recon: 0.125564, id: 0.602893] time: 0:09:49.616432 \n",
      "[Epoch 4/200] [Batch 16/266] [D loss: 0.119812, acc:  81%] [G loss: 5.110711, adv: 0.773794, recon: 0.113990, id: 0.634631] time: 0:09:50.072181 \n",
      "[Epoch 4/200] [Batch 17/266] [D loss: 0.208531, acc:  68%] [G loss: 4.993981, adv: 0.658856, recon: 0.123537, id: 0.520405] time: 0:09:50.533312 \n",
      "[Epoch 4/200] [Batch 18/266] [D loss: 0.147098, acc:  79%] [G loss: 4.867970, adv: 0.737838, recon: 0.111633, id: 0.518719] time: 0:09:50.982761 \n",
      "[Epoch 4/200] [Batch 19/266] [D loss: 0.162617, acc:  76%] [G loss: 5.957450, adv: 0.717296, recon: 0.159590, id: 0.505209] time: 0:09:51.436143 \n",
      "[Epoch 4/200] [Batch 20/266] [D loss: 0.227853, acc:  65%] [G loss: 5.285549, adv: 0.624563, recon: 0.127941, id: 0.688567] time: 0:09:51.896574 \n",
      "[Epoch 4/200] [Batch 21/266] [D loss: 0.205109, acc:  67%] [G loss: 5.709641, adv: 0.640508, recon: 0.140093, id: 0.804261] time: 0:09:52.347798 \n",
      "[Epoch 4/200] [Batch 22/266] [D loss: 0.148546, acc:  80%] [G loss: 5.312027, adv: 0.726413, recon: 0.127485, id: 0.566753] time: 0:09:52.804412 \n",
      "[Epoch 4/200] [Batch 23/266] [D loss: 0.159058, acc:  78%] [G loss: 5.542022, adv: 0.728862, recon: 0.129560, id: 0.686543] time: 0:09:53.262958 \n",
      "[Epoch 4/200] [Batch 24/266] [D loss: 0.182489, acc:  75%] [G loss: 4.887940, adv: 0.628495, recon: 0.125911, id: 0.519456] time: 0:09:53.715174 \n",
      "[Epoch 4/200] [Batch 25/266] [D loss: 0.139022, acc:  83%] [G loss: 5.704133, adv: 0.808702, recon: 0.142991, id: 0.544866] time: 0:09:54.162977 \n",
      "[Epoch 4/200] [Batch 26/266] [D loss: 0.267151, acc:  65%] [G loss: 5.587369, adv: 0.534472, recon: 0.159739, id: 0.572308] time: 0:09:54.614848 \n",
      "[Epoch 4/200] [Batch 27/266] [D loss: 0.237477, acc:  64%] [G loss: 5.318490, adv: 0.508283, recon: 0.144499, id: 0.646586] time: 0:09:55.071168 \n",
      "[Epoch 4/200] [Batch 28/266] [D loss: 0.153368, acc:  77%] [G loss: 5.405600, adv: 0.667993, recon: 0.133676, id: 0.693382] time: 0:09:55.537443 \n",
      "[Epoch 4/200] [Batch 29/266] [D loss: 0.137115, acc:  81%] [G loss: 5.662202, adv: 0.728699, recon: 0.141624, id: 0.532562] time: 0:09:55.984477 \n",
      "[Epoch 4/200] [Batch 30/266] [D loss: 0.332021, acc:  44%] [G loss: 5.027204, adv: 0.613587, recon: 0.126044, id: 0.692312] time: 0:09:56.433914 \n",
      "[Epoch 4/200] [Batch 31/266] [D loss: 0.210232, acc:  68%] [G loss: 6.646677, adv: 0.822723, recon: 0.163002, id: 0.838285] time: 0:09:56.879123 \n",
      "[Epoch 4/200] [Batch 32/266] [D loss: 0.165538, acc:  74%] [G loss: 5.114115, adv: 0.706200, recon: 0.121368, id: 0.656856] time: 0:09:57.329678 \n",
      "[Epoch 4/200] [Batch 33/266] [D loss: 0.238298, acc:  67%] [G loss: 5.380119, adv: 0.681945, recon: 0.128315, id: 0.697078] time: 0:09:57.786300 \n",
      "[Epoch 4/200] [Batch 34/266] [D loss: 0.172704, acc:  71%] [G loss: 5.277492, adv: 0.710170, recon: 0.124900, id: 0.702519] time: 0:09:58.242196 \n",
      "[Epoch 4/200] [Batch 35/266] [D loss: 0.313298, acc:  49%] [G loss: 5.157266, adv: 0.598775, recon: 0.123828, id: 0.757152] time: 0:09:58.696918 \n",
      "[Epoch 4/200] [Batch 36/266] [D loss: 0.146359, acc:  78%] [G loss: 5.803923, adv: 0.738960, recon: 0.143211, id: 0.601425] time: 0:09:59.150255 \n",
      "[Epoch 4/200] [Batch 37/266] [D loss: 0.160614, acc:  77%] [G loss: 5.524036, adv: 0.712419, recon: 0.140056, id: 0.547657] time: 0:09:59.598588 \n",
      "[Epoch 4/200] [Batch 38/266] [D loss: 0.133472, acc:  85%] [G loss: 5.530761, adv: 0.749355, recon: 0.135286, id: 0.596692] time: 0:10:00.050685 \n",
      "[Epoch 4/200] [Batch 39/266] [D loss: 0.158986, acc:  78%] [G loss: 5.824107, adv: 0.672840, recon: 0.156023, id: 0.617199] time: 0:10:00.499957 \n",
      "[Epoch 4/200] [Batch 40/266] [D loss: 0.159526, acc:  79%] [G loss: 6.527764, adv: 0.766996, recon: 0.170270, id: 0.644291] time: 0:10:00.948769 \n",
      "[Epoch 4/200] [Batch 41/266] [D loss: 0.111700, acc:  86%] [G loss: 5.778861, adv: 0.792682, recon: 0.130345, id: 0.820733] time: 0:10:01.394830 \n",
      "[Epoch 4/200] [Batch 42/266] [D loss: 0.136385, acc:  80%] [G loss: 5.567806, adv: 0.722507, recon: 0.134057, id: 0.741656] time: 0:10:01.841852 \n",
      "[Epoch 4/200] [Batch 43/266] [D loss: 0.152475, acc:  79%] [G loss: 5.390672, adv: 0.692911, recon: 0.134595, id: 0.604319] time: 0:10:02.293162 \n",
      "[Epoch 4/200] [Batch 44/266] [D loss: 0.147454, acc:  79%] [G loss: 4.893644, adv: 0.736905, recon: 0.108388, id: 0.656024] time: 0:10:02.739434 \n",
      "[Epoch 4/200] [Batch 45/266] [D loss: 0.178725, acc:  71%] [G loss: 6.068879, adv: 0.892863, recon: 0.138853, id: 0.687317] time: 0:10:03.191168 \n",
      "[Epoch 4/200] [Batch 46/266] [D loss: 0.220195, acc:  65%] [G loss: 5.505589, adv: 0.706680, recon: 0.132323, id: 0.738428] time: 0:10:03.643049 \n",
      "[Epoch 4/200] [Batch 47/266] [D loss: 0.252644, acc:  59%] [G loss: 5.528864, adv: 0.558075, recon: 0.156958, id: 0.628860] time: 0:10:04.094518 \n",
      "[Epoch 4/200] [Batch 48/266] [D loss: 0.148008, acc:  83%] [G loss: 5.733264, adv: 0.714003, recon: 0.139749, id: 0.712546] time: 0:10:04.539681 \n",
      "[Epoch 4/200] [Batch 49/266] [D loss: 0.219460, acc:  66%] [G loss: 5.408016, adv: 0.652272, recon: 0.131142, id: 0.688539] time: 0:10:04.984805 \n",
      "[Epoch 4/200] [Batch 50/266] [D loss: 0.135534, acc:  83%] [G loss: 5.473305, adv: 0.741435, recon: 0.135355, id: 0.543314] time: 0:10:05.431633 \n",
      "[Epoch 4/200] [Batch 51/266] [D loss: 0.208150, acc:  69%] [G loss: 5.571501, adv: 0.892035, recon: 0.121043, id: 0.642483] time: 0:10:05.876193 \n",
      "[Epoch 4/200] [Batch 52/266] [D loss: 0.174816, acc:  74%] [G loss: 5.804185, adv: 0.719480, recon: 0.145794, id: 0.596620] time: 0:10:06.322283 \n",
      "[Epoch 4/200] [Batch 53/266] [D loss: 0.221636, acc:  67%] [G loss: 4.830548, adv: 0.514321, recon: 0.129054, id: 0.585274] time: 0:10:06.765368 \n",
      "[Epoch 4/200] [Batch 54/266] [D loss: 0.218473, acc:  63%] [G loss: 5.388950, adv: 0.639253, recon: 0.132586, id: 0.688204] time: 0:10:07.210891 \n",
      "[Epoch 4/200] [Batch 55/266] [D loss: 0.282397, acc:  59%] [G loss: 4.926573, adv: 0.566417, recon: 0.119559, id: 0.626148] time: 0:10:07.658611 \n",
      "[Epoch 4/200] [Batch 56/266] [D loss: 0.149124, acc:  82%] [G loss: 4.791867, adv: 0.644256, recon: 0.113420, id: 0.565259] time: 0:10:08.111337 \n",
      "[Epoch 4/200] [Batch 57/266] [D loss: 0.182401, acc:  71%] [G loss: 5.763698, adv: 0.704557, recon: 0.145937, id: 0.717802] time: 0:10:08.558303 \n",
      "[Epoch 4/200] [Batch 58/266] [D loss: 0.172592, acc:  70%] [G loss: 5.853947, adv: 0.673395, recon: 0.147952, id: 0.779262] time: 0:10:09.005860 \n",
      "[Epoch 4/200] [Batch 59/266] [D loss: 0.137818, acc:  77%] [G loss: 5.853106, adv: 0.713231, recon: 0.142474, id: 0.772169] time: 0:10:09.454301 \n",
      "[Epoch 4/200] [Batch 60/266] [D loss: 0.127248, acc:  84%] [G loss: 6.332127, adv: 0.787588, recon: 0.166414, id: 0.661413] time: 0:10:09.904361 \n",
      "[Epoch 4/200] [Batch 61/266] [D loss: 0.103214, acc:  84%] [G loss: 5.768792, adv: 0.824262, recon: 0.128401, id: 0.743546] time: 0:10:10.354478 \n",
      "[Epoch 4/200] [Batch 62/266] [D loss: 0.214808, acc:  65%] [G loss: 5.616981, adv: 0.632263, recon: 0.152313, id: 0.637859] time: 0:10:10.803226 \n",
      "[Epoch 4/200] [Batch 63/266] [D loss: 0.266272, acc:  54%] [G loss: 5.512713, adv: 0.610300, recon: 0.149488, id: 0.608241] time: 0:10:11.249298 \n",
      "[Epoch 4/200] [Batch 64/266] [D loss: 0.107641, acc:  87%] [G loss: 5.788665, adv: 0.834525, recon: 0.138140, id: 0.517117] time: 0:10:11.694622 \n",
      "[Epoch 4/200] [Batch 65/266] [D loss: 0.130107, acc:  83%] [G loss: 5.560574, adv: 0.695747, recon: 0.141008, id: 0.548759] time: 0:10:12.145844 \n",
      "[Epoch 4/200] [Batch 66/266] [D loss: 0.202262, acc:  68%] [G loss: 5.584203, adv: 0.723012, recon: 0.133992, id: 0.578650] time: 0:10:12.594911 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 67/266] [D loss: 0.156254, acc:  73%] [G loss: 6.466966, adv: 0.830551, recon: 0.156546, id: 0.825696] time: 0:10:13.040154 \n",
      "[Epoch 4/200] [Batch 68/266] [D loss: 0.272604, acc:  60%] [G loss: 6.087988, adv: 0.817138, recon: 0.145347, id: 0.770519] time: 0:10:13.486879 \n",
      "[Epoch 4/200] [Batch 69/266] [D loss: 0.248847, acc:  64%] [G loss: 5.695304, adv: 0.689683, recon: 0.148478, id: 0.651078] time: 0:10:13.942469 \n",
      "[Epoch 4/200] [Batch 70/266] [D loss: 0.208303, acc:  73%] [G loss: 5.346338, adv: 0.742312, recon: 0.122934, id: 0.685716] time: 0:10:14.388207 \n",
      "[Epoch 4/200] [Batch 71/266] [D loss: 0.275812, acc:  59%] [G loss: 5.145421, adv: 0.559521, recon: 0.131692, id: 0.754686] time: 0:10:14.833401 \n",
      "[Epoch 4/200] [Batch 72/266] [D loss: 0.172406, acc:  73%] [G loss: 5.300768, adv: 0.615753, recon: 0.135529, id: 0.724516] time: 0:10:15.291705 \n",
      "[Epoch 4/200] [Batch 73/266] [D loss: 0.343433, acc:  57%] [G loss: 5.325161, adv: 0.524031, recon: 0.151493, id: 0.609802] time: 0:10:15.752861 \n",
      "[Epoch 4/200] [Batch 74/266] [D loss: 0.200746, acc:  66%] [G loss: 5.188091, adv: 0.585130, recon: 0.137920, id: 0.514492] time: 0:10:16.208398 \n",
      "[Epoch 4/200] [Batch 75/266] [D loss: 0.165045, acc:  75%] [G loss: 5.241976, adv: 0.696033, recon: 0.126076, id: 0.642287] time: 0:10:16.667217 \n",
      "[Epoch 4/200] [Batch 76/266] [D loss: 0.112592, acc:  87%] [G loss: 5.284171, adv: 0.787436, recon: 0.120659, id: 0.603026] time: 0:10:17.125779 \n",
      "[Epoch 4/200] [Batch 77/266] [D loss: 0.174147, acc:  71%] [G loss: 5.768531, adv: 0.738886, recon: 0.146907, id: 0.479660] time: 0:10:17.577007 \n",
      "[Epoch 4/200] [Batch 78/266] [D loss: 0.181024, acc:  72%] [G loss: 4.837211, adv: 0.617393, recon: 0.120463, id: 0.553334] time: 0:10:18.027582 \n",
      "[Epoch 4/200] [Batch 79/266] [D loss: 0.181367, acc:  76%] [G loss: 5.124949, adv: 0.603964, recon: 0.129558, id: 0.609467] time: 0:10:18.473265 \n",
      "[Epoch 4/200] [Batch 80/266] [D loss: 0.171675, acc:  74%] [G loss: 5.139405, adv: 0.611674, recon: 0.128258, id: 0.675102] time: 0:10:18.928809 \n",
      "[Epoch 4/200] [Batch 81/266] [D loss: 0.105468, acc:  92%] [G loss: 5.138904, adv: 0.780916, recon: 0.114156, id: 0.670050] time: 0:10:19.378414 \n",
      "[Epoch 4/200] [Batch 82/266] [D loss: 0.243194, acc:  68%] [G loss: 5.693059, adv: 0.760511, recon: 0.146527, id: 0.530668] time: 0:10:19.840911 \n",
      "[Epoch 4/200] [Batch 83/266] [D loss: 0.157216, acc:  80%] [G loss: 6.075485, adv: 0.807861, recon: 0.150387, id: 0.720304] time: 0:10:20.295882 \n",
      "[Epoch 4/200] [Batch 84/266] [D loss: 0.202798, acc:  69%] [G loss: 6.872898, adv: 0.652762, recon: 0.195234, id: 0.703368] time: 0:10:20.753223 \n",
      "[Epoch 4/200] [Batch 85/266] [D loss: 0.150928, acc:  82%] [G loss: 5.570078, adv: 0.698666, recon: 0.150279, id: 0.571855] time: 0:10:21.209895 \n",
      "[Epoch 4/200] [Batch 86/266] [D loss: 0.202229, acc:  68%] [G loss: 5.687636, adv: 0.716330, recon: 0.145601, id: 0.579039] time: 0:10:21.662633 \n",
      "[Epoch 4/200] [Batch 87/266] [D loss: 0.144690, acc:  78%] [G loss: 5.247597, adv: 0.786536, recon: 0.129126, id: 0.434502] time: 0:10:22.123452 \n",
      "[Epoch 4/200] [Batch 88/266] [D loss: 0.240571, acc:  65%] [G loss: 5.315004, adv: 0.831555, recon: 0.128724, id: 0.487198] time: 0:10:22.575066 \n",
      "[Epoch 4/200] [Batch 89/266] [D loss: 0.205252, acc:  67%] [G loss: 5.715223, adv: 0.693001, recon: 0.141977, id: 0.573105] time: 0:10:23.029205 \n",
      "[Epoch 4/200] [Batch 90/266] [D loss: 0.160968, acc:  79%] [G loss: 5.737756, adv: 0.741542, recon: 0.142612, id: 0.625492] time: 0:10:23.534545 \n",
      "[Epoch 4/200] [Batch 91/266] [D loss: 0.183295, acc:  73%] [G loss: 5.038022, adv: 0.639811, recon: 0.123109, id: 0.621898] time: 0:10:23.990032 \n",
      "[Epoch 4/200] [Batch 92/266] [D loss: 0.101879, acc:  89%] [G loss: 5.110484, adv: 0.757223, recon: 0.113770, id: 0.652111] time: 0:10:24.441029 \n",
      "[Epoch 4/200] [Batch 93/266] [D loss: 0.110120, acc:  86%] [G loss: 5.623214, adv: 0.739106, recon: 0.139996, id: 0.712493] time: 0:10:24.897596 \n",
      "[Epoch 4/200] [Batch 94/266] [D loss: 0.308725, acc:  47%] [G loss: 6.336899, adv: 0.856466, recon: 0.155780, id: 0.647047] time: 0:10:25.350204 \n",
      "[Epoch 4/200] [Batch 95/266] [D loss: 0.181902, acc:  73%] [G loss: 5.336099, adv: 0.778224, recon: 0.123323, id: 0.596530] time: 0:10:25.799498 \n",
      "[Epoch 4/200] [Batch 96/266] [D loss: 0.159633, acc:  79%] [G loss: 5.801548, adv: 0.888276, recon: 0.127359, id: 0.614243] time: 0:10:26.255895 \n",
      "[Epoch 4/200] [Batch 97/266] [D loss: 0.170361, acc:  72%] [G loss: 5.084144, adv: 0.729212, recon: 0.114583, id: 0.633949] time: 0:10:26.715752 \n",
      "[Epoch 4/200] [Batch 98/266] [D loss: 0.241123, acc:  57%] [G loss: 5.210326, adv: 0.594425, recon: 0.131595, id: 0.592248] time: 0:10:27.172071 \n",
      "[Epoch 4/200] [Batch 99/266] [D loss: 0.229087, acc:  63%] [G loss: 5.163929, adv: 0.645810, recon: 0.115984, id: 0.645821] time: 0:10:27.628560 \n",
      "[Epoch 4/200] [Batch 100/266] [D loss: 0.197284, acc:  71%] [G loss: 5.277966, adv: 0.714510, recon: 0.117016, id: 0.626311] time: 0:10:28.086837 \n",
      "[Epoch 4/200] [Batch 101/266] [D loss: 0.133778, acc:  84%] [G loss: 5.816715, adv: 0.773743, recon: 0.144056, id: 0.664429] time: 0:10:28.539455 \n",
      "[Epoch 4/200] [Batch 102/266] [D loss: 0.209496, acc:  70%] [G loss: 6.028623, adv: 0.588971, recon: 0.163506, id: 0.740340] time: 0:10:28.996241 \n",
      "[Epoch 4/200] [Batch 103/266] [D loss: 0.149750, acc:  81%] [G loss: 6.142882, adv: 0.709429, recon: 0.152770, id: 0.638526] time: 0:10:29.448904 \n",
      "[Epoch 4/200] [Batch 104/266] [D loss: 0.154632, acc:  76%] [G loss: 5.107412, adv: 0.589038, recon: 0.126033, id: 0.586620] time: 0:10:29.904614 \n",
      "[Epoch 4/200] [Batch 105/266] [D loss: 0.157690, acc:  76%] [G loss: 5.365480, adv: 0.686643, recon: 0.129098, id: 0.654425] time: 0:10:30.360469 \n",
      "[Epoch 4/200] [Batch 106/266] [D loss: 0.138855, acc:  80%] [G loss: 6.955523, adv: 0.747084, recon: 0.186675, id: 0.795846] time: 0:10:30.812086 \n",
      "[Epoch 4/200] [Batch 107/266] [D loss: 0.144114, acc:  82%] [G loss: 5.123061, adv: 0.658525, recon: 0.117859, id: 0.702511] time: 0:10:31.265868 \n",
      "[Epoch 4/200] [Batch 108/266] [D loss: 0.098330, acc:  88%] [G loss: 5.649848, adv: 0.767640, recon: 0.129823, id: 0.736960] time: 0:10:31.717590 \n",
      "[Epoch 4/200] [Batch 109/266] [D loss: 0.168278, acc:  78%] [G loss: 5.869105, adv: 0.751757, recon: 0.147822, id: 0.565681] time: 0:10:32.176264 \n",
      "[Epoch 4/200] [Batch 110/266] [D loss: 0.135115, acc:  80%] [G loss: 5.831701, adv: 0.809078, recon: 0.143351, id: 0.591735] time: 0:10:32.636511 \n",
      "[Epoch 4/200] [Batch 111/266] [D loss: 0.133501, acc:  78%] [G loss: 5.445550, adv: 0.773864, recon: 0.125892, id: 0.724493] time: 0:10:33.086475 \n",
      "[Epoch 4/200] [Batch 112/266] [D loss: 0.246891, acc:  60%] [G loss: 6.053847, adv: 0.628033, recon: 0.167203, id: 0.630475] time: 0:10:33.538068 \n",
      "[Epoch 4/200] [Batch 113/266] [D loss: 0.170878, acc:  71%] [G loss: 5.224449, adv: 0.610615, recon: 0.128534, id: 0.633805] time: 0:10:33.991184 \n",
      "[Epoch 4/200] [Batch 114/266] [D loss: 0.121786, acc:  87%] [G loss: 5.985999, adv: 0.763612, recon: 0.157910, id: 0.607766] time: 0:10:34.445624 \n",
      "[Epoch 4/200] [Batch 115/266] [D loss: 0.169981, acc:  75%] [G loss: 5.519769, adv: 0.631515, recon: 0.131378, id: 0.813740] time: 0:10:34.895449 \n",
      "[Epoch 4/200] [Batch 116/266] [D loss: 0.223104, acc:  62%] [G loss: 6.340678, adv: 0.904294, recon: 0.147723, id: 0.729819] time: 0:10:35.352564 \n",
      "[Epoch 4/200] [Batch 117/266] [D loss: 0.182160, acc:  72%] [G loss: 5.445192, adv: 0.701572, recon: 0.140714, id: 0.655932] time: 0:10:35.805483 \n",
      "[Epoch 4/200] [Batch 118/266] [D loss: 0.109507, acc:  86%] [G loss: 5.555085, adv: 0.864447, recon: 0.115611, id: 0.776159] time: 0:10:36.258580 \n",
      "[Epoch 4/200] [Batch 119/266] [D loss: 0.193090, acc:  71%] [G loss: 5.397800, adv: 0.603370, recon: 0.139683, id: 0.682312] time: 0:10:36.712907 \n",
      "[Epoch 4/200] [Batch 120/266] [D loss: 0.127821, acc:  83%] [G loss: 5.986316, adv: 0.702747, recon: 0.153931, id: 0.624679] time: 0:10:37.171963 \n",
      "[Epoch 4/200] [Batch 121/266] [D loss: 0.205061, acc:  70%] [G loss: 6.097331, adv: 0.824215, recon: 0.149683, id: 0.670329] time: 0:10:37.628043 \n",
      "[Epoch 4/200] [Batch 122/266] [D loss: 0.102039, acc:  90%] [G loss: 5.706052, adv: 0.853900, recon: 0.131858, id: 0.644358] time: 0:10:38.079894 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 123/266] [D loss: 0.210443, acc:  69%] [G loss: 4.955574, adv: 0.772820, recon: 0.108769, id: 0.513921] time: 0:10:38.535737 \n",
      "[Epoch 4/200] [Batch 124/266] [D loss: 0.128643, acc:  82%] [G loss: 5.274697, adv: 0.788186, recon: 0.123462, id: 0.557573] time: 0:10:38.990586 \n",
      "[Epoch 4/200] [Batch 125/266] [D loss: 0.138422, acc:  83%] [G loss: 5.713815, adv: 0.694280, recon: 0.142507, id: 0.658209] time: 0:10:39.440966 \n",
      "[Epoch 4/200] [Batch 126/266] [D loss: 0.145839, acc:  77%] [G loss: 6.141931, adv: 0.774301, recon: 0.147407, id: 0.722841] time: 0:10:39.888462 \n",
      "[Epoch 4/200] [Batch 127/266] [D loss: 0.199878, acc:  68%] [G loss: 5.168349, adv: 0.669888, recon: 0.122799, id: 0.636409] time: 0:10:40.337649 \n",
      "[Epoch 4/200] [Batch 128/266] [D loss: 0.160471, acc:  77%] [G loss: 5.062796, adv: 0.658892, recon: 0.113303, id: 0.721370] time: 0:10:40.789331 \n",
      "[Epoch 4/200] [Batch 129/266] [D loss: 0.163340, acc:  75%] [G loss: 5.017574, adv: 0.725753, recon: 0.115573, id: 0.590079] time: 0:10:41.242419 \n",
      "[Epoch 4/200] [Batch 130/266] [D loss: 0.275795, acc:  51%] [G loss: 5.111017, adv: 0.747242, recon: 0.115707, id: 0.516142] time: 0:10:41.692185 \n",
      "[Epoch 4/200] [Batch 131/266] [D loss: 0.212980, acc:  73%] [G loss: 5.175195, adv: 0.720500, recon: 0.119414, id: 0.528545] time: 0:10:42.136049 \n",
      "[Epoch 4/200] [Batch 132/266] [D loss: 0.131151, acc:  84%] [G loss: 5.887292, adv: 0.877230, recon: 0.140499, id: 0.635529] time: 0:10:42.587224 \n",
      "[Epoch 4/200] [Batch 133/266] [D loss: 0.156406, acc:  76%] [G loss: 5.822298, adv: 0.738024, recon: 0.143803, id: 0.612090] time: 0:10:43.043608 \n",
      "[Epoch 4/200] [Batch 134/266] [D loss: 0.214925, acc:  72%] [G loss: 5.277739, adv: 0.728834, recon: 0.120803, id: 0.547996] time: 0:10:43.501052 \n",
      "[Epoch 4/200] [Batch 135/266] [D loss: 0.212782, acc:  67%] [G loss: 5.182304, adv: 0.681999, recon: 0.123353, id: 0.487395] time: 0:10:43.948105 \n",
      "[Epoch 4/200] [Batch 136/266] [D loss: 0.158482, acc:  78%] [G loss: 5.405459, adv: 0.781340, recon: 0.110482, id: 0.717615] time: 0:10:44.395996 \n",
      "[Epoch 4/200] [Batch 137/266] [D loss: 0.201017, acc:  73%] [G loss: 5.764314, adv: 0.682791, recon: 0.146675, id: 0.731043] time: 0:10:44.856835 \n",
      "[Epoch 4/200] [Batch 138/266] [D loss: 0.150371, acc:  80%] [G loss: 5.098857, adv: 0.638037, recon: 0.115414, id: 0.702280] time: 0:10:45.311588 \n",
      "[Epoch 4/200] [Batch 139/266] [D loss: 0.097201, acc:  88%] [G loss: 6.052957, adv: 0.905772, recon: 0.138948, id: 0.690391] time: 0:10:45.761890 \n",
      "[Epoch 4/200] [Batch 140/266] [D loss: 0.184145, acc:  75%] [G loss: 6.386707, adv: 0.728849, recon: 0.172701, id: 0.642030] time: 0:10:46.218217 \n",
      "[Epoch 4/200] [Batch 141/266] [D loss: 0.236838, acc:  60%] [G loss: 5.273602, adv: 0.581441, recon: 0.132887, id: 0.747720] time: 0:10:46.671813 \n",
      "[Epoch 4/200] [Batch 142/266] [D loss: 0.128645, acc:  83%] [G loss: 5.589377, adv: 0.818878, recon: 0.137773, id: 0.578047] time: 0:10:47.121281 \n",
      "[Epoch 4/200] [Batch 143/266] [D loss: 0.182880, acc:  69%] [G loss: 5.560841, adv: 0.649107, recon: 0.139387, id: 0.715030] time: 0:10:47.577110 \n",
      "[Epoch 4/200] [Batch 144/266] [D loss: 0.172246, acc:  72%] [G loss: 6.139697, adv: 0.806684, recon: 0.157944, id: 0.682514] time: 0:10:48.035362 \n",
      "[Epoch 4/200] [Batch 145/266] [D loss: 0.188398, acc:  72%] [G loss: 5.644186, adv: 0.743749, recon: 0.136989, id: 0.664450] time: 0:10:48.495534 \n",
      "[Epoch 4/200] [Batch 146/266] [D loss: 0.130755, acc:  81%] [G loss: 5.614785, adv: 0.788418, recon: 0.129927, id: 0.693422] time: 0:10:48.948680 \n",
      "[Epoch 4/200] [Batch 147/266] [D loss: 0.192747, acc:  72%] [G loss: 5.032197, adv: 0.566597, recon: 0.128778, id: 0.611422] time: 0:10:49.400423 \n",
      "[Epoch 4/200] [Batch 148/266] [D loss: 0.150724, acc:  76%] [G loss: 5.107638, adv: 0.669426, recon: 0.120301, id: 0.619043] time: 0:10:49.856153 \n",
      "[Epoch 4/200] [Batch 149/266] [D loss: 0.148669, acc:  79%] [G loss: 5.518455, adv: 0.717207, recon: 0.133941, id: 0.707793] time: 0:10:50.307620 \n",
      "[Epoch 4/200] [Batch 150/266] [D loss: 0.199018, acc:  67%] [G loss: 5.427659, adv: 0.619263, recon: 0.145991, id: 0.568237] time: 0:10:50.762578 \n",
      "[Epoch 4/200] [Batch 151/266] [D loss: 0.175241, acc:  73%] [G loss: 6.654861, adv: 0.790206, recon: 0.171882, id: 0.788607] time: 0:10:51.212809 \n",
      "[Epoch 4/200] [Batch 152/266] [D loss: 0.159737, acc:  74%] [G loss: 5.697585, adv: 0.713073, recon: 0.137553, id: 0.803598] time: 0:10:51.669593 \n",
      "[Epoch 4/200] [Batch 153/266] [D loss: 0.221165, acc:  66%] [G loss: 5.763109, adv: 0.650367, recon: 0.143998, id: 0.825559] time: 0:10:52.122250 \n",
      "[Epoch 4/200] [Batch 154/266] [D loss: 0.159414, acc:  78%] [G loss: 5.423192, adv: 0.678849, recon: 0.131878, id: 0.698600] time: 0:10:52.579251 \n",
      "[Epoch 4/200] [Batch 155/266] [D loss: 0.212570, acc:  70%] [G loss: 5.600042, adv: 0.657640, recon: 0.135014, id: 0.765836] time: 0:10:53.035411 \n",
      "[Epoch 4/200] [Batch 156/266] [D loss: 0.108740, acc:  86%] [G loss: 6.300796, adv: 0.813534, recon: 0.156563, id: 0.782754] time: 0:10:53.493414 \n",
      "[Epoch 4/200] [Batch 157/266] [D loss: 0.182197, acc:  70%] [G loss: 5.368402, adv: 0.783323, recon: 0.127827, id: 0.662888] time: 0:10:53.944365 \n",
      "[Epoch 4/200] [Batch 158/266] [D loss: 0.150685, acc:  75%] [G loss: 5.961054, adv: 0.786272, recon: 0.156098, id: 0.633524] time: 0:10:54.401367 \n",
      "[Epoch 4/200] [Batch 159/266] [D loss: 0.199607, acc:  67%] [G loss: 4.841859, adv: 0.641295, recon: 0.116731, id: 0.558957] time: 0:10:54.850832 \n",
      "[Epoch 4/200] [Batch 160/266] [D loss: 0.170496, acc:  72%] [G loss: 5.104078, adv: 0.717446, recon: 0.121951, id: 0.628322] time: 0:10:55.302095 \n",
      "[Epoch 4/200] [Batch 161/266] [D loss: 0.169511, acc:  74%] [G loss: 5.543181, adv: 0.888196, recon: 0.124279, id: 0.661802] time: 0:10:55.758632 \n",
      "[Epoch 4/200] [Batch 162/266] [D loss: 0.295768, acc:  64%] [G loss: 5.813321, adv: 0.603535, recon: 0.157373, id: 0.735347] time: 0:10:56.212220 \n",
      "[Epoch 4/200] [Batch 163/266] [D loss: 0.150215, acc:  77%] [G loss: 5.576416, adv: 0.794273, recon: 0.133948, id: 0.628037] time: 0:10:56.665621 \n",
      "[Epoch 4/200] [Batch 164/266] [D loss: 0.261867, acc:  57%] [G loss: 5.349260, adv: 0.620053, recon: 0.139054, id: 0.670109] time: 0:10:57.121026 \n",
      "[Epoch 4/200] [Batch 165/266] [D loss: 0.131604, acc:  84%] [G loss: 5.786916, adv: 0.791683, recon: 0.132407, id: 0.714826] time: 0:10:57.577325 \n",
      "[Epoch 4/200] [Batch 166/266] [D loss: 0.211592, acc:  70%] [G loss: 4.768333, adv: 0.644121, recon: 0.114870, id: 0.486177] time: 0:10:58.030344 \n",
      "[Epoch 4/200] [Batch 167/266] [D loss: 0.217198, acc:  69%] [G loss: 4.557868, adv: 0.575590, recon: 0.106716, id: 0.571064] time: 0:10:58.484748 \n",
      "[Epoch 4/200] [Batch 168/266] [D loss: 0.141704, acc:  82%] [G loss: 6.044777, adv: 0.750797, recon: 0.151566, id: 0.587782] time: 0:10:58.939696 \n",
      "[Epoch 4/200] [Batch 169/266] [D loss: 0.162893, acc:  73%] [G loss: 5.822165, adv: 0.793675, recon: 0.146432, id: 0.571869] time: 0:10:59.388342 \n",
      "[Epoch 4/200] [Batch 170/266] [D loss: 0.158866, acc:  79%] [G loss: 5.503539, adv: 0.733244, recon: 0.135368, id: 0.515100] time: 0:10:59.842514 \n",
      "[Epoch 4/200] [Batch 171/266] [D loss: 0.078651, acc:  93%] [G loss: 5.650582, adv: 0.913266, recon: 0.127454, id: 0.510692] time: 0:11:00.299517 \n",
      "[Epoch 4/200] [Batch 172/266] [D loss: 0.116604, acc:  84%] [G loss: 6.248579, adv: 0.840308, recon: 0.152495, id: 0.603307] time: 0:11:00.757201 \n",
      "[Epoch 4/200] [Batch 173/266] [D loss: 0.113534, acc:  86%] [G loss: 5.602726, adv: 0.757436, recon: 0.133322, id: 0.588470] time: 0:11:01.208343 \n",
      "[Epoch 4/200] [Batch 174/266] [D loss: 0.137386, acc:  77%] [G loss: 5.821157, adv: 0.799462, recon: 0.134068, id: 0.640913] time: 0:11:01.665535 \n",
      "[Epoch 4/200] [Batch 175/266] [D loss: 0.166570, acc:  72%] [G loss: 5.283419, adv: 0.662455, recon: 0.127645, id: 0.534939] time: 0:11:02.117343 \n",
      "[Epoch 4/200] [Batch 176/266] [D loss: 0.475370, acc:  45%] [G loss: 5.211335, adv: 0.813312, recon: 0.110671, id: 0.620250] time: 0:11:02.571144 \n",
      "[Epoch 4/200] [Batch 177/266] [D loss: 0.301680, acc:  60%] [G loss: 5.687184, adv: 0.675919, recon: 0.143777, id: 0.634817] time: 0:11:03.024917 \n",
      "[Epoch 4/200] [Batch 178/266] [D loss: 0.443187, acc:  46%] [G loss: 5.759185, adv: 0.778150, recon: 0.141126, id: 0.603116] time: 0:11:03.482121 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 179/266] [D loss: 0.258391, acc:  61%] [G loss: 5.703497, adv: 0.734005, recon: 0.137011, id: 0.646322] time: 0:11:03.944488 \n",
      "[Epoch 4/200] [Batch 180/266] [D loss: 0.242625, acc:  60%] [G loss: 5.423168, adv: 0.558554, recon: 0.140503, id: 0.615800] time: 0:11:04.407988 \n",
      "[Epoch 4/200] [Batch 181/266] [D loss: 0.204780, acc:  75%] [G loss: 5.327824, adv: 0.553311, recon: 0.144365, id: 0.613528] time: 0:11:04.873314 \n",
      "[Epoch 4/200] [Batch 182/266] [D loss: 0.287047, acc:  53%] [G loss: 4.925427, adv: 0.512970, recon: 0.121581, id: 0.678318] time: 0:11:05.326358 \n",
      "[Epoch 4/200] [Batch 183/266] [D loss: 0.230365, acc:  65%] [G loss: 5.183632, adv: 0.596181, recon: 0.126243, id: 0.603780] time: 0:11:05.782853 \n",
      "[Epoch 4/200] [Batch 184/266] [D loss: 0.109868, acc:  91%] [G loss: 5.227447, adv: 0.662207, recon: 0.137512, id: 0.583201] time: 0:11:06.242076 \n",
      "[Epoch 4/200] [Batch 185/266] [D loss: 0.180405, acc:  74%] [G loss: 4.847363, adv: 0.607315, recon: 0.118349, id: 0.539720] time: 0:11:06.699394 \n",
      "[Epoch 4/200] [Batch 186/266] [D loss: 0.149696, acc:  84%] [G loss: 5.927319, adv: 0.722278, recon: 0.150984, id: 0.575278] time: 0:11:07.158490 \n",
      "[Epoch 4/200] [Batch 187/266] [D loss: 0.130017, acc:  84%] [G loss: 5.308616, adv: 0.731161, recon: 0.126883, id: 0.533133] time: 0:11:07.618160 \n",
      "[Epoch 4/200] [Batch 188/266] [D loss: 0.132802, acc:  83%] [G loss: 6.220873, adv: 0.836929, recon: 0.141269, id: 0.771109] time: 0:11:08.088643 \n",
      "[Epoch 4/200] [Batch 189/266] [D loss: 0.379804, acc:  63%] [G loss: 5.699168, adv: 0.616268, recon: 0.147568, id: 0.712835] time: 0:11:08.557840 \n",
      "[Epoch 4/200] [Batch 190/266] [D loss: 0.170681, acc:  77%] [G loss: 5.292758, adv: 0.635976, recon: 0.133074, id: 0.558261] time: 0:11:09.007584 \n",
      "[Epoch 4/200] [Batch 191/266] [D loss: 0.261054, acc:  57%] [G loss: 4.652674, adv: 0.479271, recon: 0.123457, id: 0.559113] time: 0:11:09.472965 \n",
      "[Epoch 4/200] [Batch 192/266] [D loss: 0.154172, acc:  77%] [G loss: 5.418896, adv: 0.650896, recon: 0.136183, id: 0.511374] time: 0:11:09.920135 \n",
      "[Epoch 4/200] [Batch 193/266] [D loss: 0.178600, acc:  75%] [G loss: 5.474268, adv: 0.604322, recon: 0.135479, id: 0.717504] time: 0:11:10.371060 \n",
      "[Epoch 4/200] [Batch 194/266] [D loss: 0.118211, acc:  87%] [G loss: 5.643736, adv: 0.759253, recon: 0.136026, id: 0.600735] time: 0:11:10.827601 \n",
      "[Epoch 4/200] [Batch 195/266] [D loss: 0.272640, acc:  57%] [G loss: 4.598383, adv: 0.518887, recon: 0.111995, id: 0.644858] time: 0:11:11.283351 \n",
      "[Epoch 4/200] [Batch 196/266] [D loss: 0.182754, acc:  71%] [G loss: 4.956732, adv: 0.645216, recon: 0.113036, id: 0.619957] time: 0:11:11.740460 \n",
      "[Epoch 4/200] [Batch 197/266] [D loss: 0.184364, acc:  71%] [G loss: 5.426274, adv: 0.696304, recon: 0.135522, id: 0.584712] time: 0:11:12.190954 \n",
      "[Epoch 4/200] [Batch 198/266] [D loss: 0.141124, acc:  77%] [G loss: 5.493119, adv: 0.782121, recon: 0.128194, id: 0.659809] time: 0:11:12.648486 \n",
      "[Epoch 4/200] [Batch 199/266] [D loss: 0.167146, acc:  75%] [G loss: 4.889551, adv: 0.634527, recon: 0.111334, id: 0.594111] time: 0:11:13.103431 \n",
      "[Epoch 4/200] [Batch 200/266] [D loss: 0.095670, acc:  90%] [G loss: 6.006141, adv: 0.739940, recon: 0.148915, id: 0.712177] time: 0:11:13.551966 \n",
      "[Epoch 4/200] [Batch 201/266] [D loss: 0.105781, acc:  90%] [G loss: 5.067472, adv: 0.713945, recon: 0.114438, id: 0.612591] time: 0:11:14.231225 \n",
      "[Epoch 4/200] [Batch 202/266] [D loss: 0.151502, acc:  73%] [G loss: 5.292530, adv: 0.634751, recon: 0.129319, id: 0.713024] time: 0:11:14.684265 \n",
      "[Epoch 4/200] [Batch 203/266] [D loss: 0.105265, acc:  88%] [G loss: 5.049573, adv: 0.670721, recon: 0.118821, id: 0.563932] time: 0:11:15.137006 \n",
      "[Epoch 4/200] [Batch 204/266] [D loss: 0.098927, acc:  86%] [G loss: 5.275091, adv: 0.796841, recon: 0.115660, id: 0.651096] time: 0:11:15.590908 \n",
      "[Epoch 4/200] [Batch 205/266] [D loss: 0.087745, acc:  88%] [G loss: 5.655137, adv: 0.884030, recon: 0.124763, id: 0.625340] time: 0:11:16.047660 \n",
      "[Epoch 4/200] [Batch 206/266] [D loss: 0.393856, acc:  45%] [G loss: 4.924294, adv: 0.504134, recon: 0.130220, id: 0.545039] time: 0:11:16.502495 \n",
      "[Epoch 4/200] [Batch 207/266] [D loss: 0.180184, acc:  71%] [G loss: 5.686997, adv: 0.644357, recon: 0.160981, id: 0.558943] time: 0:11:16.952152 \n",
      "[Epoch 4/200] [Batch 208/266] [D loss: 0.176460, acc:  75%] [G loss: 5.872808, adv: 0.581194, recon: 0.149760, id: 0.801335] time: 0:11:17.405833 \n",
      "[Epoch 4/200] [Batch 209/266] [D loss: 0.150332, acc:  79%] [G loss: 5.348550, adv: 0.754605, recon: 0.124234, id: 0.582623] time: 0:11:17.856243 \n",
      "[Epoch 4/200] [Batch 210/266] [D loss: 0.157724, acc:  76%] [G loss: 5.172688, adv: 0.721862, recon: 0.111413, id: 0.624385] time: 0:11:18.311963 \n",
      "[Epoch 4/200] [Batch 211/266] [D loss: 0.177397, acc:  75%] [G loss: 5.041423, adv: 0.656414, recon: 0.116096, id: 0.615028] time: 0:11:18.769853 \n",
      "[Epoch 4/200] [Batch 212/266] [D loss: 0.194723, acc:  72%] [G loss: 4.846057, adv: 0.688505, recon: 0.114483, id: 0.471422] time: 0:11:19.224314 \n",
      "[Epoch 4/200] [Batch 213/266] [D loss: 0.147894, acc:  81%] [G loss: 5.780510, adv: 0.692982, recon: 0.147051, id: 0.549651] time: 0:11:19.677920 \n",
      "[Epoch 4/200] [Batch 214/266] [D loss: 0.220570, acc:  69%] [G loss: 5.133649, adv: 0.588682, recon: 0.125454, id: 0.637936] time: 0:11:20.129123 \n",
      "[Epoch 4/200] [Batch 215/266] [D loss: 0.128605, acc:  83%] [G loss: 5.276043, adv: 0.752925, recon: 0.120428, id: 0.602086] time: 0:11:20.579476 \n",
      "[Epoch 4/200] [Batch 216/266] [D loss: 0.188916, acc:  67%] [G loss: 5.717073, adv: 0.790051, recon: 0.135562, id: 0.683283] time: 0:11:21.034882 \n",
      "[Epoch 4/200] [Batch 217/266] [D loss: 0.184966, acc:  75%] [G loss: 5.161735, adv: 0.648641, recon: 0.129003, id: 0.568078] time: 0:11:21.490740 \n",
      "[Epoch 4/200] [Batch 218/266] [D loss: 0.184244, acc:  75%] [G loss: 5.425980, adv: 0.742207, recon: 0.136523, id: 0.503627] time: 0:11:21.947924 \n",
      "[Epoch 4/200] [Batch 219/266] [D loss: 0.152310, acc:  78%] [G loss: 5.442098, adv: 0.677787, recon: 0.136643, id: 0.540053] time: 0:11:22.398327 \n",
      "[Epoch 4/200] [Batch 220/266] [D loss: 0.224190, acc:  64%] [G loss: 5.540366, adv: 0.572758, recon: 0.147408, id: 0.689262] time: 0:11:22.853438 \n",
      "[Epoch 4/200] [Batch 221/266] [D loss: 0.221677, acc:  62%] [G loss: 5.635501, adv: 0.810560, recon: 0.137093, id: 0.597563] time: 0:11:23.309422 \n",
      "[Epoch 4/200] [Batch 222/266] [D loss: 0.304875, acc:  56%] [G loss: 5.591057, adv: 0.605951, recon: 0.141821, id: 0.844172] time: 0:11:23.759354 \n",
      "[Epoch 4/200] [Batch 223/266] [D loss: 0.186802, acc:  71%] [G loss: 5.354779, adv: 0.722301, recon: 0.133875, id: 0.482749] time: 0:11:24.218224 \n",
      "[Epoch 4/200] [Batch 224/266] [D loss: 0.135219, acc:  80%] [G loss: 5.373333, adv: 0.721948, recon: 0.137328, id: 0.517824] time: 0:11:24.676345 \n",
      "[Epoch 4/200] [Batch 225/266] [D loss: 0.147368, acc:  76%] [G loss: 4.980198, adv: 0.678407, recon: 0.117579, id: 0.645652] time: 0:11:25.135002 \n",
      "[Epoch 4/200] [Batch 226/266] [D loss: 0.113524, acc:  83%] [G loss: 5.741782, adv: 0.742094, recon: 0.144749, id: 0.593384] time: 0:11:25.589640 \n",
      "[Epoch 4/200] [Batch 227/266] [D loss: 0.249253, acc:  56%] [G loss: 5.252245, adv: 0.594737, recon: 0.134819, id: 0.621407] time: 0:11:26.038476 \n",
      "[Epoch 4/200] [Batch 228/266] [D loss: 0.122250, acc:  84%] [G loss: 5.327326, adv: 0.642677, recon: 0.131378, id: 0.624979] time: 0:11:26.488661 \n",
      "[Epoch 4/200] [Batch 229/266] [D loss: 0.098161, acc:  87%] [G loss: 5.685399, adv: 0.797298, recon: 0.138481, id: 0.582089] time: 0:11:26.941383 \n",
      "[Epoch 4/200] [Batch 230/266] [D loss: 0.208680, acc:  70%] [G loss: 5.415797, adv: 0.725183, recon: 0.130486, id: 0.677647] time: 0:11:27.389921 \n",
      "[Epoch 4/200] [Batch 231/266] [D loss: 0.193275, acc:  69%] [G loss: 5.195177, adv: 0.722627, recon: 0.121254, id: 0.651690] time: 0:11:27.842678 \n",
      "[Epoch 4/200] [Batch 232/266] [D loss: 0.187224, acc:  73%] [G loss: 5.935454, adv: 0.676101, recon: 0.163615, id: 0.525667] time: 0:11:28.295284 \n",
      "[Epoch 4/200] [Batch 233/266] [D loss: 0.140673, acc:  79%] [G loss: 5.606885, adv: 0.732029, recon: 0.134770, id: 0.753087] time: 0:11:28.750223 \n",
      "[Epoch 4/200] [Batch 234/266] [D loss: 0.129481, acc:  80%] [G loss: 5.695150, adv: 0.870160, recon: 0.126949, id: 0.529739] time: 0:11:29.198519 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 235/266] [D loss: 0.221160, acc:  66%] [G loss: 5.211889, adv: 0.635311, recon: 0.132287, id: 0.567584] time: 0:11:29.649176 \n",
      "[Epoch 4/200] [Batch 236/266] [D loss: 0.117160, acc:  84%] [G loss: 5.381466, adv: 0.761226, recon: 0.130752, id: 0.588701] time: 0:11:30.101777 \n",
      "[Epoch 4/200] [Batch 237/266] [D loss: 0.124608, acc:  84%] [G loss: 6.059268, adv: 0.769306, recon: 0.152672, id: 0.636458] time: 0:11:30.554922 \n",
      "[Epoch 4/200] [Batch 238/266] [D loss: 0.120591, acc:  86%] [G loss: 6.196877, adv: 0.864194, recon: 0.148734, id: 0.560165] time: 0:11:31.007148 \n",
      "[Epoch 4/200] [Batch 239/266] [D loss: 0.111140, acc:  86%] [G loss: 5.515707, adv: 0.775239, recon: 0.129124, id: 0.635131] time: 0:11:31.463456 \n",
      "[Epoch 4/200] [Batch 240/266] [D loss: 0.222771, acc:  62%] [G loss: 5.160761, adv: 0.570601, recon: 0.126450, id: 0.748254] time: 0:11:31.915053 \n",
      "[Epoch 4/200] [Batch 241/266] [D loss: 0.166690, acc:  76%] [G loss: 4.971771, adv: 0.687889, recon: 0.111798, id: 0.535761] time: 0:11:32.367672 \n",
      "[Epoch 4/200] [Batch 242/266] [D loss: 0.299825, acc:  60%] [G loss: 5.607300, adv: 0.757891, recon: 0.127670, id: 0.679370] time: 0:11:32.824325 \n",
      "[Epoch 4/200] [Batch 243/266] [D loss: 0.212978, acc:  62%] [G loss: 5.201693, adv: 0.609752, recon: 0.131357, id: 0.690716] time: 0:11:33.280992 \n",
      "[Epoch 4/200] [Batch 244/266] [D loss: 0.186600, acc:  77%] [G loss: 5.356268, adv: 0.779428, recon: 0.124084, id: 0.497280] time: 0:11:33.731284 \n",
      "[Epoch 4/200] [Batch 245/266] [D loss: 0.200694, acc:  68%] [G loss: 5.588714, adv: 0.703353, recon: 0.138222, id: 0.779650] time: 0:11:34.187957 \n",
      "[Epoch 4/200] [Batch 246/266] [D loss: 0.195043, acc:  70%] [G loss: 5.520624, adv: 0.740433, recon: 0.131427, id: 0.580885] time: 0:11:34.635395 \n",
      "[Epoch 4/200] [Batch 247/266] [D loss: 0.290368, acc:  57%] [G loss: 4.662242, adv: 0.547614, recon: 0.114411, id: 0.580046] time: 0:11:35.084761 \n",
      "[Epoch 4/200] [Batch 248/266] [D loss: 0.203821, acc:  68%] [G loss: 5.262880, adv: 0.688266, recon: 0.123192, id: 0.723668] time: 0:11:35.535054 \n",
      "[Epoch 4/200] [Batch 249/266] [D loss: 0.138829, acc:  78%] [G loss: 5.548780, adv: 0.707104, recon: 0.136903, id: 0.650465] time: 0:11:35.984298 \n",
      "[Epoch 4/200] [Batch 250/266] [D loss: 0.189905, acc:  71%] [G loss: 5.404724, adv: 0.698761, recon: 0.137622, id: 0.490775] time: 0:11:36.440845 \n",
      "[Epoch 4/200] [Batch 251/266] [D loss: 0.146876, acc:  74%] [G loss: 5.667465, adv: 0.765781, recon: 0.135786, id: 0.628071] time: 0:11:36.899923 \n",
      "[Epoch 4/200] [Batch 252/266] [D loss: 0.143928, acc:  79%] [G loss: 5.779423, adv: 0.704049, recon: 0.157452, id: 0.531331] time: 0:11:37.358280 \n",
      "[Epoch 4/200] [Batch 253/266] [D loss: 0.112695, acc:  84%] [G loss: 5.850350, adv: 0.785362, recon: 0.147966, id: 0.475258] time: 0:11:37.808338 \n",
      "[Epoch 4/200] [Batch 254/266] [D loss: 0.239857, acc:  62%] [G loss: 5.618831, adv: 0.769277, recon: 0.127289, id: 0.775773] time: 0:11:38.264432 \n",
      "[Epoch 4/200] [Batch 255/266] [D loss: 0.227757, acc:  63%] [G loss: 5.286100, adv: 0.689817, recon: 0.128877, id: 0.643372] time: 0:11:38.715836 \n",
      "[Epoch 4/200] [Batch 256/266] [D loss: 0.152214, acc:  76%] [G loss: 5.631651, adv: 0.689953, recon: 0.141431, id: 0.690247] time: 0:11:39.170880 \n",
      "[Epoch 4/200] [Batch 257/266] [D loss: 0.275854, acc:  60%] [G loss: 5.434611, adv: 0.521725, recon: 0.161274, id: 0.499041] time: 0:11:39.633087 \n",
      "[Epoch 4/200] [Batch 258/266] [D loss: 0.170171, acc:  78%] [G loss: 5.278776, adv: 0.637356, recon: 0.134792, id: 0.652517] time: 0:11:40.092405 \n",
      "[Epoch 4/200] [Batch 259/266] [D loss: 0.210784, acc:  64%] [G loss: 6.120140, adv: 0.731710, recon: 0.158677, id: 0.587158] time: 0:11:40.552869 \n",
      "[Epoch 4/200] [Batch 260/266] [D loss: 0.182325, acc:  73%] [G loss: 5.310992, adv: 0.646960, recon: 0.133721, id: 0.583786] time: 0:11:41.009213 \n",
      "[Epoch 4/200] [Batch 261/266] [D loss: 0.147704, acc:  79%] [G loss: 5.597591, adv: 0.792929, recon: 0.134045, id: 0.559030] time: 0:11:41.459151 \n",
      "[Epoch 4/200] [Batch 262/266] [D loss: 0.120461, acc:  83%] [G loss: 5.758832, adv: 0.836513, recon: 0.139962, id: 0.541240] time: 0:11:41.910347 \n",
      "[Epoch 4/200] [Batch 263/266] [D loss: 0.166621, acc:  76%] [G loss: 5.567631, adv: 0.682802, recon: 0.138741, id: 0.636948] time: 0:11:42.357951 \n",
      "[Epoch 4/200] [Batch 264/266] [D loss: 0.106966, acc:  90%] [G loss: 5.373785, adv: 0.790121, recon: 0.128320, id: 0.513791] time: 0:11:42.813685 \n",
      "[Epoch 5/200] [Batch 0/266] [D loss: 0.168412, acc:  75%] [G loss: 5.657205, adv: 0.676674, recon: 0.139910, id: 0.754263] time: 0:11:43.874404 \n",
      "[Epoch 5/200] [Batch 1/266] [D loss: 0.155778, acc:  77%] [G loss: 6.154337, adv: 0.881902, recon: 0.152227, id: 0.561652] time: 0:11:44.548340 \n",
      "[Epoch 5/200] [Batch 2/266] [D loss: 0.176115, acc:  74%] [G loss: 5.219341, adv: 0.709210, recon: 0.130849, id: 0.488660] time: 0:11:44.998036 \n",
      "[Epoch 5/200] [Batch 3/266] [D loss: 0.117099, acc:  87%] [G loss: 6.565471, adv: 0.872424, recon: 0.170902, id: 0.633194] time: 0:11:45.448248 \n",
      "[Epoch 5/200] [Batch 4/266] [D loss: 0.142927, acc:  84%] [G loss: 5.480324, adv: 0.658279, recon: 0.136089, id: 0.650556] time: 0:11:45.898519 \n",
      "[Epoch 5/200] [Batch 5/266] [D loss: 0.058761, acc:  94%] [G loss: 5.598577, adv: 0.916306, recon: 0.124902, id: 0.663638] time: 0:11:46.346455 \n",
      "[Epoch 5/200] [Batch 6/266] [D loss: 0.109223, acc:  84%] [G loss: 5.983541, adv: 0.878108, recon: 0.126980, id: 0.898692] time: 0:11:46.800452 \n",
      "[Epoch 5/200] [Batch 7/266] [D loss: 0.104185, acc:  84%] [G loss: 5.716846, adv: 0.812048, recon: 0.143395, id: 0.488228] time: 0:11:47.247312 \n",
      "[Epoch 5/200] [Batch 8/266] [D loss: 0.109524, acc:  84%] [G loss: 5.247374, adv: 0.812434, recon: 0.112013, id: 0.647909] time: 0:11:47.704174 \n",
      "[Epoch 5/200] [Batch 9/266] [D loss: 0.171378, acc:  76%] [G loss: 5.358969, adv: 0.711056, recon: 0.136223, id: 0.551300] time: 0:11:48.156472 \n",
      "[Epoch 5/200] [Batch 10/266] [D loss: 0.212202, acc:  65%] [G loss: 5.317992, adv: 0.785791, recon: 0.126636, id: 0.536972] time: 0:11:48.612459 \n",
      "[Epoch 5/200] [Batch 11/266] [D loss: 0.098238, acc:  88%] [G loss: 5.602326, adv: 0.874534, recon: 0.127346, id: 0.535687] time: 0:11:49.068325 \n",
      "[Epoch 5/200] [Batch 12/266] [D loss: 0.253156, acc:  56%] [G loss: 5.389461, adv: 0.663730, recon: 0.130904, id: 0.645437] time: 0:11:49.519753 \n",
      "[Epoch 5/200] [Batch 13/266] [D loss: 0.159601, acc:  77%] [G loss: 5.182445, adv: 0.683615, recon: 0.125369, id: 0.499757] time: 0:11:49.971194 \n",
      "[Epoch 5/200] [Batch 14/266] [D loss: 0.154535, acc:  77%] [G loss: 5.427114, adv: 0.743360, recon: 0.127590, id: 0.699312] time: 0:11:50.419760 \n",
      "[Epoch 5/200] [Batch 15/266] [D loss: 0.154869, acc:  75%] [G loss: 5.537071, adv: 0.678159, recon: 0.142957, id: 0.469732] time: 0:11:50.875673 \n",
      "[Epoch 5/200] [Batch 16/266] [D loss: 0.225934, acc:  63%] [G loss: 5.142894, adv: 0.775107, recon: 0.110729, id: 0.600599] time: 0:11:51.329755 \n",
      "[Epoch 5/200] [Batch 17/266] [D loss: 0.137733, acc:  80%] [G loss: 5.786722, adv: 0.773750, recon: 0.146671, id: 0.558188] time: 0:11:51.785038 \n",
      "[Epoch 5/200] [Batch 18/266] [D loss: 0.212509, acc:  62%] [G loss: 6.382012, adv: 0.684129, recon: 0.166333, id: 0.777749] time: 0:11:52.239902 \n",
      "[Epoch 5/200] [Batch 19/266] [D loss: 0.276028, acc:  68%] [G loss: 6.126050, adv: 0.816298, recon: 0.150142, id: 0.714269] time: 0:11:52.699201 \n",
      "[Epoch 5/200] [Batch 20/266] [D loss: 0.166834, acc:  78%] [G loss: 6.442607, adv: 0.878404, recon: 0.161450, id: 0.564849] time: 0:11:53.152428 \n",
      "[Epoch 5/200] [Batch 21/266] [D loss: 0.219411, acc:  73%] [G loss: 5.593752, adv: 0.680393, recon: 0.141608, id: 0.686242] time: 0:11:53.603477 \n",
      "[Epoch 5/200] [Batch 22/266] [D loss: 0.265162, acc:  52%] [G loss: 6.102161, adv: 0.737456, recon: 0.156884, id: 0.649255] time: 0:11:54.063017 \n",
      "[Epoch 5/200] [Batch 23/266] [D loss: 0.162616, acc:  74%] [G loss: 5.710423, adv: 0.744137, recon: 0.139165, id: 0.662918] time: 0:11:54.512493 \n",
      "[Epoch 5/200] [Batch 24/266] [D loss: 0.200639, acc:  74%] [G loss: 5.676892, adv: 0.663122, recon: 0.141874, id: 0.649482] time: 0:11:54.967767 \n",
      "[Epoch 5/200] [Batch 25/266] [D loss: 0.183389, acc:  73%] [G loss: 5.110972, adv: 0.588536, recon: 0.121188, id: 0.657155] time: 0:11:55.424076 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 26/266] [D loss: 0.221628, acc:  64%] [G loss: 4.902951, adv: 0.587043, recon: 0.121860, id: 0.611997] time: 0:11:55.881796 \n",
      "[Epoch 5/200] [Batch 27/266] [D loss: 0.109049, acc:  88%] [G loss: 5.210799, adv: 0.757497, recon: 0.122203, id: 0.559949] time: 0:11:56.335470 \n",
      "[Epoch 5/200] [Batch 28/266] [D loss: 0.114249, acc:  84%] [G loss: 5.917319, adv: 0.777395, recon: 0.142350, id: 0.735386] time: 0:11:56.788531 \n",
      "[Epoch 5/200] [Batch 29/266] [D loss: 0.163227, acc:  75%] [G loss: 5.150533, adv: 0.671221, recon: 0.119295, id: 0.537726] time: 0:11:57.242331 \n",
      "[Epoch 5/200] [Batch 30/266] [D loss: 0.137247, acc:  81%] [G loss: 4.758477, adv: 0.707804, recon: 0.101675, id: 0.584977] time: 0:11:57.695252 \n",
      "[Epoch 5/200] [Batch 31/266] [D loss: 0.165120, acc:  78%] [G loss: 5.502893, adv: 0.823614, recon: 0.123851, id: 0.565228] time: 0:11:58.149888 \n",
      "[Epoch 5/200] [Batch 32/266] [D loss: 0.118056, acc:  84%] [G loss: 5.594052, adv: 0.877763, recon: 0.120842, id: 0.694900] time: 0:11:58.602006 \n",
      "[Epoch 5/200] [Batch 33/266] [D loss: 0.230258, acc:  69%] [G loss: 6.119676, adv: 0.713956, recon: 0.160116, id: 0.747198] time: 0:11:59.056819 \n",
      "[Epoch 5/200] [Batch 34/266] [D loss: 0.082461, acc:  89%] [G loss: 5.879574, adv: 0.847776, recon: 0.146683, id: 0.514002] time: 0:11:59.506762 \n",
      "[Epoch 5/200] [Batch 35/266] [D loss: 0.152962, acc:  79%] [G loss: 5.499444, adv: 0.691280, recon: 0.144988, id: 0.524777] time: 0:11:59.962010 \n",
      "[Epoch 5/200] [Batch 36/266] [D loss: 0.186834, acc:  69%] [G loss: 5.189144, adv: 0.689472, recon: 0.128998, id: 0.662019] time: 0:12:00.417557 \n",
      "[Epoch 5/200] [Batch 37/266] [D loss: 0.141151, acc:  81%] [G loss: 5.797283, adv: 0.795755, recon: 0.136936, id: 0.678537] time: 0:12:00.872640 \n",
      "[Epoch 5/200] [Batch 38/266] [D loss: 0.103842, acc:  86%] [G loss: 5.693552, adv: 0.833379, recon: 0.131833, id: 0.712902] time: 0:12:01.326678 \n",
      "[Epoch 5/200] [Batch 39/266] [D loss: 0.227093, acc:  60%] [G loss: 5.265617, adv: 0.677842, recon: 0.132779, id: 0.616906] time: 0:12:01.780976 \n",
      "[Epoch 5/200] [Batch 40/266] [D loss: 0.165462, acc:  75%] [G loss: 5.179419, adv: 0.640647, recon: 0.125388, id: 0.655486] time: 0:12:02.231069 \n",
      "[Epoch 5/200] [Batch 41/266] [D loss: 0.166968, acc:  77%] [G loss: 5.738194, adv: 0.660949, recon: 0.139795, id: 0.784968] time: 0:12:02.685922 \n",
      "[Epoch 5/200] [Batch 42/266] [D loss: 0.145020, acc:  79%] [G loss: 6.294086, adv: 0.849690, recon: 0.150139, id: 0.787903] time: 0:12:03.139065 \n",
      "[Epoch 5/200] [Batch 43/266] [D loss: 0.159739, acc:  78%] [G loss: 6.262932, adv: 0.770334, recon: 0.164029, id: 0.672124] time: 0:12:03.594616 \n",
      "[Epoch 5/200] [Batch 44/266] [D loss: 0.206439, acc:  68%] [G loss: 5.825227, adv: 0.725388, recon: 0.140993, id: 0.798443] time: 0:12:04.050881 \n",
      "[Epoch 5/200] [Batch 45/266] [D loss: 0.161445, acc:  76%] [G loss: 5.363286, adv: 0.808436, recon: 0.118045, id: 0.688588] time: 0:12:04.503797 \n",
      "[Epoch 5/200] [Batch 46/266] [D loss: 0.158129, acc:  78%] [G loss: 5.218361, adv: 0.649217, recon: 0.128534, id: 0.625924] time: 0:12:04.951308 \n",
      "[Epoch 5/200] [Batch 47/266] [D loss: 0.099020, acc:  87%] [G loss: 5.299765, adv: 0.766798, recon: 0.120037, id: 0.600743] time: 0:12:05.404389 \n",
      "[Epoch 5/200] [Batch 48/266] [D loss: 0.091807, acc:  91%] [G loss: 5.161097, adv: 0.820721, recon: 0.115169, id: 0.543502] time: 0:12:05.857720 \n",
      "[Epoch 5/200] [Batch 49/266] [D loss: 0.143057, acc:  77%] [G loss: 5.427615, adv: 0.785301, recon: 0.126623, id: 0.570101] time: 0:12:06.307307 \n",
      "[Epoch 5/200] [Batch 50/266] [D loss: 0.101125, acc:  84%] [G loss: 5.032832, adv: 0.820622, recon: 0.109882, id: 0.515947] time: 0:12:06.762445 \n",
      "[Epoch 5/200] [Batch 51/266] [D loss: 0.104406, acc:  86%] [G loss: 5.056916, adv: 0.721310, recon: 0.117385, id: 0.493137] time: 0:12:07.208328 \n",
      "[Epoch 5/200] [Batch 52/266] [D loss: 0.164798, acc:  77%] [G loss: 5.178379, adv: 0.801316, recon: 0.114879, id: 0.573425] time: 0:12:07.662564 \n",
      "[Epoch 5/200] [Batch 53/266] [D loss: 0.185235, acc:  71%] [G loss: 5.060392, adv: 0.786507, recon: 0.106283, id: 0.555447] time: 0:12:08.114513 \n",
      "[Epoch 5/200] [Batch 54/266] [D loss: 0.213376, acc:  68%] [G loss: 4.959022, adv: 0.682787, recon: 0.119555, id: 0.529704] time: 0:12:08.570003 \n",
      "[Epoch 5/200] [Batch 55/266] [D loss: 0.198752, acc:  73%] [G loss: 5.491271, adv: 0.606453, recon: 0.141799, id: 0.691086] time: 0:12:09.019014 \n",
      "[Epoch 5/200] [Batch 56/266] [D loss: 0.081893, acc:  91%] [G loss: 5.563412, adv: 0.953664, recon: 0.115845, id: 0.648699] time: 0:12:09.465777 \n",
      "[Epoch 5/200] [Batch 57/266] [D loss: 0.423778, acc:  45%] [G loss: 5.934489, adv: 0.688838, recon: 0.163086, id: 0.548653] time: 0:12:09.918064 \n",
      "[Epoch 5/200] [Batch 58/266] [D loss: 0.173922, acc:  74%] [G loss: 5.585585, adv: 0.757376, recon: 0.138677, id: 0.537514] time: 0:12:10.371724 \n",
      "[Epoch 5/200] [Batch 59/266] [D loss: 0.167751, acc:  77%] [G loss: 5.023540, adv: 0.631772, recon: 0.116942, id: 0.663100] time: 0:12:10.824746 \n",
      "[Epoch 5/200] [Batch 60/266] [D loss: 0.216080, acc:  67%] [G loss: 5.634048, adv: 0.727212, recon: 0.150799, id: 0.490193] time: 0:12:11.277007 \n",
      "[Epoch 5/200] [Batch 61/266] [D loss: 0.160652, acc:  75%] [G loss: 5.902295, adv: 0.839742, recon: 0.143829, id: 0.599332] time: 0:12:11.734569 \n",
      "[Epoch 5/200] [Batch 62/266] [D loss: 0.237041, acc:  60%] [G loss: 4.864465, adv: 0.705311, recon: 0.110363, id: 0.512400] time: 0:12:12.190616 \n",
      "[Epoch 5/200] [Batch 63/266] [D loss: 0.145000, acc:  78%] [G loss: 5.523858, adv: 0.721574, recon: 0.138712, id: 0.543104] time: 0:12:12.641814 \n",
      "[Epoch 5/200] [Batch 64/266] [D loss: 0.207674, acc:  70%] [G loss: 5.340636, adv: 0.674883, recon: 0.129840, id: 0.600163] time: 0:12:13.091201 \n",
      "[Epoch 5/200] [Batch 65/266] [D loss: 0.197818, acc:  69%] [G loss: 4.933909, adv: 0.570829, recon: 0.119385, id: 0.583302] time: 0:12:13.550500 \n",
      "[Epoch 5/200] [Batch 66/266] [D loss: 0.159473, acc:  75%] [G loss: 5.164842, adv: 0.681016, recon: 0.120269, id: 0.631738] time: 0:12:14.001929 \n",
      "[Epoch 5/200] [Batch 67/266] [D loss: 0.182901, acc:  68%] [G loss: 5.256454, adv: 0.650792, recon: 0.131674, id: 0.594941] time: 0:12:14.455866 \n",
      "[Epoch 5/200] [Batch 68/266] [D loss: 0.183733, acc:  74%] [G loss: 5.251842, adv: 0.652579, recon: 0.133508, id: 0.495760] time: 0:12:14.908355 \n",
      "[Epoch 5/200] [Batch 69/266] [D loss: 0.097327, acc:  90%] [G loss: 5.563866, adv: 0.834103, recon: 0.116981, id: 0.629954] time: 0:12:15.354293 \n",
      "[Epoch 5/200] [Batch 70/266] [D loss: 0.212937, acc:  68%] [G loss: 5.203127, adv: 0.769946, recon: 0.108027, id: 0.662186] time: 0:12:15.814254 \n",
      "[Epoch 5/200] [Batch 71/266] [D loss: 0.161227, acc:  77%] [G loss: 5.921313, adv: 0.794459, recon: 0.144685, id: 0.562936] time: 0:12:16.265664 \n",
      "[Epoch 5/200] [Batch 72/266] [D loss: 0.182607, acc:  77%] [G loss: 5.691967, adv: 0.761892, recon: 0.129798, id: 0.673488] time: 0:12:16.720787 \n",
      "[Epoch 5/200] [Batch 73/266] [D loss: 0.123442, acc:  83%] [G loss: 5.711853, adv: 0.707510, recon: 0.137731, id: 0.707449] time: 0:12:17.163678 \n",
      "[Epoch 5/200] [Batch 74/266] [D loss: 0.157495, acc:  78%] [G loss: 6.094167, adv: 0.687267, recon: 0.165502, id: 0.550210] time: 0:12:17.613081 \n",
      "[Epoch 5/200] [Batch 75/266] [D loss: 0.088049, acc:  91%] [G loss: 5.205690, adv: 0.887783, recon: 0.107334, id: 0.487742] time: 0:12:18.067908 \n",
      "[Epoch 5/200] [Batch 76/266] [D loss: 0.128852, acc:  81%] [G loss: 5.192634, adv: 0.713341, recon: 0.125362, id: 0.604784] time: 0:12:18.517800 \n",
      "[Epoch 5/200] [Batch 77/266] [D loss: 0.208775, acc:  62%] [G loss: 5.581616, adv: 0.683544, recon: 0.121959, id: 0.952010] time: 0:12:18.974582 \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = CycleGAN()\n",
    "    gan.train(epochs=200, batch_size=4, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
